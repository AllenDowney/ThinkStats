
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Estimation &#8212; Think Stats, 3rd edition</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]]}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chap08';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Hypothesis testing" href="chap09.html" />
    <link rel="prev" title="Relationships between variables" href="chap07.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
  
    <p class="title logo__title">Think Stats, 3rd edition</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="index.html">
                    Think Stats, 3rd edition
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="chap00.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap01.html">Exploratory data analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap02.html">Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap03.html">Probability mass functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap04.html">Cumulative distribution functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap05.html">Modeling distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap06.html">Probability density functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap07.html">Relationships between variables</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap09.html">Hypothesis testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap10.html">Linear least squares</a></li>

<li class="toctree-l1"><a class="reference internal" href="chap11.html">Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap12.html">Time series analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap13.html">Survival analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap14.html">Analytic methods</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/AllenDowney/ThinkStats/tree/v3" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/chap08.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Estimation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-estimation-game">The estimation game</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#guess-the-variance">Guess the variance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-distributions">Sampling distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-bias">Sampling bias</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exponential-distributions">Exponential distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glossary">Glossary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="estimation">
<h1>Estimation<a class="headerlink" href="#estimation" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">basename</span><span class="p">,</span> <span class="n">exists</span>


<span class="k">def</span> <span class="nf">download</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="n">basename</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">urllib.request</span> <span class="kn">import</span> <span class="n">urlretrieve</span>

        <span class="n">local</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Downloaded &quot;</span> <span class="o">+</span> <span class="n">local</span><span class="p">)</span>


<span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkstats2.py&quot;</span><span class="p">)</span>
<span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkplot.py&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">thinkstats2</span>
<span class="kn">import</span> <span class="nn">thinkplot</span>
</pre></div>
</div>
</div>
</div>
<section id="the-estimation-game">
<h2>The estimation game<a class="headerlink" href="#the-estimation-game" title="Link to this heading">#</a></h2>
<p>Let’s play a game. I think of a distribution, and you have to guess what
it is. I’ll give you two hints: it’s a normal distribution, and here’s a
random sample drawn from it:</p>
<p><code class="docutils literal notranslate"><span class="pre">[-0.441,</span> <span class="pre">1.774,</span> <span class="pre">-0.101,</span> <span class="pre">-1.138,</span> <span class="pre">2.975,</span> <span class="pre">-2.138]</span></code></p>
<p>What do you think is the mean parameter, <span class="math notranslate nohighlight">\(\mu\)</span>, of this distribution?</p>
<p>One choice is to use the sample mean, <span class="math notranslate nohighlight">\(\bar{x}\)</span>, as an estimate of <span class="math notranslate nohighlight">\(\mu\)</span>.
In this example, <span class="math notranslate nohighlight">\(\bar{x}\)</span> is 0.155, so it would be reasonable to guess
<span class="math notranslate nohighlight">\(\mu\)</span> = 0.155. This process is called <strong>estimation</strong>, and the statistic
we used (the sample mean) is called an <strong>estimator</strong>.</p>
<p>Using the sample mean to estimate <span class="math notranslate nohighlight">\(\mu\)</span> is so obvious that it is hard to
imagine a reasonable alternative. But suppose we change the game by
introducing outliers.</p>
<p><em>I’m thinking of a distribution.</em> It’s a normal distribution, and here’s
a sample that was collected by an unreliable surveyor who occasionally
puts the decimal point in the wrong place.</p>
<p><code class="docutils literal notranslate"><span class="pre">[-0.441,</span> <span class="pre">1.774,</span> <span class="pre">-0.101,</span> <span class="pre">-1.138,</span> <span class="pre">2.975,</span> <span class="pre">-213.8]</span></code></p>
<p>Now what’s your estimate of <span class="math notranslate nohighlight">\(\mu\)</span>? If you use the sample mean, your
guess is -35.12. Is that the best choice? What are the alternatives?</p>
<p>One option is to identify and discard outliers, then compute the sample
mean of the rest. Another option is to use the median as an estimator.</p>
<p>Which estimator is best depends on the circumstances (for example,
whether there are outliers) and on what the goal is. Are you trying to
minimize errors, or maximize your chance of getting the right answer?</p>
<p>If there are no outliers, the sample mean minimizes the <strong>mean squared
error</strong> (MSE). That is, if we play the game many times, and each time
compute the error <span class="math notranslate nohighlight">\(\bar{x} - \mu\)</span>, the sample mean minimizes
$<span class="math notranslate nohighlight">\(MSE = \frac{1}{m} \sum (\bar{x} - \mu)^2\)</span><span class="math notranslate nohighlight">\( Where \)</span>m<span class="math notranslate nohighlight">\( is the number of
times you play the estimation game, not to be confused with \)</span>n<span class="math notranslate nohighlight">\(, which
is the size of the sample used to compute \)</span>\bar{x}$.</p>
<p>Here is a function that simulates the estimation game and computes the
root mean squared error (RMSE), which is the square root of MSE:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">RMSE</span><span class="p">(</span><span class="n">estimates</span><span class="p">,</span> <span class="n">actual</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes the root mean squared error of a sequence of estimates.</span>

<span class="sd">    estimate: sequence of numbers</span>
<span class="sd">    actual: actual value</span>

<span class="sd">    returns: float RMSE</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">e2</span> <span class="o">=</span> <span class="p">[(</span><span class="n">estimate</span><span class="o">-</span><span class="n">actual</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">estimate</span> <span class="ow">in</span> <span class="n">estimates</span><span class="p">]</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">e2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>

<span class="k">def</span> <span class="nf">Estimate1</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">means</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">medians</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">gauss</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
        <span class="n">xbar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
        <span class="n">median</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
        <span class="n">means</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">xbar</span><span class="p">)</span>
        <span class="n">medians</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">median</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;rmse xbar&#39;</span><span class="p">,</span> <span class="n">RMSE</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">mu</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;rmse median&#39;</span><span class="p">,</span> <span class="n">RMSE</span><span class="p">(</span><span class="n">medians</span><span class="p">,</span> <span class="n">mu</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Estimate1</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>rmse xbar 0.39530236044347977
rmse median 0.475238334720722
</pre></div>
</div>
</div>
</div>
<p>Again, <code class="docutils literal notranslate"><span class="pre">n</span></code> is the size of the sample, and <code class="docutils literal notranslate"><span class="pre">m</span></code> is the number of times we
play the game. <code class="docutils literal notranslate"><span class="pre">means</span></code> is the list of estimates based on <span class="math notranslate nohighlight">\(\bar{x}\)</span>.
<code class="docutils literal notranslate"><span class="pre">medians</span></code> is the list of medians.</p>
<p>Here’s the function that computes RMSE:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">RMSE</span><span class="p">(</span><span class="n">estimates</span><span class="p">,</span> <span class="n">actual</span><span class="p">):</span>
    <span class="n">e2</span> <span class="o">=</span> <span class="p">[(</span><span class="n">estimate</span><span class="o">-</span><span class="n">actual</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">estimate</span> <span class="ow">in</span> <span class="n">estimates</span><span class="p">]</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">e2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">estimates</span></code> is a list of estimates; <code class="docutils literal notranslate"><span class="pre">actual</span></code> is the actual value being
estimated. In practice, of course, we don’t know <code class="docutils literal notranslate"><span class="pre">actual</span></code>; if we did, we
wouldn’t have to estimate it. The purpose of this experiment is to
compare the performance of the two estimators.</p>
<p>When I ran this code, the RMSE of the sample mean was 0.41, which means
that if we use <span class="math notranslate nohighlight">\(\bar{x}\)</span> to estimate the mean of this distribution, based
on a sample with <span class="math notranslate nohighlight">\(n=7\)</span>, we should expect to be off by 0.41 on average.
Using the median to estimate the mean yields RMSE 0.53, which confirms
that <span class="math notranslate nohighlight">\(\bar{x}\)</span> yields lower RMSE, at least for this example.</p>
<p>Minimizing MSE is a nice property, but it’s not always the best
strategy. For example, suppose we are estimating the distribution of
wind speeds at a building site. If the estimate is too high, we might
overbuild the structure, increasing its cost. But if it’s too low, the
building might collapse. Because cost as a function of error is not
symmetric, minimizing MSE is not the best strategy.</p>
<p>As another example, suppose I roll three six-sided dice and ask you to
predict the total. If you get it exactly right, you get a prize;
otherwise you get nothing. In this case the value that minimizes MSE is
10.5, but that would be a bad guess, because the total of three dice is
never 10.5. For this game, you want an estimator that has the highest
chance of being right, which is a <strong>maximum likelihood estimator</strong>
(MLE). If you pick 10 or 11, your chance of winning is 1 in 8, and
that’s the best you can do.</p>
</section>
<section id="guess-the-variance">
<h2>Guess the variance<a class="headerlink" href="#guess-the-variance" title="Link to this heading">#</a></h2>
<p><em>I’m thinking of a distribution.</em> It’s a normal distribution, and here’s
a (familiar) sample:</p>
<p><code class="docutils literal notranslate"><span class="pre">[-0.441,</span> <span class="pre">1.774,</span> <span class="pre">-0.101,</span> <span class="pre">-1.138,</span> <span class="pre">2.975,</span> <span class="pre">-2.138]</span></code></p>
<p>What do you think is the variance, <span class="math notranslate nohighlight">\(\sigma^2\)</span>, of my distribution?
Again, the obvious choice is to use the sample variance, <span class="math notranslate nohighlight">\(S^2\)</span>, as an
estimator. $<span class="math notranslate nohighlight">\(S^2 = \frac{1}{n} \sum (x_i - \bar{x})^2\)</span><span class="math notranslate nohighlight">\( For large samples,
\)</span>S^2$ is an adequate estimator, but for small samples it tends to be too
low. Because of this unfortunate property, it is called a <strong>biased</strong>
estimator. An estimator is <strong>unbiased</strong> if the expected total (or mean)
error, after many iterations of the estimation game, is 0.</p>
<p>Fortunately, there is another simple statistic that is an unbiased
estimator of <span class="math notranslate nohighlight">\(\sigma^2\)</span>:
$<span class="math notranslate nohighlight">\(S_{n-1}^2 = \frac{1}{n-1} \sum (x_i - \bar{x})^2\)</span><span class="math notranslate nohighlight">\( For an explanation of
why \)</span>S^2<span class="math notranslate nohighlight">\( is biased, and a proof that \)</span>S_{n-1}^2$ is unbiased, see
<a class="reference external" href="http://wikipedia.org/wiki/Bias_of_an_estimator">http://wikipedia.org/wiki/Bias_of_an_estimator</a>.</p>
<p>The biggest problem with this estimator is that its name and symbol are
used inconsistently. The name “sample variance” can refer to either
<span class="math notranslate nohighlight">\(S^2\)</span> or <span class="math notranslate nohighlight">\(S_{n-1}^2\)</span>, and the symbol <span class="math notranslate nohighlight">\(S^2\)</span> is used for either or both.</p>
<p>Here is a function that simulates the estimation game and tests the
performance of <span class="math notranslate nohighlight">\(S^2\)</span> and <span class="math notranslate nohighlight">\(S_{n-1}^2\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">MeanError</span><span class="p">(</span><span class="n">estimates</span><span class="p">,</span> <span class="n">actual</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes the mean error of a sequence of estimates.</span>

<span class="sd">    estimate: sequence of numbers</span>
<span class="sd">    actual: actual value</span>

<span class="sd">    returns: float mean error</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimate</span><span class="o">-</span><span class="n">actual</span> <span class="k">for</span> <span class="n">estimate</span> <span class="ow">in</span> <span class="n">estimates</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">Estimate2</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">estimates1</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">estimates2</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">gauss</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
        <span class="n">biased</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
        <span class="n">unbiased</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">estimates1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">biased</span><span class="p">)</span>
        <span class="n">estimates2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unbiased</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mean error biased&#39;</span><span class="p">,</span> <span class="n">MeanError</span><span class="p">(</span><span class="n">estimates1</span><span class="p">,</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mean error unbiased&#39;</span><span class="p">,</span> <span class="n">MeanError</span><span class="p">(</span><span class="n">estimates2</span><span class="p">,</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Estimate2</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mean error biased -0.13695189314208897
mean error unbiased 0.006889458000896184
</pre></div>
</div>
</div>
</div>
<p>Again, <code class="docutils literal notranslate"><span class="pre">n</span></code> is the sample size and <code class="docutils literal notranslate"><span class="pre">m</span></code> is the number of times we play the
game. <code class="docutils literal notranslate"><span class="pre">np.var</span></code> computes <span class="math notranslate nohighlight">\(S^2\)</span> by default and <span class="math notranslate nohighlight">\(S_{n-1}^2\)</span> if you provide
the argument <code class="docutils literal notranslate"><span class="pre">ddof=1</span></code>, which stands for “delta degrees of freedom.” I
won’t explain that term, but you can read about it at
<a class="reference external" href="http://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)">http://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)</a>.</p>
<p><code class="docutils literal notranslate"><span class="pre">MeanError</span></code> computes the mean difference between the estimates and the
actual value:</p>
<p>When I ran this code, the mean error for <span class="math notranslate nohighlight">\(S^2\)</span> was -0.13. As expected,
this biased estimator tends to be too low. For <span class="math notranslate nohighlight">\(S_{n-1}^2\)</span>, the mean
error was 0.014, about 10 times smaller. As <code class="docutils literal notranslate"><span class="pre">m</span></code> increases, we expect the
mean error for <span class="math notranslate nohighlight">\(S_{n-1}^2\)</span> to approach 0.</p>
<p>Properties like MSE and bias are long-term expectations based on many
iterations of the estimation game. By running simulations like the ones
in this chapter, we can compare estimators and check whether they have
desired properties.</p>
<p>But when you apply an estimator to real data, you just get one estimate.
It would not be meaningful to say that the estimate is unbiased; being
unbiased is a property of the estimator, not the estimate.</p>
<p>After you choose an estimator with appropriate properties, and use it to
generate an estimate, the next step is to characterize the uncertainty
of the estimate, which is the topic of the next section.</p>
</section>
<section id="sampling-distributions">
<h2>Sampling distributions<a class="headerlink" href="#sampling-distributions" title="Link to this heading">#</a></h2>
<p>Suppose you are a scientist studying gorillas in a wildlife preserve.
You want to know the average weight of the adult female gorillas in the
preserve. To weigh them, you have to tranquilize them, which is
dangerous, expensive, and possibly harmful to the gorillas. But if it is
important to obtain this information, it might be acceptable to weigh a
sample of 9 gorillas. Let’s assume that the population of the preserve
is well known, so we can choose a representative sample of adult
females. We could use the sample mean, <span class="math notranslate nohighlight">\(\bar{x}\)</span>, to estimate the unknown
population mean, <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
<p>Having weighed 9 female gorillas, you might find <span class="math notranslate nohighlight">\(\bar{x}=90\)</span> kg and
sample standard deviation, <span class="math notranslate nohighlight">\(S=7.5\)</span> kg. The sample mean is an unbiased
estimator of <span class="math notranslate nohighlight">\(\mu\)</span>, and in the long run it minimizes MSE. So if you
report a single estimate that summarizes the results, you would report
90 kg.</p>
<p>But how confident should you be in this estimate? If you only weigh
<span class="math notranslate nohighlight">\(n=9\)</span> gorillas out of a much larger population, you might be unlucky and
choose the 9 heaviest gorillas (or the 9 lightest ones) just by chance.
Variation in the estimate caused by random selection is called
<strong>sampling error</strong>.</p>
<p>To quantify sampling error, we can simulate the sampling process with
hypothetical values of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>, and see how much <span class="math notranslate nohighlight">\(\bar{x}\)</span>
varies.</p>
<p>Since we don’t know the actual values of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> in the
population, we’ll use the estimates <span class="math notranslate nohighlight">\(\bar{x}\)</span> and <span class="math notranslate nohighlight">\(S\)</span>. So the question we
answer is: “If the actual values of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> were 90 kg and
7.5 kg, and we ran the same experiment many times, how much would the
estimated mean, <span class="math notranslate nohighlight">\(\bar{x}\)</span>, vary?”</p>
<p>The following function answers that question:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">SimulateSample</span><span class="p">(</span><span class="n">mu</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">7.5</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">xbars</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iters</span><span class="p">):</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
        <span class="n">xbar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
        <span class="n">xbars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">xbar</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">xbars</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">mu</span></code> and <code class="docutils literal notranslate"><span class="pre">sigma</span></code> are the <em>hypothetical</em> values of the parameters. <code class="docutils literal notranslate"><span class="pre">n</span></code> is
the sample size, the number of gorillas we measured. <code class="docutils literal notranslate"><span class="pre">m</span></code> is the number
of times we run the simulation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xbars</span> <span class="o">=</span> <span class="n">SimulateSample</span><span class="p">()</span>
<span class="n">cdf</span> <span class="o">=</span> <span class="n">thinkstats2</span><span class="o">.</span><span class="n">Cdf</span><span class="p">(</span><span class="n">xbars</span><span class="p">)</span>
<span class="n">thinkplot</span><span class="o">.</span><span class="n">Cdf</span><span class="p">(</span><span class="n">cdf</span><span class="p">)</span>
<span class="n">thinkplot</span><span class="o">.</span><span class="n">Config</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Sample mean&#39;</span><span class="p">,</span>
                 <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;CDF&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/57dabec1a776d4c7d42a4b55ae387a45d8a17164430e5e34fb8dd3b7b52e180e.png" src="_images/57dabec1a776d4c7d42a4b55ae387a45d8a17164430e5e34fb8dd3b7b52e180e.png" />
</div>
</div>
<p>In each iteration, we choose <code class="docutils literal notranslate"><span class="pre">n</span></code> values from a normal distribution with
the given parameters, and compute the sample mean, <code class="docutils literal notranslate"><span class="pre">xbar</span></code>. We run 1000
simulations and then compute the distribution, <code class="docutils literal notranslate"><span class="pre">cdf</span></code>, of the estimates.
The result is shown in
Figure <a class="reference internal" href="#estimation1"><span class="xref myst">[estimation1]</span></a>{reference-type=“ref”
reference=“estimation1”}. This distribution is called the <strong>sampling
distribution</strong> of the estimator. It shows how much the estimates would
vary if we ran the experiment over and over.</p>
<p>The mean of the sampling distribution is pretty close to the
hypothetical value of <span class="math notranslate nohighlight">\(\mu\)</span>, which means that the experiment yields the
right answer, on average. After 1000 tries, the lowest result is 82 kg,
and the highest is 98 kg. This range suggests that the estimate might be
off by as much as 8 kg.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xbars</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>90.06484084475981
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ci</span> <span class="o">=</span> <span class="n">cdf</span><span class="o">.</span><span class="n">Percentile</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="n">cdf</span><span class="o">.</span><span class="n">Percentile</span><span class="p">(</span><span class="mi">95</span><span class="p">)</span>
<span class="n">ci</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(85.96712753834224, 94.13764998760222)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stderr</span> <span class="o">=</span> <span class="n">RMSE</span><span class="p">(</span><span class="n">xbars</span><span class="p">,</span> <span class="mi">90</span><span class="p">)</span>
<span class="n">stderr</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.5378143765427614
</pre></div>
</div>
</div>
</div>
<p>There are two common ways to summarize the sampling distribution:</p>
<ul class="simple">
<li><p><strong>Standard error</strong> (SE) is a measure of how far we expect the
estimate to be off, on average. For each simulated experiment, we
compute the error, <span class="math notranslate nohighlight">\(\bar{x} - \mu\)</span>, and then compute the root mean
squared error (RMSE). In this example, it is roughly 2.5 kg.</p></li>
<li><p>A <strong>confidence interval</strong> (CI) is a range that includes a given
fraction of the sampling distribution. For example, the 90%
confidence interval is the range from the 5th to the 95th
percentile. In this example, the 90% CI is <span class="math notranslate nohighlight">\((86, 94)\)</span> kg.</p></li>
</ul>
<p>Standard errors and confidence intervals are the source of much
confusion:</p>
<ul class="simple">
<li><p>People often confuse standard error and standard deviation. Remember
that standard deviation describes variability in a measured
quantity; in this example, the standard deviation of gorilla weight
is 7.5 kg. Standard error describes variability in an estimate. In
this example, the standard error of the mean, based on a sample of 9
measurements, is 2.5 kg.</p></li>
</ul>
<p>One way to remember the difference is that, as sample size
increases, standard error gets smaller; standard deviation does not.</p>
<ul class="simple">
<li><p>People often think that there is a 90% probability that the actual
parameter, <span class="math notranslate nohighlight">\(\mu\)</span>, falls in the 90% confidence interval. Sadly, that
is not true. If you want to make a claim like that, you have to use
Bayesian methods (see my book, <em>Think Bayes</em>).</p></li>
</ul>
<p>The sampling distribution answers a different question: it gives you
a sense of how reliable an estimate is by telling you how much it
would vary if you ran the experiment again.</p>
<p>It is important to remember that confidence intervals and standard
errors only quantify sampling error; that is, error due to measuring
only part of the population. The sampling distribution does not account
for other sources of error, notably sampling bias and measurement error,
which are the topics of the next section.</p>
</section>
<section id="sampling-bias">
<h2>Sampling bias<a class="headerlink" href="#sampling-bias" title="Link to this heading">#</a></h2>
<p>Suppose that instead of the weight of gorillas in a nature preserve, you
want to know the average weight of women in the city where you live. It
is unlikely that you would be allowed to choose a representative sample
of women and weigh them.</p>
<p>A simple alternative would be “telephone sampling;” that is, you could
choose random numbers from the phone book, call and ask to speak to an
adult woman, and ask how much she weighs.</p>
<p>Telephone sampling has obvious limitations. For example, the sample is
limited to people whose telephone numbers are listed, so it eliminates
people without phones (who might be poorer than average) and people with
unlisted numbers (who might be richer). Also, if you call home
telephones during the day, you are less likely to sample people with
jobs. And if you only sample the person who answers the phone, you are
less likely to sample people who share a phone line.</p>
<p>If factors like income, employment, and household size are related to
weight—and it is plausible that they are—the results of your survey
would be affected one way or another. This problem is called <strong>sampling
bias</strong> because it is a property of the sampling process.</p>
<p>This sampling process is also vulnerable to self-selection, which is a
kind of sampling bias. Some people will refuse to answer the question,
and if the tendency to refuse is related to weight, that would affect
the results.</p>
<p>Finally, if you ask people how much they weigh, rather than weighing
them, the results might not be accurate. Even helpful respondents might
round up or down if they are uncomfortable with their actual weight. And
not all respondents are helpful. These inaccuracies are examples of
<strong>measurement error</strong>.</p>
<p>When you report an estimated quantity, it is useful to report standard
error, or a confidence interval, or both, in order to quantify sampling
error. But it is also important to remember that sampling error is only
one source of error, and often it is not the biggest.</p>
</section>
<section id="exponential-distributions">
<h2>Exponential distributions<a class="headerlink" href="#exponential-distributions" title="Link to this heading">#</a></h2>
<p>Let’s play one more round of the estimation game. <em>I’m thinking of a
distribution.</em> It’s an exponential distribution, and here’s a sample:</p>
<p><code class="docutils literal notranslate"><span class="pre">[5.384,</span> <span class="pre">4.493,</span> <span class="pre">19.198,</span> <span class="pre">2.790,</span> <span class="pre">6.122,</span> <span class="pre">12.844]</span></code></p>
<p>What do you think is the parameter, <span class="math notranslate nohighlight">\(\lambda\)</span>, of this distribution?</p>
<p>In general, the mean of an exponential distribution is <span class="math notranslate nohighlight">\(1/\lambda\)</span>, so
working backwards, we might choose $<span class="math notranslate nohighlight">\(L= 1 / \bar{x}\)</span><span class="math notranslate nohighlight">\( \)</span>L<span class="math notranslate nohighlight">\( is an estimator
of \)</span>\lambda<span class="math notranslate nohighlight">\(. And not just any estimator; it is also the maximum
likelihood estimator (see
&lt;http://wikipedia.org/wiki/Exponential_distribution#Maximum_likelihood&gt;).
So if you want to maximize your chance of guessing \)</span>\lambda<span class="math notranslate nohighlight">\( exactly,
\)</span>L$ is the way to go.</p>
<p>But we know that <span class="math notranslate nohighlight">\(\bar{x}\)</span> is not robust in the presence of outliers, so
we expect <span class="math notranslate nohighlight">\(L\)</span> to have the same problem.</p>
<p>We can choose an alternative based on the sample median. The median of
an exponential distribution is <span class="math notranslate nohighlight">\(\ln(2) / \lambda\)</span>, so working backwards
again, we can define an estimator $<span class="math notranslate nohighlight">\(L_m= \ln(2) / m\)</span><span class="math notranslate nohighlight">\( where \)</span>m$ is the
sample median.</p>
<p>To test the performance of these estimators, we can simulate the
sampling process:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">Estimate3</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">lam</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="n">means</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">medians</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="n">lam</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
        <span class="n">L</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
        <span class="n">Lm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">thinkstats2</span><span class="o">.</span><span class="n">Median</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
        <span class="n">means</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
        <span class="n">medians</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Lm</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;rmse L&#39;</span><span class="p">,</span> <span class="n">RMSE</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">lam</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;rmse Lm&#39;</span><span class="p">,</span> <span class="n">RMSE</span><span class="p">(</span><span class="n">medians</span><span class="p">,</span> <span class="n">lam</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mean error L&#39;</span><span class="p">,</span> <span class="n">MeanError</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">lam</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mean error Lm&#39;</span><span class="p">,</span> <span class="n">MeanError</span><span class="p">(</span><span class="n">medians</span><span class="p">,</span> <span class="n">lam</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>When I run this experiment with <span class="math notranslate nohighlight">\(\lambda=2\)</span>, the RMSE of <span class="math notranslate nohighlight">\(L\)</span> is 1.1. For
the median-based estimator <span class="math notranslate nohighlight">\(L_m\)</span>, RMSE is 1.8. We can’t tell from this
experiment whether <span class="math notranslate nohighlight">\(L\)</span> minimizes MSE, but at least it seems better than
<span class="math notranslate nohighlight">\(L_m\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Estimate3</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>rmse L 1.1170197988041468
rmse Lm 1.7766765260102633
mean error L 0.36424219588529966
mean error Lm 0.5135627068422906
</pre></div>
</div>
</div>
</div>
<p>Sadly, it seems that both estimators are biased. For <span class="math notranslate nohighlight">\(L\)</span> the mean error
is 0.33; for <span class="math notranslate nohighlight">\(L_m\)</span> it is 0.45. And neither converges to 0 as <code class="docutils literal notranslate"><span class="pre">m</span></code>
increases.</p>
<p>It turns out that <span class="math notranslate nohighlight">\(\bar{x}\)</span> is an unbiased estimator of the mean of the
distribution, <span class="math notranslate nohighlight">\(1 / \lambda\)</span>, but <span class="math notranslate nohighlight">\(L\)</span> is not an unbiased estimator of
<span class="math notranslate nohighlight">\(\lambda\)</span>.</p>
</section>
<section id="glossary">
<h2>Glossary<a class="headerlink" href="#glossary" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>estimation</strong>: The process of inferring the parameters of a
distribution from a sample.</p></li>
<li><p><strong>estimator</strong>: A statistic used to estimate a parameter.</p></li>
<li><p><strong>mean squared error (MSE)</strong>: A measure of estimation error.</p></li>
<li><p><strong>root mean squared error (RMSE)</strong>: The square root of MSE, a more
meaningful representation of typical error magnitude.</p></li>
<li><p><strong>maximum likelihood estimator (MLE)</strong>: An estimator that computes
the point estimate most likely to be correct.</p></li>
<li><p><strong>bias (of an estimator)</strong>: The tendency of an estimator to be above
or below the actual value of the parameter, when averaged over
repeated experiments.</p></li>
<li><p><strong>sampling error</strong>: Error in an estimate due to the limited size of
the sample and variation due to chance.</p></li>
<li><p><strong>sampling bias</strong>: Error in an estimate due to a sampling process
that is not representative of the population.</p></li>
<li><p><strong>measurement error</strong>: Error in an estimate due to inaccuracy
collecting or recording data.</p></li>
<li><p><strong>sampling distribution</strong>: The distribution of a statistic if an
experiment is repeated many times.</p></li>
<li><p><strong>standard error</strong>: The RMSE of an estimate, which quantifies
variability due to sampling error (but not other sources of error).</p></li>
<li><p><strong>confidence interval</strong>: An interval that represents the expected
range of an estimator if an experiment is repeated many times.</p></li>
</ul>
</section>
<section id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<p><strong>Exercise:</strong> Suppose you draw a sample with size n=10 from an exponential distribution with λ=2. Simulate this experiment 1000 times and plot the sampling distribution of the estimate L. Compute the standard error of the estimate and the 90% confidence interval.</p>
<p>Repeat the experiment with a few different values of <code class="docutils literal notranslate"><span class="pre">n</span></code> and make a plot of standard error versus <code class="docutils literal notranslate"><span class="pre">n</span></code>.</p>
<p><strong>Exercise:</strong> In games like hockey and soccer, the time between goals is roughly exponential. So you could estimate a team’s goal-scoring rate by observing the number of goals they score in a game. This estimation process is a little different from sampling the time between goals, so let’s see how it works.</p>
<p>Write a function that takes a goal-scoring rate, <code class="docutils literal notranslate"><span class="pre">lam</span></code>, in goals per game, and simulates a game by generating the time between goals until the total time exceeds 1 game, then returns the number of goals scored.</p>
<p>Write another function that simulates many games, stores the estimates of <code class="docutils literal notranslate"><span class="pre">lam</span></code>, then computes their mean error and RMSE.</p>
<p>Is this way of making an estimate biased?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">SimulateGame</span><span class="p">(</span><span class="n">lam</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Simulates a game and returns the estimated goal-scoring rate.</span>

<span class="sd">    lam: actual goal scoring rate in goals per game</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">goals</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">t</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">time_between_goals</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">expovariate</span><span class="p">(</span><span class="n">lam</span><span class="p">)</span>
        <span class="n">t</span> <span class="o">+=</span> <span class="n">time_between_goals</span>
        <span class="k">if</span> <span class="n">t</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">goals</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># estimated goal-scoring rate is the actual number of goals scored</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">goals</span>
    <span class="k">return</span> <span class="n">L</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise:</strong>  In this chapter we used <span class="math notranslate nohighlight">\(\bar{x}\)</span> and median to estimate µ, and found that <span class="math notranslate nohighlight">\(\bar{x}\)</span> yields lower MSE. Also, we used <span class="math notranslate nohighlight">\(S^2\)</span> and <span class="math notranslate nohighlight">\(S_{n-1}^2\)</span> to estimate σ, and found that <span class="math notranslate nohighlight">\(S^2\)</span> is biased and <span class="math notranslate nohighlight">\(S_{n-1}^2\)</span> unbiased.
Run similar experiments to see if <span class="math notranslate nohighlight">\(\bar{x}\)</span> and median are biased estimates of µ. Also check whether <span class="math notranslate nohighlight">\(S^2\)</span> or <span class="math notranslate nohighlight">\(S_{n-1}^2\)</span> yields a lower MSE.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="chap07.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Relationships between variables</p>
      </div>
    </a>
    <a class="right-next"
       href="chap09.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Hypothesis testing</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-estimation-game">The estimation game</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#guess-the-variance">Guess the variance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-distributions">Sampling distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-bias">Sampling bias</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exponential-distributions">Exponential distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glossary">Glossary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Allen B. Downey
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>