
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Regression &#8212; Think Stats, 3rd edition</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]]}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chap11';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Time series analysis" href="chap12.html" />
    <link rel="prev" title="Linear least squares" href="chap10.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
  
    <p class="title logo__title">Think Stats, 3rd edition</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="index.html">
                    Think Stats, 3rd edition
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="chap00.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap01.html">Exploratory data analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap02.html">Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap03.html">Probability mass functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap04.html">Cumulative distribution functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap05.html">Modeling distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap06.html">Probability density functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap07.html">Relationships between variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap08.html">Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap09.html">Hypothesis testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap10.html">Linear least squares</a></li>

<li class="toctree-l1 current active"><a class="current reference internal" href="#">Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap12.html">Time series analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap13.html">Survival analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap14.html">Analytic methods</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/AllenDowney/ThinkStats/tree/v3" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/chap11.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Regression</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statsmodels">StatsModels</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-regression">Multiple regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nonlinear-relationships">Nonlinear relationships</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-mining">Data mining</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prediction">Prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression">Logistic regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-parameters">Estimating parameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#accuracy">Accuracy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glossary">Glossary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="regression">
<h1>Regression<a class="headerlink" href="#regression" title="Link to this heading">#</a></h1>
<div class="cell tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">basename</span><span class="p">,</span> <span class="n">exists</span>


<span class="k">def</span> <span class="nf">download</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="n">basename</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">urllib.request</span> <span class="kn">import</span> <span class="n">urlretrieve</span>

        <span class="n">local</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Downloaded &quot;</span> <span class="o">+</span> <span class="n">local</span><span class="p">)</span>


<span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats/raw/v3/nb/thinkstats2.py&quot;</span><span class="p">)</span>
<span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats/raw/v3/nb/thinkplot.py&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 2;
                var nbb_unformatted_code = "from os.path import basename, exists\n\n\ndef download(url):\n    filename = basename(url)\n    if not exists(filename):\n        from urllib.request import urlretrieve\n        local, _ = urlretrieve(url, filename)\n        print('Downloaded ' + local)\n\n\ndownload(\n    'https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkstats2.py'\n    )\ndownload(\n    'https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkplot.py')";
                var nbb_formatted_code = "from os.path import basename, exists\n\n\ndef download(url):\n    filename = basename(url)\n    if not exists(filename):\n        from urllib.request import urlretrieve\n\n        local, _ = urlretrieve(url, filename)\n        print(\"Downloaded \" + local)\n\n\ndownload(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkstats2.py\")\ndownload(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkplot.py\")";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">thinkstats2</span>
<span class="kn">import</span> <span class="nn">thinkplot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 3;
                var nbb_unformatted_code = "import numpy as np\nimport pandas as pd\nimport thinkstats2\nimport thinkplot";
                var nbb_formatted_code = "import numpy as np\nimport pandas as pd\nimport thinkstats2\nimport thinkplot";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>The linear least squares fit in the previous chapter is an example of
<strong>regression</strong>, which is the more general problem of fitting any kind of
model to any kind of data. This use of the term “regression” is a
historical accident; it is only indirectly related to the original
meaning of the word.</p>
<p>The goal of regression analysis is to describe the relationship between
one set of variables, called the <strong>dependent variables</strong>, and another
set of variables, called independent or <strong>explanatory variables</strong>.</p>
<p>In the previous chapter we used mother’s age as an explanatory variable
to predict birth weight as a dependent variable. When there is only one
dependent and one explanatory variable, that’s <strong>simple regression</strong>. In
this chapter, we move on to <strong>multiple regression</strong>, with more than one
explanatory variable. If there is more than one dependent variable,
that’s multivariate regression.</p>
<p>If the relationship between the dependent and explanatory variable is
linear, that’s <strong>linear regression</strong>. For example, if the dependent
variable is <span class="math notranslate nohighlight">\(y\)</span> and the explanatory variables are <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span>, we
would write the following linear regression model:</p>
<div class="math notranslate nohighlight">
\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon\]</div>
<p>where <span class="math notranslate nohighlight">\(\beta_0\)</span> is
the intercept, <span class="math notranslate nohighlight">\(\beta_1\)</span> is the parameter associated with <span class="math notranslate nohighlight">\(x_1\)</span>,
<span class="math notranslate nohighlight">\(\beta_2\)</span> is the parameter associated with <span class="math notranslate nohighlight">\(x_2\)</span>, and <span class="math notranslate nohighlight">\(\epsilon\)</span> is the
residual due to random variation or other unknown factors.</p>
<p>Given a sequence of values for <span class="math notranslate nohighlight">\(y\)</span> and sequences for <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span>, we
can find the parameters, <span class="math notranslate nohighlight">\(\beta_0\)</span>, <span class="math notranslate nohighlight">\(\beta_1\)</span>, and <span class="math notranslate nohighlight">\(\beta_2\)</span>, that
minimize the sum of <span class="math notranslate nohighlight">\(\epsilon^2\)</span>. This process is called <strong>ordinary least
squares</strong>. The computation is similar to <code class="docutils literal notranslate"><span class="pre">thinkstats2.LeastSquare</span></code>, but
generalized to deal with more than one explanatory variable. You can
find the details at
<a class="reference external" href="https://en.wikipedia.org/wiki/Ordinary_least_squares">https://en.wikipedia.org/wiki/Ordinary_least_squares</a></p>
<section id="statsmodels">
<h2>StatsModels<a class="headerlink" href="#statsmodels" title="Link to this heading">#</a></h2>
<p>In the previous chapter I presented <code class="docutils literal notranslate"><span class="pre">thinkstats2.LeastSquares</span></code>, an
implementation of simple linear regression intended to be easy to read.
For multiple regression we’ll switch to StatsModels, a Python package
that provides several forms of regression and other analyses. If you are
using Anaconda, you already have StatsModels; otherwise you might have
to install it.</p>
<p>As an example, I’ll run the model from the previous chapter with
StatsModels:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats/raw/v3/nb/nsfg.py&quot;</span><span class="p">)</span>
<span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats/raw/v3/nb/2002FemPreg.dct&quot;</span><span class="p">)</span>
<span class="n">download</span><span class="p">(</span>
    <span class="s2">&quot;https://github.com/AllenDowney/ThinkStats/raw/v3/nb/2002FemPreg.dat.gz&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 4;
                var nbb_unformatted_code = "download('https://github.com/AllenDowney/ThinkStats2/raw/master/code/nsfg.py')\ndownload(\n    'https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemPreg.dct'\n    )\ndownload(\n    'https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemPreg.dat.gz'\n    )";
                var nbb_formatted_code = "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/nsfg.py\")\ndownload(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemPreg.dct\")\ndownload(\n    \"https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemPreg.dat.gz\"\n)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nsfg</span>

<span class="n">live</span><span class="p">,</span> <span class="n">firsts</span><span class="p">,</span> <span class="n">others</span> <span class="o">=</span> <span class="n">nsfg</span><span class="o">.</span><span class="n">make_frames</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 5;
                var nbb_unformatted_code = "import nsfg\nlive, firsts, others = nsfg.make_frames()";
                var nbb_formatted_code = "import nsfg\n\nlive, firsts, others = nsfg.make_frames()";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="n">formula</span> <span class="o">=</span> <span class="s2">&quot;totalwgt_lb ~ agepreg&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">live</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 6;
                var nbb_unformatted_code = "import statsmodels.formula.api as smf\nformula = 'totalwgt_lb ~ agepreg'\nmodel = smf.ols(formula, data=live)\nresults = model.fit()";
                var nbb_formatted_code = "import statsmodels.formula.api as smf\n\nformula = \"totalwgt_lb ~ agepreg\"\nmodel = smf.ols(formula, data=live)\nresults = model.fit()";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> provides two interfaces (APIs); the “formula” API uses
strings to identify the dependent and explanatory variables. It uses a
syntax called <code class="docutils literal notranslate"><span class="pre">patsy</span></code>; in this example, the <code class="docutils literal notranslate"><span class="pre">~</span></code> operator separates the
dependent variable on the left from the explanatory variables on the
right.</p>
<p><code class="docutils literal notranslate"><span class="pre">smf.ols</span></code> takes the formula string and the DataFrame, <code class="docutils literal notranslate"><span class="pre">live</span></code>, and
returns an OLS object that represents the model. The name <code class="docutils literal notranslate"><span class="pre">ols</span></code> stands
for “ordinary least squares.”</p>
<p>The <code class="docutils literal notranslate"><span class="pre">fit</span></code> method fits the model to the data and returns a
RegressionResults object that contains the results.</p>
<p>The results are also available as attributes. <code class="docutils literal notranslate"><span class="pre">params</span></code> is a Series that
maps from variable names to their parameters, so we can get the
intercept and slope like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inter</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;Intercept&quot;</span><span class="p">]</span>
<span class="n">slope</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;agepreg&quot;</span><span class="p">]</span>
<span class="n">inter</span><span class="p">,</span> <span class="n">slope</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(6.830396973311051, 0.017453851471802638)
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 7;
                var nbb_unformatted_code = "inter = results.params['Intercept']\nslope = results.params['agepreg']\ninter, slope";
                var nbb_formatted_code = "inter = results.params[\"Intercept\"]\nslope = results.params[\"agepreg\"]\ninter, slope";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>The estimated parameters are 6.83 and 0.0175, the same as from
<code class="docutils literal notranslate"><span class="pre">LeastSquares</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">pvalues</span></code> is a Series that maps from variable names to the associated
p-values, so we can check whether the estimated slope is statistically
significant:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">slope_pvalue</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">pvalues</span><span class="p">[</span><span class="s2">&quot;agepreg&quot;</span><span class="p">]</span>
<span class="n">slope_pvalue</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5.7229471073163425e-11
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 8;
                var nbb_unformatted_code = "slope_pvalue = results.pvalues['agepreg']\nslope_pvalue";
                var nbb_formatted_code = "slope_pvalue = results.pvalues[\"agepreg\"]\nslope_pvalue";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">rsquared</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.004738115474710369
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 9;
                var nbb_unformatted_code = "results.rsquared";
                var nbb_formatted_code = "results.rsquared";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>The p-value associated with <code class="docutils literal notranslate"><span class="pre">agepreg</span></code> is <code class="docutils literal notranslate"><span class="pre">5.7e-11</span></code>, which is less than
<span class="math notranslate nohighlight">\(0.001\)</span>, as expected.</p>
<p><code class="docutils literal notranslate"><span class="pre">results.rsquared</span></code> contains <span class="math notranslate nohighlight">\(R^2\)</span>, which is <span class="math notranslate nohighlight">\(0.0047\)</span>. <code class="docutils literal notranslate"><span class="pre">results</span></code> also
provides <code class="docutils literal notranslate"><span class="pre">f_pvalue</span></code>, which is the p-value associated with the model as a
whole, similar to testing whether <span class="math notranslate nohighlight">\(R^2\)</span> is statistically significant.</p>
<p>And <code class="docutils literal notranslate"><span class="pre">results</span></code> provides <code class="docutils literal notranslate"><span class="pre">resid</span></code>, a sequence of residuals, and
<code class="docutils literal notranslate"><span class="pre">fittedvalues</span></code>, a sequence of fitted values corresponding to <code class="docutils literal notranslate"><span class="pre">agepreg</span></code>.</p>
<p>The results object provides <code class="docutils literal notranslate"><span class="pre">summary()</span></code>, which represents the results in
a readable format.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>       <td>totalwgt_lb</td>   <th>  R-squared:         </th> <td>   0.005</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.005</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   43.02</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Tue, 18 Jun 2024</td> <th>  Prob (F-statistic):</th> <td>5.72e-11</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>14:57:21</td>     <th>  Log-Likelihood:    </th> <td> -15897.</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td>  9038</td>      <th>  AIC:               </th> <td>3.180e+04</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>  9036</td>      <th>  BIC:               </th> <td>3.181e+04</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>    6.8304</td> <td>    0.068</td> <td>  100.470</td> <td> 0.000</td> <td>    6.697</td> <td>    6.964</td>
</tr>
<tr>
  <th>agepreg</th>   <td>    0.0175</td> <td>    0.003</td> <td>    6.559</td> <td> 0.000</td> <td>    0.012</td> <td>    0.023</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>1024.052</td> <th>  Durbin-Watson:     </th> <td>   1.618</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3081.833</td>
</tr>
<tr>
  <th>Skew:</th>           <td>-0.601</td>  <th>  Prob(JB):          </th> <td>    0.00</td>
</tr>
<tr>
  <th>Kurtosis:</th>       <td> 5.596</td>  <th>  Cond. No.          </th> <td>    118.</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div><script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 10;
                var nbb_unformatted_code = "results.summary()";
                var nbb_formatted_code = "results.summary()";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>But it prints a lot of information that is not relevant (yet), so I use
a simpler function called <code class="docutils literal notranslate"><span class="pre">SummarizeResults</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">thinkstats2</span> <span class="kn">import</span> <span class="n">summarize_results</span>

<span class="n">summarize_results</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   6.83   (0)
agepreg   0.0175   (5.72e-11)
R^2 0.004738
Std(ys) 1.408
Std(res) 1.405
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 12;
                var nbb_unformatted_code = "from thinkstats2 import summarize_results\n\nsummarize_results(results)";
                var nbb_formatted_code = "from thinkstats2 import summarize_results\n\nsummarize_results(results)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">Std(ys)</span></code> is the standard deviation of the dependent variable, which is
the RMSE if you have to guess birth weights without the benefit of any
explanatory variables. <code class="docutils literal notranslate"><span class="pre">Std(res)</span></code> is the standard deviation of the
residuals, which is the RMSE if your guesses are informed by the
mother’s age. As we have already seen, knowing the mother’s age provides
no substantial improvement to the predictions.</p>
</section>
<section id="multiple-regression">
<h2>Multiple regression<a class="headerlink" href="#multiple-regression" title="Link to this heading">#</a></h2>
<p>In Section <a class="reference internal" href="#birth_weights"><span class="xref myst">[birth_weights]</span></a>{reference-type=“ref”
reference=“birth_weights”} we saw that first babies tend to be lighter
than others, and this effect is statistically significant. But it is a
strange result because there is no obvious mechanism that would cause
first babies to be lighter. So we might wonder whether this relationship
is <strong>spurious</strong>.</p>
<p>In fact, there is a possible explanation for this effect. We have seen
that birth weight depends on mother’s age, and we might expect that
mothers of first babies are younger than others.</p>
<p>With a few calculations we can check whether this explanation is
plausible. Then we’ll use multiple regression to investigate more
carefully. First, let’s see how big the difference in weight is:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">diff_weight</span> <span class="o">=</span> <span class="n">firsts</span><span class="o">.</span><span class="n">totalwgt_lb</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">others</span><span class="o">.</span><span class="n">totalwgt_lb</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">diff_weight</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.12476118453549034
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 13;
                var nbb_unformatted_code = "diff_weight = firsts.totalwgt_lb.mean() - others.totalwgt_lb.mean()\ndiff_weight";
                var nbb_formatted_code = "diff_weight = firsts.totalwgt_lb.mean() - others.totalwgt_lb.mean()\ndiff_weight";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>First babies are 0.125 lbs lighter, or 2 ounces. And the difference in
ages:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">diff_age</span> <span class="o">=</span> <span class="n">firsts</span><span class="o">.</span><span class="n">agepreg</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">others</span><span class="o">.</span><span class="n">agepreg</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">diff_age</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-3.5864347661500275
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 14;
                var nbb_unformatted_code = "diff_age = firsts.agepreg.mean() - others.agepreg.mean()\ndiff_age";
                var nbb_formatted_code = "diff_age = firsts.agepreg.mean() - others.agepreg.mean()\ndiff_age";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>The mothers of first babies are 3.59 years younger. Running the linear
model again, we get the change in birth weight as a function of age:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s2">&quot;totalwgt_lb ~ agepreg&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">live</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">slope</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;agepreg&quot;</span><span class="p">]</span>
<span class="n">slope</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.017453851471802638
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 15;
                var nbb_unformatted_code = "results = smf.ols('totalwgt_lb ~ agepreg', data=live).fit()\nslope = results.params['agepreg']\nslope";
                var nbb_formatted_code = "results = smf.ols(\"totalwgt_lb ~ agepreg\", data=live).fit()\nslope = results.params[\"agepreg\"]\nslope";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>The slope is 0.0175 pounds per year. If we multiply the slope by the
difference in ages, we get the expected difference in birth weight for
first babies and others, due to mother’s age:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">slope</span> <span class="o">*</span> <span class="n">diff_age</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.0625970997216918
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 16;
                var nbb_unformatted_code = "slope * diff_age";
                var nbb_formatted_code = "slope * diff_age";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>The result is 0.063, just about half of the observed difference. So we
conclude, tentatively, that the observed difference in birth weight can
be partly explained by the difference in mother’s age.</p>
<p>Using multiple regression, we can explore these relationships more
systematically.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">live</span><span class="p">[</span><span class="s2">&quot;isfirst&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">live</span><span class="o">.</span><span class="n">birthord</span> <span class="o">==</span> <span class="mi">1</span>
<span class="n">formula</span> <span class="o">=</span> <span class="s2">&quot;totalwgt_lb ~ isfirst&quot;</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">live</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 17;
                var nbb_unformatted_code = "live['isfirst'] = live.birthord == 1\nformula = 'totalwgt_lb ~ isfirst'\nresults = smf.ols(formula, data=live).fit()";
                var nbb_formatted_code = "live[\"isfirst\"] = live.birthord == 1\nformula = \"totalwgt_lb ~ isfirst\"\nresults = smf.ols(formula, data=live).fit()";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>The first line creates a new column named <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> that is True for
first babies and false otherwise. Then we fit a model using <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> as
an explanatory variable.</p>
<p>Here are the results:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summarize_results</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   7.33   (0)
isfirst[T.True]   -0.125   (2.55e-05)
R^2 0.00196
Std(ys) 1.408
Std(res) 1.407
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 18;
                var nbb_unformatted_code = "summarize_results(results)";
                var nbb_formatted_code = "summarize_results(results)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>Because <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> is a boolean, <code class="docutils literal notranslate"><span class="pre">ols</span></code> treats it as a <strong>categorical
variable</strong>, which means that the values fall into categories, like True
and False, and should not be treated as numbers. The estimated parameter
is the effect on birth weight when <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> is true, so the result,
-0.125 lbs, is the difference in birth weight between first babies and
others.</p>
<p>The slope and the intercept are statistically significant, which means
that they were unlikely to occur by chance, but the the <span class="math notranslate nohighlight">\(R^2\)</span> value for
this model is small, which means that <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> doesn’t account for a
substantial part of the variation in birth weight.</p>
<p>The results are similar with <code class="docutils literal notranslate"><span class="pre">agepreg</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="s2">&quot;totalwgt_lb ~ agepreg&quot;</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">live</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">summarize_results</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   6.83   (0)
agepreg   0.0175   (5.72e-11)
R^2 0.004738
Std(ys) 1.408
Std(res) 1.405
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 19;
                var nbb_unformatted_code = "formula = 'totalwgt_lb ~ agepreg'\nresults = smf.ols(formula, data=live).fit()\nsummarize_results(results)";
                var nbb_formatted_code = "formula = \"totalwgt_lb ~ agepreg\"\nresults = smf.ols(formula, data=live).fit()\nsummarize_results(results)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>Again, the parameters are statistically significant, but <span class="math notranslate nohighlight">\(R^2\)</span> is low.</p>
<p>These models confirm results we have already seen. But now we can fit a
single model that includes both variables. With the formula
<code class="docutils literal notranslate"><span class="pre">totalwgt_lb</span> <span class="pre">~</span> <span class="pre">isfirst</span> <span class="pre">+</span> <span class="pre">agepreg</span></code>, we get:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="s2">&quot;totalwgt_lb ~ isfirst + agepreg&quot;</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">live</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">summarize_results</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   6.91   (0)
isfirst[T.True]   -0.0698   (0.0253)
agepreg   0.0154   (3.93e-08)
R^2 0.005289
Std(ys) 1.408
Std(res) 1.405
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 20;
                var nbb_unformatted_code = "formula = 'totalwgt_lb ~ isfirst + agepreg'\nresults = smf.ols(formula, data=live).fit()\nsummarize_results(results)";
                var nbb_formatted_code = "formula = \"totalwgt_lb ~ isfirst + agepreg\"\nresults = smf.ols(formula, data=live).fit()\nsummarize_results(results)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>In the combined model, the parameter for <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> is smaller by about
half, which means that part of the apparent effect of <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> is
actually accounted for by <code class="docutils literal notranslate"><span class="pre">agepreg</span></code>. And the p-value for <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> is
about 2.5%, which is on the border of statistical significance.</p>
<p><span class="math notranslate nohighlight">\(R^2\)</span> for this model is a little higher, which indicates that the two
variables together account for more variation in birth weight than
either alone (but not by much).</p>
</section>
<section id="nonlinear-relationships">
<h2>Nonlinear relationships<a class="headerlink" href="#nonlinear-relationships" title="Link to this heading">#</a></h2>
<p>Remembering that the contribution of <code class="docutils literal notranslate"><span class="pre">agepreg</span></code> might be nonlinear, we
might consider adding a variable to capture more of this relationship.
One option is to create a column, <code class="docutils literal notranslate"><span class="pre">agepreg2</span></code>, that contains the squares
of the ages:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">live</span><span class="p">[</span><span class="s2">&quot;agepreg2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">live</span><span class="o">.</span><span class="n">agepreg</span><span class="o">**</span><span class="mi">2</span>
<span class="n">formula</span> <span class="o">=</span> <span class="s2">&quot;totalwgt_lb ~ isfirst + agepreg + agepreg2&quot;</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">live</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 21;
                var nbb_unformatted_code = "live['agepreg2'] = live.agepreg ** 2\nformula = 'totalwgt_lb ~ isfirst + agepreg + agepreg2'\nresults = smf.ols(formula, data=live).fit()";
                var nbb_formatted_code = "live[\"agepreg2\"] = live.agepreg**2\nformula = \"totalwgt_lb ~ isfirst + agepreg + agepreg2\"\nresults = smf.ols(formula, data=live).fit()";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>Now by estimating parameters for <code class="docutils literal notranslate"><span class="pre">agepreg</span></code> and <code class="docutils literal notranslate"><span class="pre">agepreg2</span></code>, we are
effectively fitting a parabola:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summarize_results</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   5.69   (1.38e-86)
isfirst[T.True]   -0.0504   (0.109)
agepreg   0.112   (3.23e-07)
agepreg2   -0.00185   (8.8e-06)
R^2 0.007462
Std(ys) 1.408
Std(res) 1.403
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 22;
                var nbb_unformatted_code = "summarize_results(results)";
                var nbb_formatted_code = "summarize_results(results)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>The parameter of <code class="docutils literal notranslate"><span class="pre">agepreg2</span></code> is negative, so the parabola curves
downward, which is consistent with the shape of the lines in
Figure <a class="reference internal" href="#linear2"><span class="xref myst">[linear2]</span></a>{reference-type=“ref”
reference=“linear2”}.</p>
<p>The quadratic model of <code class="docutils literal notranslate"><span class="pre">agepreg</span></code> accounts for more of the variability in
birth weight; the parameter for <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> is smaller in this model, and
no longer statistically significant.</p>
<p>Using computed variables like <code class="docutils literal notranslate"><span class="pre">agepreg2</span></code> is a common way to fit
polynomials and other functions to data. This process is still
considered linear regression, because the dependent variable is a linear
function of the explanatory variables, regardless of whether some
variables are nonlinear functions of others.</p>
<p>The following table summarizes the results of these regressions:</p>
<p>center
isfirst        agepreg     agepreg2     <span class="math notranslate nohighlight">\(R^2\)</span></p>
<hr class="docutils" />
<p>Model 1       -0.125 *         –           –        0.002
Model 2          –          0.0175 *       –        0.0047
Model 3    -0.0698 (0.025)   0.0154 *       –        0.0053
Model 4    -0.0504 (0.11)    0.112 *    -0.00185 *   0.0075</p>
<p>The columns in this table are the explanatory variables and the
coefficient of determination, <span class="math notranslate nohighlight">\(R^2\)</span>. Each entry is an estimated
parameter and either a p-value in parentheses or an asterisk to indicate
a p-value less that 0.001.</p>
<p>We conclude that the apparent difference in birth weight is explained,
at least in part, by the difference in mother’s age. When we include
mother’s age in the model, the effect of <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> gets smaller, and the
remaining effect might be due to chance.</p>
<p>In this example, mother’s age acts as a <strong>control variable</strong>; including
<code class="docutils literal notranslate"><span class="pre">agepreg</span></code> in the model “controls for” the difference in age between
first-time mothers and others, making it possible to isolate the effect
(if any) of <code class="docutils literal notranslate"><span class="pre">isfirst</span></code>.</p>
</section>
<section id="data-mining">
<h2>Data mining<a class="headerlink" href="#data-mining" title="Link to this heading">#</a></h2>
<p>So far we have used regression models for explanation; for example, in
the previous section we discovered that an apparent difference in birth
weight is actually due to a difference in mother’s age. But the <span class="math notranslate nohighlight">\(R^2\)</span>
values of those models is very low, which means that they have little
predictive power. In this section we’ll try to do better.</p>
<p>Suppose one of your co-workers is expecting a baby and there is an
office pool to guess the baby’s birth weight (if you are not familiar
with betting pools, see <a class="reference external" href="https://en.wikipedia.org/wiki/Betting_pool">https://en.wikipedia.org/wiki/Betting_pool</a>).</p>
<p>Now suppose that you <em>really</em> want to win the pool. What could you do to
improve your chances? Well, the NSFG dataset includes 244 variables
about each pregnancy and another 3087 variables about each respondent.
Maybe some of those variables have predictive power. To find out which
ones are most useful, why not try them all?</p>
<p>Testing the variables in the pregnancy table is easy, but in order to
use the variables in the respondent table, we have to match up each
pregnancy with a respondent. In theory we could iterate through the rows
of the pregnancy table, use the <code class="docutils literal notranslate"><span class="pre">caseid</span></code> to find the corresponding
respondent, and copy the values from the correspondent table into the
pregnancy table. But that would be slow.</p>
<p>A better option is to recognize this process as a <strong>join</strong> operation as
defined in SQL and other relational database languages (see
<a class="reference external" href="https://en.wikipedia.org/wiki/Join_(SQL)">https://en.wikipedia.org/wiki/Join_(SQL)</a>). Join is implemented as a
DataFrame method, so we can perform the operation like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats/raw/v3/nb/2002FemResp.dct&quot;</span><span class="p">)</span>
<span class="n">download</span><span class="p">(</span>
    <span class="s2">&quot;https://github.com/AllenDowney/ThinkStats/raw/v3/nb/2002FemResp.dat.gz&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 23;
                var nbb_unformatted_code = "download(\n    'https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemResp.dct'\n    )\ndownload(\n    'https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemResp.dat.gz'\n    )";
                var nbb_formatted_code = "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemResp.dct\")\ndownload(\n    \"https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemResp.dat.gz\"\n)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nsfg</span>

<span class="n">live</span> <span class="o">=</span> <span class="n">live</span><span class="p">[</span><span class="n">live</span><span class="o">.</span><span class="n">prglngth</span> <span class="o">&gt;</span> <span class="mi">30</span><span class="p">]</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">nsfg</span><span class="o">.</span><span class="n">read_fem_resp</span><span class="p">()</span>
<span class="n">resp</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">caseid</span>
<span class="n">join</span> <span class="o">=</span> <span class="n">live</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">resp</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;caseid&quot;</span><span class="p">,</span> <span class="n">rsuffix</span><span class="o">=</span><span class="s2">&quot;_r&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 24;
                var nbb_unformatted_code = "import nsfg\nlive = live[live.prglngth > 30]\nresp = nsfg.read_fem_resp()\nresp.index = resp.caseid\njoin = live.join(resp, on='caseid', rsuffix='_r')";
                var nbb_formatted_code = "import nsfg\n\nlive = live[live.prglngth > 30]\nresp = nsfg.read_fem_resp()\nresp.index = resp.caseid\njoin = live.join(resp, on=\"caseid\", rsuffix=\"_r\")";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>The first line selects records for pregnancies longer than 30 weeks,
assuming that the office pool is formed several weeks before the due
date.</p>
<p>The next line reads the respondent file. The result is a DataFrame with
integer indices; in order to look up respondents efficiently, I replace
<code class="docutils literal notranslate"><span class="pre">resp.index</span></code> with <code class="docutils literal notranslate"><span class="pre">resp.caseid</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">join</span></code> method is invoked on <code class="docutils literal notranslate"><span class="pre">live</span></code>, which is considered the “left”
table, and passed <code class="docutils literal notranslate"><span class="pre">resp</span></code>, which is the “right” table. The keyword
argument <code class="docutils literal notranslate"><span class="pre">on</span></code> indicates the variable used to match up rows from the two
tables.</p>
<p>In this example some column names appear in both tables, so we have to
provide <code class="docutils literal notranslate"><span class="pre">rsuffix</span></code>, which is a string that will be appended to the names
of overlapping columns from the right table. For example, both tables
have a column named <code class="docutils literal notranslate"><span class="pre">race</span></code> that encodes the race of the respondent. The
result of the join contains two columns named <code class="docutils literal notranslate"><span class="pre">race</span></code> and <code class="docutils literal notranslate"><span class="pre">race_r</span></code>.</p>
<p>The Pandas implementation is fast. Joining the NSFG tables takes less
than a second on an ordinary desktop computer. Now we can start testing
variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">join</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">join</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">1e-07</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">formula</span> <span class="o">=</span> <span class="s2">&quot;totalwgt_lb ~ agepreg + &quot;</span> <span class="o">+</span> <span class="n">name</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">join</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">nobs</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">join</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
        <span class="k">continue</span>
    <span class="n">t</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">results</span><span class="o">.</span><span class="n">rsquared</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 25;
                var nbb_unformatted_code = "t = []\nfor name in join.columns:\n    try:\n        if join[name].var() < 1e-07:\n            continue\n        formula = 'totalwgt_lb ~ agepreg + ' + name\n        model = smf.ols(formula, data=join)\n        if model.nobs < len(join) / 2:\n            continue\n        results = model.fit()\n    except (ValueError, TypeError):\n        continue\n    t.append((results.rsquared, name))";
                var nbb_formatted_code = "t = []\nfor name in join.columns:\n    try:\n        if join[name].var() < 1e-07:\n            continue\n        formula = \"totalwgt_lb ~ agepreg + \" + name\n        model = smf.ols(formula, data=join)\n        if model.nobs < len(join) / 2:\n            continue\n        results = model.fit()\n    except (ValueError, TypeError):\n        continue\n    t.append((results.rsquared, name))";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;$R^2$&quot;</span><span class="p">,</span> <span class="s2">&quot;column&quot;</span><span class="p">]</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;$R^2$&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>$R^2$</th>
      <th>column</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>107</th>
      <td>1.000000</td>
      <td>totalwgt_lb</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.949813</td>
      <td>birthwgt_lb</td>
    </tr>
    <tr>
      <th>49</th>
      <td>0.300824</td>
      <td>lbw1</td>
    </tr>
    <tr>
      <th>39</th>
      <td>0.130125</td>
      <td>prglngth</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.123400</td>
      <td>wksgest</td>
    </tr>
    <tr>
      <th>44</th>
      <td>0.102031</td>
      <td>agecon</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.027144</td>
      <td>mosgest</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.018551</td>
      <td>babysex</td>
    </tr>
    <tr>
      <th>62</th>
      <td>0.016200</td>
      <td>race</td>
    </tr>
    <tr>
      <th>517</th>
      <td>0.016200</td>
      <td>race_r</td>
    </tr>
  </tbody>
</table>
</div></div><script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 26;
                var nbb_unformatted_code = "columns = ['$R^2$', 'column']\npd.DataFrame(t, columns=columns).sort_values(by='$R^2$', ascending=False).head(\n    10)";
                var nbb_formatted_code = "columns = [\"$R^2$\", \"column\"]\npd.DataFrame(t, columns=columns).sort_values(by=\"$R^2$\", ascending=False).head(10)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>For each variable we construct a model, compute <span class="math notranslate nohighlight">\(R^2\)</span>, and append the
results to a list. The models all include <code class="docutils literal notranslate"><span class="pre">agepreg</span></code>, since we already
know that it has some predictive power.</p>
<p>I check that each explanatory variable has some variability; otherwise
the results of the regression are unreliable. I also check the number of
observations for each model. Variables that contain a large number of
<code class="docutils literal notranslate"><span class="pre">nan</span></code>s are not good candidates for prediction.</p>
<p>For most of these variables, we haven’t done any cleaning. Some of them
are encoded in ways that don’t work very well for linear regression. As
a result, we might overlook some variables that would be useful if they
were cleaned properly. But maybe we will find some good candidates.</p>
</section>
<section id="prediction">
<h2>Prediction<a class="headerlink" href="#prediction" title="Link to this heading">#</a></h2>
<p>The next step is to sort the results and select the variables that yield
the highest values of <span class="math notranslate nohighlight">\(R^2\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>


<span class="k">def</span> <span class="nf">read_variables</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Reads Stata dictionary files for NSFG data.</span>

<span class="sd">    returns: DataFrame that maps variables names to descriptions</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">vars1</span> <span class="o">=</span> <span class="n">thinkstats2</span><span class="o">.</span><span class="n">read_stata_dct</span><span class="p">(</span><span class="s2">&quot;2002FemPreg.dct&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">variables</span>
    <span class="n">vars2</span> <span class="o">=</span> <span class="n">thinkstats2</span><span class="o">.</span><span class="n">read_stata_dct</span><span class="p">(</span><span class="s2">&quot;2002FemResp.dct&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">variables</span>
    <span class="n">all_vars</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">vars1</span><span class="p">,</span> <span class="n">vars2</span><span class="p">])</span>
    <span class="n">all_vars</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">all_vars</span><span class="o">.</span><span class="n">name</span>
    <span class="k">return</span> <span class="n">all_vars</span>


<span class="k">def</span> <span class="nf">mining_report</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Prints variables with the highest R^2.</span>

<span class="sd">    t: list of (R^2, variable name) pairs</span>
<span class="sd">    n: number of pairs to print</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">all_vars</span> <span class="o">=</span> <span class="n">read_variables</span><span class="p">()</span>
    <span class="n">variables</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">r2</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">[:</span><span class="n">n</span><span class="p">]:</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;_r$&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">desc</span> <span class="o">=</span> <span class="n">all_vars</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">desc</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">desc</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
                <span class="n">desc</span> <span class="o">=</span> <span class="n">desc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">r2</span><span class="p">,</span> <span class="n">desc</span><span class="p">)</span>
        <span class="k">except</span> <span class="p">(</span><span class="ne">KeyError</span><span class="p">,</span> <span class="ne">IndexError</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">r2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 27;
                var nbb_unformatted_code = "import re\n\n\ndef read_variables():\n    \"\"\"Reads Stata dictionary files for NSFG data.\n\n    returns: DataFrame that maps variables names to descriptions\n    \"\"\"\n    vars1 = thinkstats2.read_stata_dct('2002FemPreg.dct').variables\n    vars2 = thinkstats2.read_stata_dct('2002FemResp.dct').variables\n    all_vars = pd.concat([vars1, vars2])\n    all_vars.index = all_vars.name\n    return all_vars\n\n\ndef mining_report(variables, n=30):\n    \"\"\"Prints variables with the highest R^2.\n\n    t: list of (R^2, variable name) pairs\n    n: number of pairs to print\n    \"\"\"\n    all_vars = read_variables()\n    variables.sort(reverse=True)\n    for r2, name in variables[:n]:\n        key = re.sub('_r$', '', name)\n        try:\n            desc = all_vars.loc[key].desc\n            if isinstance(desc, pd.Series):\n                desc = desc[0]\n            print(name, r2, desc)\n        except (KeyError, IndexError):\n            print(name, r2)";
                var nbb_formatted_code = "import re\n\n\ndef read_variables():\n    \"\"\"Reads Stata dictionary files for NSFG data.\n\n    returns: DataFrame that maps variables names to descriptions\n    \"\"\"\n    vars1 = thinkstats2.read_stata_dct(\"2002FemPreg.dct\").variables\n    vars2 = thinkstats2.read_stata_dct(\"2002FemResp.dct\").variables\n    all_vars = pd.concat([vars1, vars2])\n    all_vars.index = all_vars.name\n    return all_vars\n\n\ndef mining_report(variables, n=30):\n    \"\"\"Prints variables with the highest R^2.\n\n    t: list of (R^2, variable name) pairs\n    n: number of pairs to print\n    \"\"\"\n    all_vars = read_variables()\n    variables.sort(reverse=True)\n    for r2, name in variables[:n]:\n        key = re.sub(\"_r$\", \"\", name)\n        try:\n            desc = all_vars.loc[key].desc\n            if isinstance(desc, pd.Series):\n                desc = desc[0]\n            print(name, r2, desc)\n        except (KeyError, IndexError):\n            print(name, r2)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mining_report</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>totalwgt_lb 1.0
birthwgt_lb 0.9498127305978009 BD-3 BIRTHWEIGHT IN POUNDS - 1ST BABY FROM THIS PREGNANCY
lbw1 0.3008240784470769 LOW BIRTHWEIGHT - BABY 1
prglngth 0.13012519488625085 DURATION OF COMPLETED PREGNANCY IN WEEKS
wksgest 0.12340041363361076 GESTATIONAL LENGTH OF COMPLETED PREGNANCY (IN WEEKS)
agecon 0.10203149928156052 AGE AT TIME OF CONCEPTION
mosgest 0.02714427463957958 GESTATIONAL LENGTH OF COMPLETED PREGNANCY (IN MONTHS)
babysex 0.018550925293942533 BD-2 SEX OF 1ST LIVEBORN BABY FROM THIS PREGNANCY
race_r 0.016199503586253106 RACE
race 0.016199503586253106 RACE
nbrnaliv 0.016017752709788113 BC-2 NUMBER OF BABIES BORN ALIVE FROM THIS PREGNANCY
paydu 0.014003795578114597 IB-10 CURRENT LIVING QUARTERS OWNED/RENTED, ETC
rmarout03 0.01343006646571343 INFORMAL MARITAL STATUS WHEN PREGNANCY ENDED - 3RD
birthwgt_oz 0.013102457615706498 BD-3 BIRTHWEIGHT IN OUNCES - 1ST BABY FROM THIS PREGNANCY
anynurse 0.012529022541810653 BH-1 WHETHER R BREASTFED THIS CHILD AT ALL - 1ST FROM THIS PREG
bfeedwks 0.012193688404495417 DURATION OF BREASTFEEDING IN WEEKS
totincr 0.011870069031173158 TOTAL INCOME OF R&#39;S FAMILY
marout03 0.011807801994375033 FORMAL MARITAL STATUS WHEN PREGNANCY ENDED - 3RD
marcon03 0.011752599354395321 FORMAL MARITAL STATUS WHEN PREGNANCY BEGAN - 3RD
cebow 0.011437770919637269 NUMBER OF CHILDREN BORN OUT OF WEDLOCK
rmarout01 0.011407737138640073 INFORMAL MARITAL STATUS WHEN PREGNANCY ENDED - 1ST
rmarout6 0.011354138472805753 INFORMAL MARITAL STATUS AT PREGNANCY OUTCOME - 6 CATEGORIES
marout01 0.011269357246806444 FORMAL MARITAL STATUS WHEN PREGNANCY ENDED - 1ST
hisprace_r 0.01123834930203138 RACE AND HISPANIC ORIGIN
hisprace 0.01123834930203138 RACE AND HISPANIC ORIGIN
mar1diss 0.0109615635907514 MONTHS BTW/1ST MARRIAGE &amp; DISSOLUTION (OR INTERVIEW)
fmarcon5 0.0106049646842995 FORMAL MARITAL STATUS AT CONCEPTION - 5 CATEGORIES
rmarout02 0.010546913206564978 INFORMAL MARITAL STATUS WHEN PREGNANCY ENDED - 2ND
marcon02 0.01048140179553414 FORMAL MARITAL STATUS WHEN PREGNANCY BEGAN - 2ND
fmarout5 0.010461691367377068 FORMAL MARITAL STATUS AT PREGNANCY OUTCOME
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_283807/439348224.py:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  desc = desc[0]
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 28;
                var nbb_unformatted_code = "mining_report(t)";
                var nbb_formatted_code = "mining_report(t)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>The first variable on the list is <code class="docutils literal notranslate"><span class="pre">totalwgt_lb</span></code>, followed by
<code class="docutils literal notranslate"><span class="pre">birthwgt_lb</span></code>. Obviously, we can’t use birth weight to predict birth
weight.</p>
<p>Similarly <code class="docutils literal notranslate"><span class="pre">prglngth</span></code> has useful predictive power, but for the office
pool we assume pregnancy length (and the related variables) are not
known yet.</p>
<p>The first useful predictive variable is <code class="docutils literal notranslate"><span class="pre">babysex</span></code> which indicates
whether the baby is male or female. In the NSFG dataset, boys are about
0.3 lbs heavier. So, assuming that the sex of the baby is known, we can
use it for prediction.</p>
<p>Next is <code class="docutils literal notranslate"><span class="pre">race</span></code>, which indicates whether the respondent is white, black,
or other. As an explanatory variable, race can be problematic. In
datasets like the NSFG, race is correlated with many other variables,
including income and other socioeconomic factors. In a regression model,
race acts as a <strong>proxy variable</strong>, so apparent correlations with race
are often caused, at least in part, by other factors.</p>
<p>The next variable on the list is <code class="docutils literal notranslate"><span class="pre">nbrnaliv</span></code>, which indicates whether the
pregnancy yielded multiple births. Twins and triplets tend to be smaller
than other babies, so if we know whether our hypothetical co-worker is
expecting twins, that would help.</p>
<p>Next on the list is <code class="docutils literal notranslate"><span class="pre">paydu</span></code>, which indicates whether the respondent owns
her home. It is one of several income-related variables that turn out to
be predictive. In datasets like the NSFG, income and wealth are
correlated with just about everything. In this example, income is
related to diet, health, health care, and other factors likely to affect
birth weight.</p>
<p>Some of the other variables on the list are things that would not be
known until later, like <code class="docutils literal notranslate"><span class="pre">bfeedwks</span></code>, the number of weeks the baby was
breast fed. We can’t use these variables for prediction, but you might
want to speculate on reasons <code class="docutils literal notranslate"><span class="pre">bfeedwks</span></code> might be correlated with birth
weight.</p>
<p>Sometimes you start with a theory and use data to test it. Other times
you start with data and go looking for possible theories. The second
approach, which this section demonstrates, is called <strong>data mining</strong>. An
advantage of data mining is that it can discover unexpected patterns. A
hazard is that many of the patterns it discovers are either random or
spurious.</p>
<p>Having identified potential explanatory variables, I tested a few models
and settled on this one:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;totalwgt_lb ~ agepreg + C(race) + babysex==1 + nbrnaliv&gt;1 + paydu==1 + totincr&quot;</span>
<span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">join</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 29;
                var nbb_unformatted_code = "formula = (\n    'totalwgt_lb ~ agepreg + C(race) + babysex==1 + nbrnaliv>1 + paydu==1 + totincr'\n    )\nresults = smf.ols(formula, data=join).fit()";
                var nbb_formatted_code = "formula = (\n    \"totalwgt_lb ~ agepreg + C(race) + babysex==1 + nbrnaliv>1 + paydu==1 + totincr\"\n)\nresults = smf.ols(formula, data=join).fit()";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>This formula uses some syntax we have not seen yet: <code class="docutils literal notranslate"><span class="pre">C(race)</span></code> tells the
formula parser (Patsy) to treat race as a categorical variable, even
though it is encoded numerically.</p>
<p>The encoding for <code class="docutils literal notranslate"><span class="pre">babysex</span></code> is 1 for male, 2 for female; writing
<code class="docutils literal notranslate"><span class="pre">babysex==1</span></code> converts it to boolean, True for male and false for female.</p>
<p>Similarly <code class="docutils literal notranslate"><span class="pre">nbrnaliv&gt;1</span></code> is True for multiple births and <code class="docutils literal notranslate"><span class="pre">paydu==1</span></code> is
True for respondents who own their houses.</p>
<p><code class="docutils literal notranslate"><span class="pre">totincr</span></code> is encoded numerically from 1-14, with each increment
representing about $5000 in annual income.</p>
<p>So we can treat these values as numerical, expressed in units of $5000.</p>
<p>Here are the results of the model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summarize_results</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   6.63   (0)
C(race)[T.2]   0.357   (5.43e-29)
C(race)[T.3]   0.266   (2.33e-07)
babysex == 1[T.True]   0.295   (5.39e-29)
nbrnaliv &gt; 1[T.True]   -1.38   (5.1e-37)
paydu == 1[T.True]   0.12   (0.000114)
agepreg   0.00741   (0.0035)
totincr   0.0122   (0.00188)
R^2 0.05999
Std(ys) 1.271
Std(res) 1.232
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 30;
                var nbb_unformatted_code = "summarize_results(results)";
                var nbb_formatted_code = "summarize_results(results)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>The estimated parameters for race are larger than I expected, especially
since we control for income. The encoding is 1 for black, 2 for white,
and 3 for other. Babies of black mothers are lighter than babies of
other races by 0.27–0.36 lbs.</p>
<p>As we’ve already seen, boys are heavier by about 0.3 lbs; twins and
other multiplets are lighter by 1.4 lbs.</p>
<p>People who own their homes have heavier babies by about 0.12 lbs, even
when we control for income. The parameter for mother’s age is smaller
than what we saw in
Section <a class="reference internal" href="#multiple"><span class="xref myst">[multiple]</span></a>{reference-type=“ref”
reference=“multiple”}, which suggests that some of the other variables
are correlated with age, probably including <code class="docutils literal notranslate"><span class="pre">paydu</span></code> and <code class="docutils literal notranslate"><span class="pre">totincr</span></code>.</p>
<p>All of these variables are statistically significant, some with very low
p-values, but <span class="math notranslate nohighlight">\(R^2\)</span> is only 0.06, still quite small. RMSE without using
the model is 1.27 lbs; with the model it drops to 1.23. So your chance
of winning the pool is not substantially improved. Sorry!</p>
</section>
<section id="logistic-regression">
<h2>Logistic regression<a class="headerlink" href="#logistic-regression" title="Link to this heading">#</a></h2>
<p>In the previous examples, some of the explanatory variables were
numerical and some categorical (including boolean). But the dependent
variable was always numerical.</p>
<p>Linear regression can be generalized to handle other kinds of dependent
variables. If the dependent variable is boolean, the generalized model
is called <strong>logistic regression</strong>. If the dependent variable is an
integer count, it’s called <strong>Poisson regression</strong>.</p>
<p>As an example of logistic regression, let’s consider a variation on the
office pool scenario. Suppose a friend of yours is pregnant and you want
to predict whether the baby is a boy or a girl. You could use data from
the NSFG to find factors that affect the “sex ratio”, which is
conventionally defined to be the probability of having a boy.</p>
<p>If you encode the dependent variable numerically, for example 0 for a
girl and 1 for a boy, you could apply ordinary least squares, but there
would be problems. The linear model might be something like this:
$<span class="math notranslate nohighlight">\(y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \eps\)</span><span class="math notranslate nohighlight">\( Where \)</span>y<span class="math notranslate nohighlight">\( is the
dependent variable, and \)</span>x_1<span class="math notranslate nohighlight">\( and \)</span>x_2$ are explanatory variables. Then
we could find the parameters that minimize the residuals.</p>
<p>The problem with this approach is that it produces predictions that are
hard to interpret. Given estimated parameters and values for <span class="math notranslate nohighlight">\(x_1\)</span> and
<span class="math notranslate nohighlight">\(x_2\)</span>, the model might predict <span class="math notranslate nohighlight">\(y=0.5\)</span>, but the only meaningful values
of <span class="math notranslate nohighlight">\(y\)</span> are 0 and 1.</p>
<p>It is tempting to interpret a result like that as a probability; for
example, we might say that a respondent with particular values of <span class="math notranslate nohighlight">\(x_1\)</span>
and <span class="math notranslate nohighlight">\(x_2\)</span> has a 50% chance of having a boy. But it is also possible for
this model to predict <span class="math notranslate nohighlight">\(y=1.1\)</span> or <span class="math notranslate nohighlight">\(y=-0.1\)</span>, and those are not valid
probabilities.</p>
<p>Logistic regression avoids this problem by expressing predictions in
terms of <strong>odds</strong> rather than probabilities. If you are not familiar
with odds, “odds in favor” of an event is the ratio of the probability
it will occur to the probability that it will not.</p>
<p>So if I think my team has a 75% chance of winning, I would say that the
odds in their favor are three to one, because the chance of winning is
three times the chance of losing.</p>
<p>Odds and probabilities are different representations of the same
information. Given a probability, you can compute the odds like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="mf">0.75</span>
<span class="n">o</span> <span class="o">=</span> <span class="n">p</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span>
<span class="n">o</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.0
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 31;
                var nbb_unformatted_code = "p = 0.75\no = p / (1 - p)\no";
                var nbb_formatted_code = "p = 0.75\no = p / (1 - p)\no";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>Given odds in favor, you can convert to probability like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">o</span> <span class="o">/</span> <span class="p">(</span><span class="n">o</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">p</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.75
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 32;
                var nbb_unformatted_code = "p = o / (o + 1)\np";
                var nbb_formatted_code = "p = o / (o + 1)\np";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>Logistic regression is based on the following model:
$<span class="math notranslate nohighlight">\(\log o = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon\)</span><span class="math notranslate nohighlight">\( Where \)</span>o<span class="math notranslate nohighlight">\( is the
odds in favor of a particular outcome; in the example, \)</span>o$ would be the
odds of having a boy.</p>
<p>Suppose we have estimated the parameters <span class="math notranslate nohighlight">\(\beta_0\)</span>, <span class="math notranslate nohighlight">\(\beta_1\)</span>, and
<span class="math notranslate nohighlight">\(\beta_2\)</span> (I’ll explain how in a minute). And suppose we are given
values for <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span>. We can compute the predicted value of
<span class="math notranslate nohighlight">\(\log o\)</span>, and then convert to a probability:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">log_o</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">o</span><span class="p">)</span>
<span class="n">o</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_o</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">o</span> <span class="o">/</span> <span class="p">(</span><span class="n">o</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">p</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7500000000000001
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 33;
                var nbb_unformatted_code = "log_o = np.log(o)\no = np.exp(log_o)\np = o / (o + 1)\np";
                var nbb_formatted_code = "log_o = np.log(o)\no = np.exp(log_o)\np = o / (o + 1)\np";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>So in the office pool scenario we could compute the predictive
probability of having a boy. But how do we estimate the parameters?</p>
</section>
<section id="estimating-parameters">
<h2>Estimating parameters<a class="headerlink" href="#estimating-parameters" title="Link to this heading">#</a></h2>
<p>Unlike linear regression, logistic regression does not have a closed
form solution, so it is solved by guessing an initial solution and
improving it iteratively.</p>
<p>The usual goal is to find the maximum-likelihood estimate (MLE), which
is the set of parameters that maximizes the likelihood of the data. For
example, suppose we have the following data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 34;
                var nbb_unformatted_code = "y = np.array([0, 1, 0, 1])\nx1 = np.array([0, 0, 0, 1])\nx2 = np.array([0, 1, 1, 1])";
                var nbb_formatted_code = "y = np.array([0, 1, 0, 1])\nx1 = np.array([0, 0, 0, 1])\nx2 = np.array([0, 1, 1, 1])";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>And we start with the initial guesses <span class="math notranslate nohighlight">\(\beta_0=-1.5\)</span>, <span class="math notranslate nohighlight">\(\beta_1=2.8\)</span>, and
<span class="math notranslate nohighlight">\(\beta_2=1.1\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">beta</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.8</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 35;
                var nbb_unformatted_code = "beta = [-1.5, 2.8, 1.1]";
                var nbb_formatted_code = "beta = [-1.5, 2.8, 1.1]";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>Then for each row we can compute <code class="docutils literal notranslate"><span class="pre">log_o</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">log_o</span> <span class="o">=</span> <span class="n">beta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">beta</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">+</span> <span class="n">beta</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">x2</span>
<span class="n">log_o</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-1.5, -0.4, -0.4,  2.4])
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 36;
                var nbb_unformatted_code = "log_o = beta[0] + beta[1] * x1 + beta[2] * x2\nlog_o";
                var nbb_formatted_code = "log_o = beta[0] + beta[1] * x1 + beta[2] * x2\nlog_o";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>And convert from log odds to probabilities:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">o</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_o</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 37;
                var nbb_unformatted_code = "o = np.exp(log_o)";
                var nbb_formatted_code = "o = np.exp(log_o)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">o</span> <span class="o">/</span> <span class="p">(</span><span class="n">o</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 38;
                var nbb_unformatted_code = "p = o / (o + 1)";
                var nbb_formatted_code = "p = o / (o + 1)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>Notice that when <code class="docutils literal notranslate"><span class="pre">log_o</span></code> is greater than 0, <code class="docutils literal notranslate"><span class="pre">o</span></code> is greater than 1 and
<code class="docutils literal notranslate"><span class="pre">p</span></code> is greater than 0.5.</p>
<p>The likelihood of an outcome is <code class="docutils literal notranslate"><span class="pre">p</span></code> when <code class="docutils literal notranslate"><span class="pre">y==1</span></code> and <code class="docutils literal notranslate"><span class="pre">1-p</span></code> when <code class="docutils literal notranslate"><span class="pre">y==0</span></code>.
For example, if we think the probability of a boy is 0.8 and the outcome
is a boy, the likelihood is 0.8; if the outcome is a girl, the
likelihood is 0.2. We can compute that like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">likes</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="n">p</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 39;
                var nbb_unformatted_code = "likes = y * p + (1 - y) * (1 - p)";
                var nbb_formatted_code = "likes = y * p + (1 - y) * (1 - p)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>The overall likelihood of the data is the product of <code class="docutils literal notranslate"><span class="pre">likes</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">like</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">likes</span><span class="p">)</span>
<span class="n">like</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.1800933529673034
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 40;
                var nbb_unformatted_code = "like = np.prod(likes)\nlike";
                var nbb_formatted_code = "like = np.prod(likes)\nlike";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>For these values of <code class="docutils literal notranslate"><span class="pre">beta</span></code>, the likelihood of the data is 0.18. The goal
of logistic regression is to find parameters that maximize this
likelihood. To do that, most statistics packages use an iterative solver
like Newton’s method (see
<a class="reference external" href="https://en.wikipedia.org/wiki/Logistic_regression#Model_fitting">https://en.wikipedia.org/wiki/Logistic_regression#Model_fitting</a>).</p>
</section>
<section id="implementation">
<h2>Implementation<a class="headerlink" href="#implementation" title="Link to this heading">#</a></h2>
<p>StatsModels provides an implementation of logistic regression called
<code class="docutils literal notranslate"><span class="pre">logit</span></code>, named for the function that converts from probability to log
odds. To demonstrate its use, I’ll look for variables that affect the
sex ratio.</p>
<p>Again, I load the NSFG data and select pregnancies longer than 30 weeks:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">live</span> <span class="o">=</span> <span class="n">live</span><span class="p">[</span><span class="n">live</span><span class="o">.</span><span class="n">prglngth</span> <span class="o">&gt;</span> <span class="mi">30</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 41;
                var nbb_unformatted_code = "live = live[live.prglngth > 30]";
                var nbb_formatted_code = "live = live[live.prglngth > 30]";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">logit</span></code> requires the dependent variable to be binary (rather than
boolean), so I create a new column named <code class="docutils literal notranslate"><span class="pre">boy</span></code>, using <code class="docutils literal notranslate"><span class="pre">astype(int)</span></code> to
convert to binary integers:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">live</span><span class="p">[</span><span class="s2">&quot;boy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">live</span><span class="o">.</span><span class="n">babysex</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">live</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(8884, 247)
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 42;
                var nbb_unformatted_code = "live['boy'] = (live.babysex == 1).astype(int)\nlive.shape";
                var nbb_formatted_code = "live[\"boy\"] = (live.babysex == 1).astype(int)\nlive.shape";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>Factors that have been found to affect sex ratio include parents’ age,
birth order, race, and social status. We can use logistic regression to
see if these effects appear in the NSFG data. I’ll start with the
mother’s age:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">logit</span><span class="p">(</span><span class="s2">&quot;boy ~ agepreg&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">live</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 43;
                var nbb_unformatted_code = "import statsmodels.formula.api as smf\nmodel = smf.logit('boy ~ agepreg', data=live)\nresults = model.fit()";
                var nbb_formatted_code = "import statsmodels.formula.api as smf\n\nmodel = smf.logit(\"boy ~ agepreg\", data=live)\nresults = model.fit()";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">logit</span></code> takes the same arguments as <code class="docutils literal notranslate"><span class="pre">ols</span></code>, a formula in Patsy syntax and
a DataFrame. The result is a Logit object that represents the model.</p>
<p>The result of <code class="docutils literal notranslate"><span class="pre">model.fit</span></code> is a BinaryResults object, which is similar to
the RegressionResults object we got from <code class="docutils literal notranslate"><span class="pre">ols</span></code>. Here is a summary of the
results:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summarize_results</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   0.00579   (0.953)
agepreg   0.00105   (0.783)
R^2 6.144e-06
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 44;
                var nbb_unformatted_code = "summarize_results(results)";
                var nbb_formatted_code = "summarize_results(results)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>The parameter of <code class="docutils literal notranslate"><span class="pre">agepreg</span></code> is positive, which suggests that older
mothers are more likely to have boys, but the p-value is 0.783, which
means that the apparent effect could easily be due to chance.</p>
<p>The coefficient of determination, <span class="math notranslate nohighlight">\(R^2\)</span>, does not apply to logistic
regression, but there are several alternatives that are used as “pseudo
<span class="math notranslate nohighlight">\(R^2\)</span> values.” These values can be useful for comparing models. For
example, here’s a model that includes several factors believed to be
associated with sex ratio:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="s2">&quot;boy ~ agepreg + hpagelb + birthord + C(race)&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">logit</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">live</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.692944
         Iterations 3
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 45;
                var nbb_unformatted_code = "formula = 'boy ~ agepreg + hpagelb + birthord + C(race)'\nmodel = smf.logit(formula, data=live)\nresults = model.fit()";
                var nbb_formatted_code = "formula = \"boy ~ agepreg + hpagelb + birthord + C(race)\"\nmodel = smf.logit(formula, data=live)\nresults = model.fit()";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>Along with mother’s age, this model includes father’s age at birth
(<code class="docutils literal notranslate"><span class="pre">hpagelb</span></code>), birth order (<code class="docutils literal notranslate"><span class="pre">birthord</span></code>), and race as a categorical
variable. Here are the results:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summarize_results</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   -0.0301   (0.772)
C(race)[T.2]   -0.0224   (0.66)
C(race)[T.3]   -0.000457   (0.996)
agepreg   -0.00267   (0.629)
hpagelb   0.0047   (0.266)
birthord   0.00501   (0.821)
R^2 0.000144
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 46;
                var nbb_unformatted_code = "summarize_results(results)";
                var nbb_formatted_code = "summarize_results(results)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>None of the estimated parameters are statistically significant. The
pseudo-<span class="math notranslate nohighlight">\(R^2\)</span> value is a little higher, but that could be due to chance.</p>
</section>
<section id="accuracy">
<h2>Accuracy<a class="headerlink" href="#accuracy" title="Link to this heading">#</a></h2>
<p>In the office pool scenario, we are most interested in the accuracy of
the model: the number of successful predictions, compared with what we
would expect by chance.</p>
<p>In the NSFG data, there are more boys than girls, so the baseline
strategy is to guess “boy” every time.</p>
<p>The model contains attributes called <code class="docutils literal notranslate"><span class="pre">endog</span></code> and <code class="docutils literal notranslate"><span class="pre">exog</span></code> that contain the
<strong>endogenous variable</strong>, another name for the dependent variable, and
the <strong>exogenous variables</strong>, another name for the explanatory variables.
Since they are NumPy arrays, it is sometimes convenient to convert them
to DataFrames:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">endog</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">endog</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">endog_names</span><span class="p">])</span>
<span class="n">exog</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">exog</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">exog_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 47;
                var nbb_unformatted_code = "import pandas as pd\nendog = pd.DataFrame(model.endog, columns=[model.endog_names])\nexog = pd.DataFrame(model.exog, columns=model.exog_names)";
                var nbb_formatted_code = "import pandas as pd\n\nendog = pd.DataFrame(model.endog, columns=[model.endog_names])\nexog = pd.DataFrame(model.exog, columns=model.exog_names)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>The accuracy of this strategy is
just the fraction of boys:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">actual</span> <span class="o">=</span> <span class="n">endog</span><span class="p">[</span><span class="s2">&quot;boy&quot;</span><span class="p">]</span>
<span class="n">actual</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(8782,)
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 48;
                var nbb_unformatted_code = "actual = endog['boy']\nactual.shape";
                var nbb_formatted_code = "actual = endog[\"boy\"]\nactual.shape";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">baseline</span> <span class="o">=</span> <span class="n">actual</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">baseline</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.507173764518333
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 49;
                var nbb_unformatted_code = "baseline = actual.mean()\nbaseline";
                var nbb_formatted_code = "baseline = actual.mean()\nbaseline";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>Since <code class="docutils literal notranslate"><span class="pre">actual</span></code> is encoded in binary integers, the mean is the fraction
of boys, which is 0.507.</p>
<p>Here’s how we compute the accuracy of the model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predict</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">predict</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mf">0.5</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 50;
                var nbb_unformatted_code = "predict = results.predict() >= 0.5";
                var nbb_formatted_code = "predict = results.predict() >= 0.5";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">true_pos</span> <span class="o">=</span> <span class="n">predict</span> <span class="o">*</span> <span class="n">actual</span>
<span class="n">true_pos</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3944.0
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 51;
                var nbb_unformatted_code = "true_pos = predict * actual\ntrue_pos.sum()";
                var nbb_formatted_code = "true_pos = predict * actual\ntrue_pos.sum()";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">true_neg</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">predict</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">actual</span><span class="p">)</span>
<span class="n">true_neg</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>548.0
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 52;
                var nbb_unformatted_code = "true_neg = (1 - predict) * (1 - actual)\ntrue_neg.sum()";
                var nbb_formatted_code = "true_neg = (1 - predict) * (1 - actual)\ntrue_neg.sum()";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">results.predict</span></code> returns a NumPy array of probabilities, which we round
off to 0 or 1. Multiplying by <code class="docutils literal notranslate"><span class="pre">actual</span></code> yields 1 if we predict a boy and
get it right, 0 otherwise. So, <code class="docutils literal notranslate"><span class="pre">true_pos</span></code> indicates “true positives”.</p>
<p>Similarly, <code class="docutils literal notranslate"><span class="pre">true_neg</span></code> indicates the cases where we guess “girl” and get
it right. Accuracy is the fraction of correct guesses:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">acc</span> <span class="o">=</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">true_pos</span><span class="p">)</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">true_neg</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span>
<span class="n">acc</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.5115007970849464
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 53;
                var nbb_unformatted_code = "acc = (sum(true_pos) + sum(true_neg)) / len(actual)\nacc";
                var nbb_formatted_code = "acc = (sum(true_pos) + sum(true_neg)) / len(actual)\nacc";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>The result is 0.512, slightly better than the baseline, 0.507. But, you
should not take this result too seriously. We used the same data to
build and test the model, so the model may not have predictive power on
new data.</p>
<p>Nevertheless, let’s use the model to make a prediction for the office
pool. Suppose your friend is 35 years old and white, her husband is 39,
and they are expecting their third child:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;agepreg&quot;</span><span class="p">,</span> <span class="s2">&quot;hpagelb&quot;</span><span class="p">,</span> <span class="s2">&quot;birthord&quot;</span><span class="p">,</span> <span class="s2">&quot;race&quot;</span><span class="p">]</span>
<span class="n">new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([[</span><span class="mi">35</span><span class="p">,</span> <span class="mi">39</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new</span><span class="p">)</span>
<span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.5130905016919948
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 54;
                var nbb_unformatted_code = "columns = ['agepreg', 'hpagelb', 'birthord', 'race']\nnew = pd.DataFrame([[35, 39, 3, 2]], columns=columns)\ny = results.predict(new)\ny.mean()";
                var nbb_formatted_code = "columns = [\"agepreg\", \"hpagelb\", \"birthord\", \"race\"]\nnew = pd.DataFrame([[35, 39, 3, 2]], columns=columns)\ny = results.predict(new)\ny.mean()";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>To invoke <code class="docutils literal notranslate"><span class="pre">results.predict</span></code> for a new case, you have to construct a
DataFrame with a column for each variable in the model. The result in
this case is 0.52, so you should guess “boy.” But if the model improves
your chances of winning, the difference is very small.</p>
</section>
<section id="glossary">
<h2>Glossary<a class="headerlink" href="#glossary" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>regression</strong>: One of several related processes for estimating
parameters that fit a model to data.</p></li>
<li><p><strong>dependent variables</strong>: The variables in a regression model we
would like to predict. Also known as endogenous variables.</p></li>
<li><p><strong>explanatory variables</strong>: The variables used to predict or explain
the dependent variables. Also known as independent, or exogenous,
variables.</p></li>
<li><p><strong>simple regression</strong>: A regression with only one dependent and one
explanatory variable.</p></li>
<li><p><strong>multiple regression</strong>: A regression with multiple explanatory
variables, but only one dependent variable.</p></li>
<li><p><strong>linear regression</strong>: A regression based on a linear model.</p></li>
<li><p><strong>ordinary least squares</strong>: A linear regression that estimates
parameters by minimizing the squared error of the residuals.</p></li>
<li><p><strong>spurious relationship</strong>: A relationship between two variables that
is caused by a statistical artifact or a factor, not included in the
model, that is related to both variables.</p></li>
<li><p><strong>control variable</strong>: A variable included in a regression to
eliminate or “control for” a spurious relationship.</p></li>
<li><p><strong>proxy variable</strong>: A variable that contributes information to a
regression model indirectly because of a relationship with another
factor, so it acts as a proxy for that factor.</p></li>
<li><p><strong>categorical variable</strong>: A variable that can have one of a discrete
set of unordered values.</p></li>
<li><p><strong>join</strong>: An operation that combines data from two DataFrames using
a key to match up rows in the two frames.</p></li>
<li><p><strong>data mining</strong>: An approach to finding relationships between
variables by testing a large number of models.</p></li>
<li><p><strong>logistic regression</strong>: A form of regression used when the
dependent variable is boolean.</p></li>
<li><p><strong>Poisson regression</strong>: A form of regression used when the dependent
variable is a non-negative integer, usually a count.</p></li>
<li><p><strong>odds</strong>: An alternative way of representing a probability, <span class="math notranslate nohighlight">\(p\)</span>, as
the ratio of the probability and its complement, <span class="math notranslate nohighlight">\(p / (1-p)\)</span>.</p></li>
</ul>
</section>
<section id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<p><strong>Exercise:</strong> Suppose one of your co-workers is expecting a baby and you are participating in an office pool to predict the date of birth. Assuming that bets are placed during the 30th week of pregnancy, what variables could you use to make the best prediction? You should limit yourself to variables that are known before the birth, and likely to be available to the people in the pool.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nsfg</span>

<span class="n">live</span><span class="p">,</span> <span class="n">firsts</span><span class="p">,</span> <span class="n">others</span> <span class="o">=</span> <span class="n">nsfg</span><span class="o">.</span><span class="n">make_frames</span><span class="p">()</span>
<span class="n">live</span> <span class="o">=</span> <span class="n">live</span><span class="p">[</span><span class="n">live</span><span class="o">.</span><span class="n">prglngth</span> <span class="o">&gt;</span> <span class="mi">30</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 55;
                var nbb_unformatted_code = "import nsfg\nlive, firsts, others = nsfg.make_frames()\nlive = live[live.prglngth > 30]";
                var nbb_formatted_code = "import nsfg\n\nlive, firsts, others = nsfg.make_frames()\nlive = live[live.prglngth > 30]";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s2">&quot;prglngth ~ birthord==1 + race==2 + nbrnaliv&gt;1&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">live</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>        <td>prglngth</td>     <th>  R-squared:         </th> <td>   0.011</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.011</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.28</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Tue, 18 Jun 2024</td> <th>  Prob (F-statistic):</th> <td>5.09e-22</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>14:58:32</td>     <th>  Log-Likelihood:    </th> <td> -18247.</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td>  8884</td>      <th>  AIC:               </th> <td>3.650e+04</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>  8880</td>      <th>  BIC:               </th> <td>3.653e+04</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
            <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>             <td>   38.7617</td> <td>    0.039</td> <td> 1006.410</td> <td> 0.000</td> <td>   38.686</td> <td>   38.837</td>
</tr>
<tr>
  <th>birthord == 1[T.True]</th> <td>    0.1015</td> <td>    0.040</td> <td>    2.528</td> <td> 0.011</td> <td>    0.023</td> <td>    0.180</td>
</tr>
<tr>
  <th>race == 2[T.True]</th>     <td>    0.1390</td> <td>    0.042</td> <td>    3.311</td> <td> 0.001</td> <td>    0.057</td> <td>    0.221</td>
</tr>
<tr>
  <th>nbrnaliv > 1[T.True]</th>  <td>   -1.4944</td> <td>    0.164</td> <td>   -9.086</td> <td> 0.000</td> <td>   -1.817</td> <td>   -1.172</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>1587.470</td> <th>  Durbin-Watson:     </th> <td>   1.619</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>6160.751</td>
</tr>
<tr>
  <th>Skew:</th>           <td>-0.852</td>  <th>  Prob(JB):          </th> <td>    0.00</td>
</tr>
<tr>
  <th>Kurtosis:</th>       <td> 6.707</td>  <th>  Cond. No.          </th> <td>    10.9</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div><script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 56;
                var nbb_unformatted_code = "import statsmodels.formula.api as smf\nmodel = smf.ols('prglngth ~ birthord==1 + race==2 + nbrnaliv>1', data=live)\nresults = model.fit()\nresults.summary()";
                var nbb_formatted_code = "import statsmodels.formula.api as smf\n\nmodel = smf.ols(\"prglngth ~ birthord==1 + race==2 + nbrnaliv>1\", data=live)\nresults = model.fit()\nresults.summary()";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p><strong>Exercise:</strong> The Trivers-Willard hypothesis suggests that for many mammals the sex ratio depends on “maternal condition”; that is, factors like the mother’s age, size, health, and social status. See <a class="reference external" href="https://en.wikipedia.org/wiki/Trivers-Willard_hypothesis">https://en.wikipedia.org/wiki/Trivers-Willard_hypothesis</a></p>
<p>Some studies have shown this effect among humans, but results are mixed. In this chapter we tested some variables related to these factors, but didn’t find any with a statistically significant effect on sex ratio.</p>
<p>As an exercise, use a data mining approach to test the other variables in the pregnancy and respondent files. Can you find any factors with a substantial effect?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">go_mining</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Searches for variables that predict birth weight.</span>

<span class="sd">    df: DataFrame of pregnancy records</span>

<span class="sd">    returns: list of (rsquared, variable name) pairs</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;boy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">babysex</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">variables</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">df</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">1e-07</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">formula</span> <span class="o">=</span> <span class="s2">&quot;boy ~ agepreg + &quot;</span> <span class="o">+</span> <span class="n">name</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">logit</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
            <span class="n">nobs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">endog</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">nobs</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">variables</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">results</span><span class="o">.</span><span class="n">prsquared</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">variables</span>


<span class="n">variables</span> <span class="o">=</span> <span class="n">go_mining</span><span class="p">(</span><span class="n">join</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.692991
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692961
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692849
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692996
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692903
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692724
         Iterations 6
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692992
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693010
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692985
         Iterations 5
Optimization terminated successfully.
         Current function value: 0.692577
         Iterations 6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:2385: RuntimeWarning: overflow encountered in exp
  return 1/(1+np.exp(-X))
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:2443: RuntimeWarning: divide by zero encountered in log
  return np.sum(np.log(self.cdf(q * linpred)))
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Warning: Maximum number of iterations has been exceeded.
         Current function value: inf
         Iterations: 35
Optimization terminated successfully.
         Current function value: 0.686599
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693022
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692903
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693031
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692963
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692964
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692905
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693092
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693107
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692589
         Iterations 6
Optimization terminated successfully.
         Current function value: 0.693006
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692774
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692843
         Iterations 5
Optimization terminated successfully.
         Current function value: 0.692612
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692947
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692817
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692947
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693023
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692967
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692995
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692645
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692555
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693021
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693066
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692911
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692917
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693003
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692861
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692859
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692814
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692389
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692517
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692452
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692701
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692290
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692930
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693003
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692926
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693004
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692930
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692861
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692866
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692866
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692806
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692930
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692989
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692987
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693008
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692985
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693006
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692993
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692871
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692994
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692985
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693001
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692942
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692922
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692986
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692573
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692988
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692817
         Iterations 5
Optimization terminated successfully.
         Current function value: 0.692588
         Iterations 5
Optimization terminated successfully.
         Current function value: 0.692877
         Iterations 5
Optimization terminated successfully.
         Current function value: 0.692652
         Iterations 5
Optimization terminated successfully.
         Current function value: 0.692991
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692918
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692984
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692952
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693008
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692893
         Iterations 5
Warning: Maximum number of iterations has been exceeded.
         Current function value: 0.692776
         Iterations: 35
Optimization terminated successfully.
         Current function value: 0.692638
         Iterations 6
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn(&quot;Maximum Likelihood optimization failed to &quot;
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.692838
         Iterations 5
Optimization terminated successfully.
         Current function value: 0.692971
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692985
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692971
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693003
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692973
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692973
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692810
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693003
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692995
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692979
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693003
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.686305
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693006
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692959
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692991
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692984
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692928
         Iterations 5
Optimization terminated successfully.
         Current function value: 0.692910
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693007
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693008
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692881
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692866
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692861
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692866
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692930
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692806
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692808
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692986
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693004
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692985
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693039
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692886
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692957
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692888
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692989
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693006
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692921
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692996
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692907
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692439
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692916
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692951
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692950
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693037
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693021
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693018
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692850
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693056
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692885
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693007
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692963
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692994
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692959
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692319
         Iterations 6
Optimization terminated successfully.
         Current function value: 0.692984
         Iterations 5
Optimization terminated successfully.
         Current function value: 0.692841
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693006
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692879
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693007
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692871
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692993
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692997
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692956
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693010
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692780
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693055
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693104
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693022
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693069
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693052
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692988
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693037
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693063
         Iterations 3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.693052
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693078
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693078
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692964
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692801
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693074
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692959
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692995
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693004
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692911
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692833
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693025
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692823
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692970
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692945
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693055
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692908
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692703
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692853
         Iterations 5
Optimization terminated successfully.
         Current function value: 0.692981
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693053
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692991
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692962
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692928
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693009
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692999
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692943
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693049
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692901
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692951
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692843
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692834
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692783
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692799
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692850
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692841
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693012
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692986
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693118
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693128
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692958
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692898
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693003
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693005
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692829
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692999
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692972
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692901
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692929
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692894
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692820
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692973
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692960
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692999
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693007
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692993
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692986
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693002
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692968
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692995
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693028
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692992
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693010
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692733
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692645
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693029
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692842
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692821
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692986
         Iterations 3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.693012
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692721
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693054
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692742
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693012
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693007
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692958
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692975
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692848
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692942
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692953
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692915
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692931
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692973
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692940
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692992
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693006
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693000
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693008
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693012
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693012
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692999
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692979
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693000
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692984
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692978
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692930
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692829
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692992
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692980
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692971
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693010
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693000
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693000
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692979
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692996
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693008
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693006
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692985
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693010
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693003
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692990
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693012
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693012
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692950
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693037
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693039
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693091
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693065
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692992
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692987
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692840
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692984
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693008
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693002
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693023
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693001
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693016
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693006
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692970
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693006
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692980
         Iterations 3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.692989
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693007
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692985
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693003
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692994
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692990
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693003
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692985
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692965
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692994
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692818
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692980
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692680
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692674
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692884
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692865
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693007
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692883
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692994
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692941
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692948
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693008
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692917
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692993
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692999
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692968
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692850
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692971
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692844
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692963
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692980
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692984
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692937
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692960
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692970
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693001
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692911
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693002
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692929
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692995
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692845
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692981
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692718
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692973
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692575
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692985
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692673
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692988
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692778
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693018
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692804
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693023
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692752
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693023
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692671
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692986
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692709
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693046
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692650
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693063
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692875
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693098
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692806
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693074
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693058
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693024
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692892
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692959
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692853
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692615
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692979
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693046
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692917
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692977
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692985
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693004
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692985
         Iterations 3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.692932
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692619
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692779
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692886
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692739
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692662
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692621
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692792
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692926
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692879
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692805
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693009
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692673
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692940
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692903
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693005
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693006
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692994
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692992
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692980
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693001
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692999
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693002
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692941
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692972
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692952
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692977
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692920
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692856
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692955
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692852
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692573
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692976
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692879
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693069
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692955
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692868
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693003
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693018
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693027
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692949
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693012
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692945
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692962
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692971
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693012
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692579
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692949
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692801
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692987
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693094
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693036
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692917
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692971
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693006
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692824
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692862
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692862
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692976
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693009
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693009
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692965
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692967
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692973
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693008
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692916
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693005
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692951
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692962
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692985
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692952
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692946
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692995
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692974
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692992
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693012
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692995
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692994
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692866
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692806
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692989
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692987
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692985
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693008
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693006
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693005
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693007
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693008
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692610
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692904
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692859
         Iterations 5
Optimization terminated successfully.
         Current function value: 0.692712
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692948
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692993
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692871
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692883
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692801
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693001
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692994
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692722
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692909
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692561
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692803
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692870
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692755
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692702
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693008
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692963
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692879
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692855
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692837
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692729
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693001
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692990
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692875
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692989
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692813
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692475
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693001
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692833
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692529
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692898
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692640
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692784
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692875
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692782
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692938
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692871
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692973
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692973
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692973
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692973
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692973
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692939
         Iterations 18
Optimization terminated successfully.
         Current function value: 0.693009
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693005
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692976
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693012
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692995
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692958
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693002
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692983
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693010
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692955
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692967
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693009
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692859
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693010
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692925
         Iterations 4
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.692969
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692983
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692894
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692874
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692859
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693010
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692924
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692982
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692914
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692969
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692983
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692695
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692955
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692946
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693009
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692859
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693010
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692925
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692969
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692983
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692955
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692889
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692823
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692968
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692859
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692925
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692969
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692983
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692989
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692997
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693010
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692923
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692990
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692986
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692929
         Iterations 5
Optimization terminated successfully.
         Current function value: 0.693001
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693005
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692939
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692990
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692986
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692929
         Iterations 5
Optimization terminated successfully.
         Current function value: 0.692991
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692966
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692941
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692978
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692986
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692929
         Iterations 5
Optimization terminated successfully.
         Current function value: 0.692973
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692973
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692974
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692973
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692930
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692929
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692933
         Iterations 3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.693045
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693078
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692739
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693012
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692997
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692750
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692991
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692873
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692830
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693082
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692636
         Iterations 3
Warning: Maximum number of iterations has been exceeded.
         Current function value: 0.692709
         Iterations: 35
Optimization terminated successfully.
         Current function value: 0.692863
         Iterations 3
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn(&quot;Maximum Likelihood optimization failed to &quot;
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.692926
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692726
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692774
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692999
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692861
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692705
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692723
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692803
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692956
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692786
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693007
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692989
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692993
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692952
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693012
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692970
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693009
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 4
Warning: Maximum number of iterations has been exceeded.
         Current function value: 0.692862
         Iterations: 35
Optimization terminated successfully.
         Current function value: 0.692861
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn(&quot;Maximum Likelihood optimization failed to &quot;
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693010
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692658
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692789
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693008
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692855
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692855
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692749
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692862
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692862
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692821
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692772
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692687
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692947
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692771
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692755
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693006
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693012
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692949
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692912
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692879
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692950
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692991
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692929
         Iterations 4
Warning: Maximum number of iterations has been exceeded.
         Current function value: 0.692960
         Iterations: 35
Optimization terminated successfully.
         Current function value: 0.693007
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692981
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692975
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692961
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693005
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692995
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693001
         Iterations 3
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn(&quot;Maximum Likelihood optimization failed to &quot;
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692957
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692983
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692258
         Iterations 5
Warning: Maximum number of iterations has been exceeded.
         Current function value: 0.692696
         Iterations: 35
Optimization terminated successfully.
         Current function value: 0.692993
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693009
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692853
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692971
         Iterations 3
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn(&quot;Maximum Likelihood optimization failed to &quot;
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.692639
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692917
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692760
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692832
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693028
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692888
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692770
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692992
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692976
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692866
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692992
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692976
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692866
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693010
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692896
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692758
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693081
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692986
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692927
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692827
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693008
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692890
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692941
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692920
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692920
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692982
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693001
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692997
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693008
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693008
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693005
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692956
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692931
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692996
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692996
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692730
         Iterations 5
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692898
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692879
         Iterations 5
Optimization terminated successfully.
         Current function value: 0.692887
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692987
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692986
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692995
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692980
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692849
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692974
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692987
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692957
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693009
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693002
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693013
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692980
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692849
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692974
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692987
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692957
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693009
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693002
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692969
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693005
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692946
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692862
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692905
         Iterations 4
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.692962
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692977
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693010
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693000
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692998
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693012
         Iterations 3
Warning: Maximum number of iterations has been exceeded.
         Current function value: 0.692939
         Iterations: 35
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn(&quot;Maximum Likelihood optimization failed to &quot;
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.693003
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692831
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692999
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693003
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692997
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692795
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692693
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692457
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692815
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693002
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692989
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693008
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692673
         Iterations 5
Optimization terminated successfully.
         Current function value: 0.692982
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692985
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692986
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692922
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692973
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693011
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692942
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692921
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693002
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692810
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.693003
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692995
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692979
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693014
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.693003
         Iterations 3
Optimization terminated successfully.
         Current function value: 0.692996
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692996
         Iterations 4
Optimization terminated successfully.
         Current function value: 0.692971
         Iterations 3
Warning: Maximum number of iterations has been exceeded.
         Current function value: 0.000000
         Iterations: 35
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
  warnings.warn(msg, category=PerfectSeparationWarning)
/home/downey/miniconda3/envs/ThinkStats/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn(&quot;Maximum Likelihood optimization failed to &quot;
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 57;
                var nbb_unformatted_code = "def go_mining(df):\n    \"\"\"Searches for variables that predict birth weight.\n\n    df: DataFrame of pregnancy records\n\n    returns: list of (rsquared, variable name) pairs\n    \"\"\"\n    df['boy'] = (df.babysex == 1).astype(int)\n    variables = []\n    for name in df.columns:\n        try:\n            if df[name].var() < 1e-07:\n                continue\n            formula = 'boy ~ agepreg + ' + name\n            model = smf.logit(formula, data=df)\n            nobs = len(model.endog)\n            if nobs < len(df) / 2:\n                continue\n            results = model.fit()\n        except:\n            continue\n        variables.append((results.prsquared, name))\n    return variables\n\n\nvariables = go_mining(join)";
                var nbb_formatted_code = "def go_mining(df):\n    \"\"\"Searches for variables that predict birth weight.\n\n    df: DataFrame of pregnancy records\n\n    returns: list of (rsquared, variable name) pairs\n    \"\"\"\n    df[\"boy\"] = (df.babysex == 1).astype(int)\n    variables = []\n    for name in df.columns:\n        try:\n            if df[name].var() < 1e-07:\n                continue\n            formula = \"boy ~ agepreg + \" + name\n            model = smf.logit(formula, data=df)\n            nobs = len(model.endog)\n            if nobs < len(df) / 2:\n                continue\n            results = model.fit()\n        except:\n            continue\n        variables.append((results.prsquared, name))\n    return variables\n\n\nvariables = go_mining(join)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mining_report</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>boy 0.9999999999839987
totalwgt_lb 0.009696855253233383
birthwgt_lb 0.009274460080281988 BD-3 BIRTHWEIGHT IN POUNDS - 1ST BABY FROM THIS PREGNANCY
constat3 0.0010985419170438382 3RD PRIORITY CODE FOR CURRENT CONTRACEPTIVE STATUS
lbw1 0.0010519527860078925 LOW BIRTHWEIGHT - BABY 1
nplaced 0.001010368752280555 # OF R&#39;S BIO CHILDREN SHE PLACED FOR ADOPTION (BASED ON BPA)
fmarout5 0.0009096579032891183 FORMAL MARITAL STATUS AT PREGNANCY OUTCOME
rmarout6 0.000818252143711895 INFORMAL MARITAL STATUS AT PREGNANCY OUTCOME - 6 CATEGORIES
infever 0.0008115919859909004 EVER USED INFERTILITY SERVICES OF ANY KIND
frsteatd 0.0007675331422082321 AGE (IN MOS) WHEN 1ST SUPPLEMENTED - 1ST FROM THIS PREG
splstwk1 0.0007334122339932581 IF-1 H/P DOING WHAT LAST WEEK (EMPLOYMENT STATUS) 1ST MENTION
pmarpreg 0.0007245809157658822 WHETHER PREGNANCY ENDED BEFORE R&#39;S 1ST MARRIAGE (PREMARITALLY)
usefstp 0.0007122387685902787 EF-3 USE METHOD AT FIRST SEX WITH 1ST PARTNER IN PAST 12 MONTHS?
outcom02 0.0007015744602576479 OUTCOME OF PREGNANCY - 2ND
nummult34 0.0006606172426639745 NUMBER OF METHODS REPORTED IN (OCT 2001)
coh1dur 0.0006550110146368304 DURATION (IN MONTHS) OF R&#39;S FIRST COHABITATION
brnout_r 0.0006438582787924307 IB-8 R BORN OUTSIDE OF US
brnout 0.0006438582787924307 IB-8 R BORN OUTSIDE OF US
bpa_bdscheck1 0.0006384992730465999 WHETHER 1ST LIVEBORN BABY FROM THIS PREGNANCY WAS BPA OR BDS
nummult41 0.000624852395994635 NUMBER OF METHODS REPORTED IN (MAY 2002)
agepreg_i 0.0006221097878729154 AGEPREG IMPUTATION FLAG
educmom 0.0005903653895802385 MOTHER&#39;S (OR MOTHER-FIGURE&#39;S) EDUCATION
marout03 0.0005883792792801268 FORMAL MARITAL STATUS WHEN PREGNANCY ENDED - 3RD
abort12 0.0005779076671296179 FA-3B RECEIVED ABORTION LAST 12 MONTHS
p1yhsage 0.0005631662500977797 CI-6 PARTNER&#39;S AGE AT 1ST SEX-1ST REPORTED PARTNER IN LAST 12 MOS
numfirsm1 0.0005601782001567468 TOTAL NUMBER OF RESPONSES IN EB-1 FIRSMETH - PRESCRIPTION METHODS
lbw1_i 0.0005499451546340239 LBW1 IMPUTATION FLAG
agecon_i 0.0005303754891523571 AGECON IMPUTATION FLAG
mar1con1_i 0.0005217496825273837 MAR1CON1 IMPUTATION FLAG
nummult35 0.0005188253090530059 NUMBER OF METHODS REPORTED IN (NOV 2001)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_283807/439348224.py:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  desc = desc[0]
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 58;
                var nbb_unformatted_code = "mining_report(variables)";
                var nbb_formatted_code = "mining_report(variables)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="s2">&quot;boy ~ agepreg + fmarout5==5 + infever==1&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">logit</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">join</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.691874
         Iterations 4
</pre></div>
</div>
<div class="output text_html"><table class="simpletable">
<caption>Logit Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>boy</td>       <th>  No. Observations:  </th>  <td>  8884</td>  
</tr>
<tr>
  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  8880</td>  
</tr>
<tr>
  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     3</td>  
</tr>
<tr>
  <th>Date:</th>            <td>Tue, 18 Jun 2024</td> <th>  Pseudo R-squ.:     </th> <td>0.001653</td> 
</tr>
<tr>
  <th>Time:</th>                <td>14:59:11</td>     <th>  Log-Likelihood:    </th> <td> -6146.6</td> 
</tr>
<tr>
  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -6156.8</td> 
</tr>
<tr>
  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>0.0001432</td>
</tr>
</table>
<table class="simpletable">
<tr>
            <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>             <td>   -0.1805</td> <td>    0.118</td> <td>   -1.534</td> <td> 0.125</td> <td>   -0.411</td> <td>    0.050</td>
</tr>
<tr>
  <th>fmarout5 == 5[T.True]</th> <td>    0.1582</td> <td>    0.049</td> <td>    3.217</td> <td> 0.001</td> <td>    0.062</td> <td>    0.255</td>
</tr>
<tr>
  <th>infever == 1[T.True]</th>  <td>    0.2194</td> <td>    0.065</td> <td>    3.374</td> <td> 0.001</td> <td>    0.092</td> <td>    0.347</td>
</tr>
<tr>
  <th>agepreg</th>               <td>    0.0050</td> <td>    0.004</td> <td>    1.172</td> <td> 0.241</td> <td>   -0.003</td> <td>    0.013</td>
</tr>
</table></div><script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 59;
                var nbb_unformatted_code = "formula = 'boy ~ agepreg + fmarout5==5 + infever==1'\nmodel = smf.logit(formula, data=join)\nresults = model.fit()\nresults.summary()";
                var nbb_formatted_code = "formula = \"boy ~ agepreg + fmarout5==5 + infever==1\"\nmodel = smf.logit(formula, data=join)\nresults = model.fit()\nresults.summary()";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p><strong>Exercise:</strong> If the quantity you want to predict is a count, you can use Poisson regression, which is implemented in StatsModels with a function called <code class="docutils literal notranslate"><span class="pre">poisson</span></code>. It works the same way as <code class="docutils literal notranslate"><span class="pre">ols</span></code> and <code class="docutils literal notranslate"><span class="pre">logit</span></code>. As an exercise, let’s use it to predict how many children a woman has born; in the NSFG dataset, this variable is called <code class="docutils literal notranslate"><span class="pre">numbabes</span></code>.</p>
<p>Suppose you meet a woman who is 35 years old, black, and a college graduate whose annual household income exceeds $75,000. How many children would you predict she has born?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">join</span><span class="p">[</span><span class="s2">&quot;numbabes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">join</span><span class="o">.</span><span class="n">numbabes</span><span class="o">.</span><span class="n">replace</span><span class="p">([</span><span class="mi">97</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
<span class="n">join</span><span class="p">[</span><span class="s2">&quot;age2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">join</span><span class="o">.</span><span class="n">age_r</span><span class="o">**</span><span class="mi">2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 60;
                var nbb_unformatted_code = "join['numbabes'] = join.numbabes.replace([97], np.nan)\njoin['age2'] = join.age_r ** 2";
                var nbb_formatted_code = "join[\"numbabes\"] = join.numbabes.replace([97], np.nan)\njoin[\"age2\"] = join.age_r**2";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="s2">&quot;numbabes ~ age_r + age2 + age3 + C(race) + totincr + educat&quot;</span>
<span class="n">formula</span> <span class="o">=</span> <span class="s2">&quot;numbabes ~ age_r + age2 + C(race) + totincr + educat&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">join</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 1.677002
         Iterations 7
</pre></div>
</div>
<div class="output text_html"><table class="simpletable">
<caption>Poisson Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>       <td>numbabes</td>     <th>  No. Observations:  </th>   <td>  8884</td>  
</tr>
<tr>
  <th>Model:</th>                <td>Poisson</td>     <th>  Df Residuals:      </th>   <td>  8877</td>  
</tr>
<tr>
  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     6</td>  
</tr>
<tr>
  <th>Date:</th>            <td>Tue, 18 Jun 2024</td> <th>  Pseudo R-squ.:     </th>   <td>0.03686</td> 
</tr>
<tr>
  <th>Time:</th>                <td>14:59:11</td>     <th>  Log-Likelihood:    </th>  <td> -14898.</td> 
</tr>
<tr>
  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -15469.</td> 
</tr>
<tr>
  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>3.681e-243</td>
</tr>
</table>
<table class="simpletable">
<tr>
        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>    <td>   -1.0324</td> <td>    0.169</td> <td>   -6.098</td> <td> 0.000</td> <td>   -1.364</td> <td>   -0.701</td>
</tr>
<tr>
  <th>C(race)[T.2]</th> <td>   -0.1401</td> <td>    0.015</td> <td>   -9.479</td> <td> 0.000</td> <td>   -0.169</td> <td>   -0.111</td>
</tr>
<tr>
  <th>C(race)[T.3]</th> <td>   -0.0991</td> <td>    0.025</td> <td>   -4.029</td> <td> 0.000</td> <td>   -0.147</td> <td>   -0.051</td>
</tr>
<tr>
  <th>age_r</th>        <td>    0.1556</td> <td>    0.010</td> <td>   15.006</td> <td> 0.000</td> <td>    0.135</td> <td>    0.176</td>
</tr>
<tr>
  <th>age2</th>         <td>   -0.0020</td> <td>    0.000</td> <td>  -13.102</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>
</tr>
<tr>
  <th>totincr</th>      <td>   -0.0187</td> <td>    0.002</td> <td>   -9.830</td> <td> 0.000</td> <td>   -0.022</td> <td>   -0.015</td>
</tr>
<tr>
  <th>educat</th>       <td>   -0.0471</td> <td>    0.003</td> <td>  -16.076</td> <td> 0.000</td> <td>   -0.053</td> <td>   -0.041</td>
</tr>
</table></div><script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 61;
                var nbb_unformatted_code = "formula = 'numbabes ~ age_r + age2 + age3 + C(race) + totincr + educat'\nformula = 'numbabes ~ age_r + age2 + C(race) + totincr + educat'\nmodel = smf.poisson(formula, data=join)\nresults = model.fit()\nresults.summary()";
                var nbb_formatted_code = "formula = \"numbabes ~ age_r + age2 + age3 + C(race) + totincr + educat\"\nformula = \"numbabes ~ age_r + age2 + C(race) + totincr + educat\"\nmodel = smf.poisson(formula, data=join)\nresults = model.fit()\nresults.summary()";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>Now we can predict the number of children for a woman who is 35 years old, black, and a college
graduate whose annual household income exceeds $75,000</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;age_r&quot;</span><span class="p">,</span> <span class="s2">&quot;age2&quot;</span><span class="p">,</span> <span class="s2">&quot;age3&quot;</span><span class="p">,</span> <span class="s2">&quot;race&quot;</span><span class="p">,</span> <span class="s2">&quot;totincr&quot;</span><span class="p">,</span> <span class="s2">&quot;educat&quot;</span><span class="p">]</span>
<span class="n">new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([[</span><span class="mi">35</span><span class="p">,</span> <span class="mi">35</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mi">35</span><span class="o">**</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">16</span><span class="p">]],</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>
<span class="n">results</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    2.496802
dtype: float64
</pre></div>
</div>
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 62;
                var nbb_unformatted_code = "columns = ['age_r', 'age2', 'age3', 'race', 'totincr', 'educat']\nnew = pd.DataFrame([[35, 35 ** 2, 35 ** 3, 1, 14, 16]], columns=columns)\nresults.predict(new)";
                var nbb_formatted_code = "columns = [\"age_r\", \"age2\", \"age3\", \"race\", \"totincr\", \"educat\"]\nnew = pd.DataFrame([[35, 35**2, 35**3, 1, 14, 16]], columns=columns)\nresults.predict(new)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p><strong>Exercise:</strong> If the quantity you want to predict is categorical, you can use multinomial logistic regression, which is implemented in StatsModels with a function called <code class="docutils literal notranslate"><span class="pre">mnlogit</span></code>. As an exercise, let’s use it to guess whether a woman is married, cohabitating, widowed, divorced, separated, or never married; in the NSFG dataset, marital status is encoded in a variable called <code class="docutils literal notranslate"><span class="pre">rmarital</span></code>.</p>
<p>Suppose you meet a woman who is 25 years old, white, and a high school graduate whose annual household income is about $45,000. What is the probability that she is married, cohabitating, etc?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="s2">&quot;rmarital ~ age_r + age2 + C(race) + totincr + educat&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">mnlogit</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">join</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 1.084053
         Iterations 8
</pre></div>
</div>
<div class="output text_html"><table class="simpletable">
<caption>MNLogit Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>       <td>rmarital</td>     <th>  No. Observations:  </th>  <td>  8884</td> 
</tr>
<tr>
  <th>Model:</th>                <td>MNLogit</td>     <th>  Df Residuals:      </th>  <td>  8849</td> 
</tr>
<tr>
  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    30</td> 
</tr>
<tr>
  <th>Date:</th>            <td>Tue, 18 Jun 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.1682</td> 
</tr>
<tr>
  <th>Time:</th>                <td>14:59:13</td>     <th>  Log-Likelihood:    </th> <td> -9630.7</td>
</tr>
<tr>
  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -11579.</td>
</tr>
<tr>
  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> 
</tr>
</table>
<table class="simpletable">
<tr>
   <th>rmarital=2</th>     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>    <td>    9.0156</td> <td>    0.805</td> <td>   11.199</td> <td> 0.000</td> <td>    7.438</td> <td>   10.593</td>
</tr>
<tr>
  <th>C(race)[T.2]</th> <td>   -0.9237</td> <td>    0.089</td> <td>  -10.418</td> <td> 0.000</td> <td>   -1.097</td> <td>   -0.750</td>
</tr>
<tr>
  <th>C(race)[T.3]</th> <td>   -0.6179</td> <td>    0.136</td> <td>   -4.536</td> <td> 0.000</td> <td>   -0.885</td> <td>   -0.351</td>
</tr>
<tr>
  <th>age_r</th>        <td>   -0.3635</td> <td>    0.051</td> <td>   -7.150</td> <td> 0.000</td> <td>   -0.463</td> <td>   -0.264</td>
</tr>
<tr>
  <th>age2</th>         <td>    0.0048</td> <td>    0.001</td> <td>    6.103</td> <td> 0.000</td> <td>    0.003</td> <td>    0.006</td>
</tr>
<tr>
  <th>totincr</th>      <td>   -0.1310</td> <td>    0.012</td> <td>  -11.337</td> <td> 0.000</td> <td>   -0.154</td> <td>   -0.108</td>
</tr>
<tr>
  <th>educat</th>       <td>   -0.1953</td> <td>    0.019</td> <td>  -10.424</td> <td> 0.000</td> <td>   -0.232</td> <td>   -0.159</td>
</tr>
<tr>
   <th>rmarital=3</th>     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>    <td>    2.9570</td> <td>    3.020</td> <td>    0.979</td> <td> 0.328</td> <td>   -2.963</td> <td>    8.877</td>
</tr>
<tr>
  <th>C(race)[T.2]</th> <td>   -0.4411</td> <td>    0.237</td> <td>   -1.863</td> <td> 0.062</td> <td>   -0.905</td> <td>    0.023</td>
</tr>
<tr>
  <th>C(race)[T.3]</th> <td>    0.0591</td> <td>    0.336</td> <td>    0.176</td> <td> 0.860</td> <td>   -0.600</td> <td>    0.718</td>
</tr>
<tr>
  <th>age_r</th>        <td>   -0.3177</td> <td>    0.177</td> <td>   -1.798</td> <td> 0.072</td> <td>   -0.664</td> <td>    0.029</td>
</tr>
<tr>
  <th>age2</th>         <td>    0.0064</td> <td>    0.003</td> <td>    2.528</td> <td> 0.011</td> <td>    0.001</td> <td>    0.011</td>
</tr>
<tr>
  <th>totincr</th>      <td>   -0.3258</td> <td>    0.032</td> <td>  -10.175</td> <td> 0.000</td> <td>   -0.389</td> <td>   -0.263</td>
</tr>
<tr>
  <th>educat</th>       <td>   -0.0991</td> <td>    0.048</td> <td>   -2.050</td> <td> 0.040</td> <td>   -0.194</td> <td>   -0.004</td>
</tr>
<tr>
   <th>rmarital=4</th>     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>    <td>   -3.5238</td> <td>    1.205</td> <td>   -2.924</td> <td> 0.003</td> <td>   -5.886</td> <td>   -1.162</td>
</tr>
<tr>
  <th>C(race)[T.2]</th> <td>   -0.3213</td> <td>    0.093</td> <td>   -3.445</td> <td> 0.001</td> <td>   -0.504</td> <td>   -0.139</td>
</tr>
<tr>
  <th>C(race)[T.3]</th> <td>   -0.7706</td> <td>    0.171</td> <td>   -4.509</td> <td> 0.000</td> <td>   -1.106</td> <td>   -0.436</td>
</tr>
<tr>
  <th>age_r</th>        <td>    0.1155</td> <td>    0.071</td> <td>    1.626</td> <td> 0.104</td> <td>   -0.024</td> <td>    0.255</td>
</tr>
<tr>
  <th>age2</th>         <td>   -0.0007</td> <td>    0.001</td> <td>   -0.701</td> <td> 0.483</td> <td>   -0.003</td> <td>    0.001</td>
</tr>
<tr>
  <th>totincr</th>      <td>   -0.2276</td> <td>    0.012</td> <td>  -19.621</td> <td> 0.000</td> <td>   -0.250</td> <td>   -0.205</td>
</tr>
<tr>
  <th>educat</th>       <td>    0.0667</td> <td>    0.017</td> <td>    3.995</td> <td> 0.000</td> <td>    0.034</td> <td>    0.099</td>
</tr>
<tr>
   <th>rmarital=5</th>     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>    <td>   -2.8963</td> <td>    1.305</td> <td>   -2.220</td> <td> 0.026</td> <td>   -5.453</td> <td>   -0.339</td>
</tr>
<tr>
  <th>C(race)[T.2]</th> <td>   -1.0407</td> <td>    0.104</td> <td>  -10.038</td> <td> 0.000</td> <td>   -1.244</td> <td>   -0.837</td>
</tr>
<tr>
  <th>C(race)[T.3]</th> <td>   -0.5661</td> <td>    0.156</td> <td>   -3.635</td> <td> 0.000</td> <td>   -0.871</td> <td>   -0.261</td>
</tr>
<tr>
  <th>age_r</th>        <td>    0.2411</td> <td>    0.079</td> <td>    3.038</td> <td> 0.002</td> <td>    0.086</td> <td>    0.397</td>
</tr>
<tr>
  <th>age2</th>         <td>   -0.0035</td> <td>    0.001</td> <td>   -2.977</td> <td> 0.003</td> <td>   -0.006</td> <td>   -0.001</td>
</tr>
<tr>
  <th>totincr</th>      <td>   -0.2932</td> <td>    0.015</td> <td>  -20.159</td> <td> 0.000</td> <td>   -0.322</td> <td>   -0.265</td>
</tr>
<tr>
  <th>educat</th>       <td>   -0.0174</td> <td>    0.021</td> <td>   -0.813</td> <td> 0.416</td> <td>   -0.059</td> <td>    0.025</td>
</tr>
<tr>
   <th>rmarital=6</th>     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>    <td>    8.0533</td> <td>    0.814</td> <td>    9.890</td> <td> 0.000</td> <td>    6.457</td> <td>    9.649</td>
</tr>
<tr>
  <th>C(race)[T.2]</th> <td>   -2.1871</td> <td>    0.080</td> <td>  -27.211</td> <td> 0.000</td> <td>   -2.345</td> <td>   -2.030</td>
</tr>
<tr>
  <th>C(race)[T.3]</th> <td>   -1.9611</td> <td>    0.138</td> <td>  -14.188</td> <td> 0.000</td> <td>   -2.232</td> <td>   -1.690</td>
</tr>
<tr>
  <th>age_r</th>        <td>   -0.2127</td> <td>    0.052</td> <td>   -4.122</td> <td> 0.000</td> <td>   -0.314</td> <td>   -0.112</td>
</tr>
<tr>
  <th>age2</th>         <td>    0.0019</td> <td>    0.001</td> <td>    2.321</td> <td> 0.020</td> <td>    0.000</td> <td>    0.003</td>
</tr>
<tr>
  <th>totincr</th>      <td>   -0.2945</td> <td>    0.012</td> <td>  -25.320</td> <td> 0.000</td> <td>   -0.317</td> <td>   -0.272</td>
</tr>
<tr>
  <th>educat</th>       <td>   -0.0742</td> <td>    0.018</td> <td>   -4.169</td> <td> 0.000</td> <td>   -0.109</td> <td>   -0.039</td>
</tr>
</table></div><script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 63;
                var nbb_unformatted_code = "formula = 'rmarital ~ age_r + age2 + C(race) + totincr + educat'\nmodel = smf.mnlogit(formula, data=join)\nresults = model.fit()\nresults.summary()";
                var nbb_formatted_code = "formula = \"rmarital ~ age_r + age2 + C(race) + totincr + educat\"\nmodel = smf.mnlogit(formula, data=join)\nresults = model.fit()\nresults.summary()";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<p>Make a prediction for a woman who is 25 years old, white, and a high
school graduate whose annual household income is about $45,000.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;age_r&quot;</span><span class="p">,</span> <span class="s2">&quot;age2&quot;</span><span class="p">,</span> <span class="s2">&quot;race&quot;</span><span class="p">,</span> <span class="s2">&quot;totincr&quot;</span><span class="p">,</span> <span class="s2">&quot;educat&quot;</span><span class="p">]</span>
<span class="n">new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]],</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>
<span class="n">results</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.750028</td>
      <td>0.126397</td>
      <td>0.001564</td>
      <td>0.033403</td>
      <td>0.021485</td>
      <td>0.067122</td>
    </tr>
  </tbody>
</table>
</div></div><script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 64;
                var nbb_unformatted_code = "columns = ['age_r', 'age2', 'race', 'totincr', 'educat']\nnew = pd.DataFrame([[25, 25 ** 2, 2, 11, 12]], columns=columns)\nresults.predict(new)";
                var nbb_formatted_code = "columns = [\"age_r\", \"age2\", \"race\", \"totincr\", \"educat\"]\nnew = pd.DataFrame([[25, 25**2, 2, 11, 12]], columns=columns)\nresults.predict(new)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="chap10.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Linear least squares</p>
      </div>
    </a>
    <a class="right-next"
       href="chap12.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Time series analysis</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statsmodels">StatsModels</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-regression">Multiple regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nonlinear-relationships">Nonlinear relationships</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-mining">Data mining</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prediction">Prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression">Logistic regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-parameters">Estimating parameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#accuracy">Accuracy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glossary">Glossary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Allen B. Downey
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>