
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Regression &#8212; Think Stats, 3rd edition</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]]}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chap11';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Time series analysis" href="chap12.html" />
    <link rel="prev" title="Linear least squares" href="chap10.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
  
    <p class="title logo__title">Think Stats, 3rd edition</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="index.html">
                    Think Stats, 3rd edition
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="chap00.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap01.html">Exploratory data analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap02.html">Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap03.html">Probability mass functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap04.html">Cumulative distribution functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap05.html">Modeling distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap06.html">Probability density functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap07.html">Relationships between variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap08.html">Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap09.html">Hypothesis testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap10.html">Linear least squares</a></li>

<li class="toctree-l1 current active"><a class="current reference internal" href="#">Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap12.html">Time series analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap13.html">Survival analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap14.html">Analytic methods</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/AllenDowney/ThinkStats/tree/v3" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/chap11.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Regression</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statsmodels">StatsModels</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-regression">Multiple regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nonlinear-relationships">Nonlinear relationships</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-mining">Data mining</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prediction">Prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression">Logistic regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-parameters">Estimating parameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#accuracy">Accuracy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glossary">Glossary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="regression">
<h1>Regression<a class="headerlink" href="#regression" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">basename</span><span class="p">,</span> <span class="n">exists</span>


<span class="k">def</span> <span class="nf">download</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="n">basename</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">urllib.request</span> <span class="kn">import</span> <span class="n">urlretrieve</span>

        <span class="n">local</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Downloaded &quot;</span> <span class="o">+</span> <span class="n">local</span><span class="p">)</span>


<span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkstats2.py&quot;</span><span class="p">)</span>
<span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkplot.py&quot;</span><span class="p">)</span>
<span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats2/raw/master/code/regression.py&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloaded regression.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">thinkstats2</span>
<span class="kn">import</span> <span class="nn">thinkplot</span>
</pre></div>
</div>
</div>
</div>
<p>The linear least squares fit in the previous chapter is an example of
<strong>regression</strong>, which is the more general problem of fitting any kind of
model to any kind of data. This use of the term “regression” is a
historical accident; it is only indirectly related to the original
meaning of the word.</p>
<p>The goal of regression analysis is to describe the relationship between
one set of variables, called the <strong>dependent variables</strong>, and another
set of variables, called independent or <strong>explanatory variables</strong>.</p>
<p>In the previous chapter we used mother’s age as an explanatory variable
to predict birth weight as a dependent variable. When there is only one
dependent and one explanatory variable, that’s <strong>simple regression</strong>. In
this chapter, we move on to <strong>multiple regression</strong>, with more than one
explanatory variable. If there is more than one dependent variable,
that’s multivariate regression.</p>
<p>If the relationship between the dependent and explanatory variable is
linear, that’s <strong>linear regression</strong>. For example, if the dependent
variable is <span class="math notranslate nohighlight">\(y\)</span> and the explanatory variables are <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span>, we
would write the following linear regression model:
$<span class="math notranslate nohighlight">\(y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \eps\)</span><span class="math notranslate nohighlight">\( where \)</span>\beta_0<span class="math notranslate nohighlight">\( is
the intercept, \)</span>\beta_1<span class="math notranslate nohighlight">\( is the parameter associated with \)</span>x_1<span class="math notranslate nohighlight">\(,
\)</span>\beta_2<span class="math notranslate nohighlight">\( is the parameter associated with \)</span>x_2<span class="math notranslate nohighlight">\(, and \)</span>\eps$ is the
residual due to random variation or other unknown factors.</p>
<p>Given a sequence of values for <span class="math notranslate nohighlight">\(y\)</span> and sequences for <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span>, we
can find the parameters, <span class="math notranslate nohighlight">\(\beta_0\)</span>, <span class="math notranslate nohighlight">\(\beta_1\)</span>, and <span class="math notranslate nohighlight">\(\beta_2\)</span>, that
minimize the sum of <span class="math notranslate nohighlight">\(\eps^2\)</span>. This process is called <strong>ordinary least
squares</strong>. The computation is similar to <code class="docutils literal notranslate"><span class="pre">thinkstats2.LeastSquare</span></code>, but
generalized to deal with more than one explanatory variable. You can
find the details at
<a class="reference external" href="https://en.wikipedia.org/wiki/Ordinary_least_squares">https://en.wikipedia.org/wiki/Ordinary_least_squares</a></p>
<section id="statsmodels">
<h2>StatsModels<a class="headerlink" href="#statsmodels" title="Link to this heading">#</a></h2>
<p>In the previous chapter I presented <code class="docutils literal notranslate"><span class="pre">thinkstats2.LeastSquares</span></code>, an
implementation of simple linear regression intended to be easy to read.
For multiple regression we’ll switch to StatsModels, a Python package
that provides several forms of regression and other analyses. If you are
using Anaconda, you already have StatsModels; otherwise you might have
to install it.</p>
<p>As an example, I’ll run the model from the previous chapter with
StatsModels:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats2/raw/master/code/nsfg.py&quot;</span><span class="p">)</span>
<span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats2/raw/master/code/first.py&quot;</span><span class="p">)</span>

<span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemPreg.dct&quot;</span><span class="p">)</span>
<span class="n">download</span><span class="p">(</span>
    <span class="s2">&quot;https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemPreg.dat.gz&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">first</span>

<span class="n">live</span><span class="p">,</span> <span class="n">firsts</span><span class="p">,</span> <span class="n">others</span> <span class="o">=</span> <span class="n">first</span><span class="o">.</span><span class="n">MakeFrames</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;totalwgt_lb ~ agepreg&#39;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">live</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> provides two interfaces (APIs); the “formula” API uses
strings to identify the dependent and explanatory variables. It uses a
syntax called <code class="docutils literal notranslate"><span class="pre">patsy</span></code>; in this example, the <code class="docutils literal notranslate"><span class="pre">~</span></code> operator separates the
dependent variable on the left from the explanatory variables on the
right.</p>
<p><code class="docutils literal notranslate"><span class="pre">smf.ols</span></code> takes the formula string and the DataFrame, <code class="docutils literal notranslate"><span class="pre">live</span></code>, and
returns an OLS object that represents the model. The name <code class="docutils literal notranslate"><span class="pre">ols</span></code> stands
for “ordinary least squares.”</p>
<p>The <code class="docutils literal notranslate"><span class="pre">fit</span></code> method fits the model to the data and returns a
RegressionResults object that contains the results.</p>
<p>The results are also available as attributes. <code class="docutils literal notranslate"><span class="pre">params</span></code> is a Series that
maps from variable names to their parameters, so we can get the
intercept and slope like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inter</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;Intercept&#39;</span><span class="p">]</span>
<span class="n">slope</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;agepreg&#39;</span><span class="p">]</span>
<span class="n">inter</span><span class="p">,</span> <span class="n">slope</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(6.830396973311051, 0.017453851471802638)
</pre></div>
</div>
</div>
</div>
<p>The estimated parameters are 6.83 and 0.0175, the same as from
<code class="docutils literal notranslate"><span class="pre">LeastSquares</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">pvalues</span></code> is a Series that maps from variable names to the associated
p-values, so we can check whether the estimated slope is statistically
significant:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">slope_pvalue</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">pvalues</span><span class="p">[</span><span class="s1">&#39;agepreg&#39;</span><span class="p">]</span>
<span class="n">slope_pvalue</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">rsquared</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.004738115474710369
</pre></div>
</div>
</div>
</div>
<p>The p-value associated with <code class="docutils literal notranslate"><span class="pre">agepreg</span></code> is <code class="docutils literal notranslate"><span class="pre">5.7e-11</span></code>, which is less than
<span class="math notranslate nohighlight">\(0.001\)</span>, as expected.</p>
<p><code class="docutils literal notranslate"><span class="pre">results.rsquared</span></code> contains <span class="math notranslate nohighlight">\(R^2\)</span>, which is <span class="math notranslate nohighlight">\(0.0047\)</span>. <code class="docutils literal notranslate"><span class="pre">results</span></code> also
provides <code class="docutils literal notranslate"><span class="pre">f_pvalue</span></code>, which is the p-value associated with the model as a
whole, similar to testing whether <span class="math notranslate nohighlight">\(R^2\)</span> is statistically significant.</p>
<p>And <code class="docutils literal notranslate"><span class="pre">results</span></code> provides <code class="docutils literal notranslate"><span class="pre">resid</span></code>, a sequence of residuals, and
<code class="docutils literal notranslate"><span class="pre">fittedvalues</span></code>, a sequence of fitted values corresponding to <code class="docutils literal notranslate"><span class="pre">agepreg</span></code>.</p>
<p>The results object provides <code class="docutils literal notranslate"><span class="pre">summary()</span></code>, which represents the results in
a readable format.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>       <td>totalwgt_lb</td>   <th>  R-squared:         </th> <td>   0.005</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.005</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   43.02</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Mon, 17 Jun 2024</td> <th>  Prob (F-statistic):</th> <td>5.72e-11</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>09:45:19</td>     <th>  Log-Likelihood:    </th> <td> -15897.</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td>  9038</td>      <th>  AIC:               </th> <td>3.180e+04</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>  9036</td>      <th>  BIC:               </th> <td>3.181e+04</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>    6.8304</td> <td>    0.068</td> <td>  100.470</td> <td> 0.000</td> <td>    6.697</td> <td>    6.964</td>
</tr>
<tr>
  <th>agepreg</th>   <td>    0.0175</td> <td>    0.003</td> <td>    6.559</td> <td> 0.000</td> <td>    0.012</td> <td>    0.023</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>1024.052</td> <th>  Durbin-Watson:     </th> <td>   1.618</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3081.833</td>
</tr>
<tr>
  <th>Skew:</th>           <td>-0.601</td>  <th>  Prob(JB):          </th> <td>    0.00</td>
</tr>
<tr>
  <th>Kurtosis:</th>       <td> 5.596</td>  <th>  Cond. No.          </th> <td>    118.</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p>But it prints a lot of information that is not relevant (yet), so I use
a simpler function called <code class="docutils literal notranslate"><span class="pre">SummarizeResults</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">regression</span> <span class="kn">import</span> <span class="n">SummarizeResults</span>

<span class="n">SummarizeResults</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   6.83   (0)
agepreg   0.0175   (5.72e-11)
R^2 0.004738
Std(ys) 1.408
Std(res) 1.405
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">Std(ys)</span></code> is the standard deviation of the dependent variable, which is
the RMSE if you have to guess birth weights without the benefit of any
explanatory variables. <code class="docutils literal notranslate"><span class="pre">Std(res)</span></code> is the standard deviation of the
residuals, which is the RMSE if your guesses are informed by the
mother’s age. As we have already seen, knowing the mother’s age provides
no substantial improvement to the predictions.</p>
</section>
<section id="multiple-regression">
<h2>Multiple regression<a class="headerlink" href="#multiple-regression" title="Link to this heading">#</a></h2>
<p>In Section <a class="reference internal" href="#birth_weights"><span class="xref myst">[birth_weights]</span></a>{reference-type=“ref”
reference=“birth_weights”} we saw that first babies tend to be lighter
than others, and this effect is statistically significant. But it is a
strange result because there is no obvious mechanism that would cause
first babies to be lighter. So we might wonder whether this relationship
is <strong>spurious</strong>.</p>
<p>In fact, there is a possible explanation for this effect. We have seen
that birth weight depends on mother’s age, and we might expect that
mothers of first babies are younger than others.</p>
<p>With a few calculations we can check whether this explanation is
plausible. Then we’ll use multiple regression to investigate more
carefully. First, let’s see how big the difference in weight is:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">diff_weight</span> <span class="o">=</span> <span class="n">firsts</span><span class="o">.</span><span class="n">totalwgt_lb</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">others</span><span class="o">.</span><span class="n">totalwgt_lb</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">diff_weight</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.12476118453549034
</pre></div>
</div>
</div>
</div>
<p>First babies are 0.125 lbs lighter, or 2 ounces. And the difference in
ages:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">diff_age</span> <span class="o">=</span> <span class="n">firsts</span><span class="o">.</span><span class="n">agepreg</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">others</span><span class="o">.</span><span class="n">agepreg</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">diff_age</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-3.5864347661500275
</pre></div>
</div>
</div>
</div>
<p>The mothers of first babies are 3.59 years younger. Running the linear
model again, we get the change in birth weight as a function of age:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;totalwgt_lb ~ agepreg&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">live</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">slope</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;agepreg&#39;</span><span class="p">]</span>
<span class="n">slope</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.017453851471802638
</pre></div>
</div>
</div>
</div>
<p>The slope is 0.0175 pounds per year. If we multiply the slope by the
difference in ages, we get the expected difference in birth weight for
first babies and others, due to mother’s age:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">slope</span> <span class="o">*</span> <span class="n">diff_age</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.0625970997216918
</pre></div>
</div>
</div>
</div>
<p>The result is 0.063, just about half of the observed difference. So we
conclude, tentatively, that the observed difference in birth weight can
be partly explained by the difference in mother’s age.</p>
<p>Using multiple regression, we can explore these relationships more
systematically.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">live</span><span class="p">[</span><span class="s1">&#39;isfirst&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">live</span><span class="o">.</span><span class="n">birthord</span> <span class="o">==</span> <span class="mi">1</span>
<span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;totalwgt_lb ~ isfirst&#39;</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">live</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The first line creates a new column named <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> that is True for
first babies and false otherwise. Then we fit a model using <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> as
an explanatory variable.</p>
<p>Here are the results:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SummarizeResults</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   7.33   (0)
isfirst[T.True]   -0.125   (2.55e-05)
R^2 0.00196
Std(ys) 1.408
Std(res) 1.407
</pre></div>
</div>
</div>
</div>
<p>Because <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> is a boolean, <code class="docutils literal notranslate"><span class="pre">ols</span></code> treats it as a <strong>categorical
variable</strong>, which means that the values fall into categories, like True
and False, and should not be treated as numbers. The estimated parameter
is the effect on birth weight when <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> is true, so the result,
-0.125 lbs, is the difference in birth weight between first babies and
others.</p>
<p>The slope and the intercept are statistically significant, which means
that they were unlikely to occur by chance, but the the <span class="math notranslate nohighlight">\(R^2\)</span> value for
this model is small, which means that <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> doesn’t account for a
substantial part of the variation in birth weight.</p>
<p>The results are similar with <code class="docutils literal notranslate"><span class="pre">agepreg</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;totalwgt_lb ~ agepreg&#39;</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">live</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">SummarizeResults</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   6.83   (0)
agepreg   0.0175   (5.72e-11)
R^2 0.004738
Std(ys) 1.408
Std(res) 1.405
</pre></div>
</div>
</div>
</div>
<p>Again, the parameters are statistically significant, but <span class="math notranslate nohighlight">\(R^2\)</span> is low.</p>
<p>These models confirm results we have already seen. But now we can fit a
single model that includes both variables. With the formula
<code class="docutils literal notranslate"><span class="pre">totalwgt_lb</span> <span class="pre">~</span> <span class="pre">isfirst</span> <span class="pre">+</span> <span class="pre">agepreg</span></code>, we get:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;totalwgt_lb ~ isfirst + agepreg&#39;</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">live</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">SummarizeResults</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   6.91   (0)
isfirst[T.True]   -0.0698   (0.0253)
agepreg   0.0154   (3.93e-08)
R^2 0.005289
Std(ys) 1.408
Std(res) 1.405
</pre></div>
</div>
</div>
</div>
<p>In the combined model, the parameter for <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> is smaller by about
half, which means that part of the apparent effect of <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> is
actually accounted for by <code class="docutils literal notranslate"><span class="pre">agepreg</span></code>. And the p-value for <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> is
about 2.5%, which is on the border of statistical significance.</p>
<p><span class="math notranslate nohighlight">\(R^2\)</span> for this model is a little higher, which indicates that the two
variables together account for more variation in birth weight than
either alone (but not by much).</p>
</section>
<section id="nonlinear-relationships">
<h2>Nonlinear relationships<a class="headerlink" href="#nonlinear-relationships" title="Link to this heading">#</a></h2>
<p>Remembering that the contribution of <code class="docutils literal notranslate"><span class="pre">agepreg</span></code> might be nonlinear, we
might consider adding a variable to capture more of this relationship.
One option is to create a column, <code class="docutils literal notranslate"><span class="pre">agepreg2</span></code>, that contains the squares
of the ages:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">live</span><span class="p">[</span><span class="s1">&#39;agepreg2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">live</span><span class="o">.</span><span class="n">agepreg</span><span class="o">**</span><span class="mi">2</span>
<span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;totalwgt_lb ~ isfirst + agepreg + agepreg2&#39;</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">live</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Now by estimating parameters for <code class="docutils literal notranslate"><span class="pre">agepreg</span></code> and <code class="docutils literal notranslate"><span class="pre">agepreg2</span></code>, we are
effectively fitting a parabola:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SummarizeResults</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   6.91   (0)
isfirst[T.True]   -0.0698   (0.0253)
agepreg   0.0154   (3.93e-08)
R^2 0.005289
Std(ys) 1.408
Std(res) 1.405
</pre></div>
</div>
</div>
</div>
<p>The parameter of <code class="docutils literal notranslate"><span class="pre">agepreg2</span></code> is negative, so the parabola curves
downward, which is consistent with the shape of the lines in
Figure <a class="reference internal" href="#linear2"><span class="xref myst">[linear2]</span></a>{reference-type=“ref”
reference=“linear2”}.</p>
<p>The quadratic model of <code class="docutils literal notranslate"><span class="pre">agepreg</span></code> accounts for more of the variability in
birth weight; the parameter for <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> is smaller in this model, and
no longer statistically significant.</p>
<p>Using computed variables like <code class="docutils literal notranslate"><span class="pre">agepreg2</span></code> is a common way to fit
polynomials and other functions to data. This process is still
considered linear regression, because the dependent variable is a linear
function of the explanatory variables, regardless of whether some
variables are nonlinear functions of others.</p>
<p>The following table summarizes the results of these regressions:</p>
<p>center
isfirst        agepreg     agepreg2     <span class="math notranslate nohighlight">\(R^2\)</span></p>
<hr class="docutils" />
<p>Model 1       -0.125 *         –           –        0.002
Model 2          –          0.0175 *       –        0.0047
Model 3    -0.0698 (0.025)   0.0154 *       –        0.0053
Model 4    -0.0504 (0.11)    0.112 *    -0.00185 *   0.0075</p>
<p>The columns in this table are the explanatory variables and the
coefficient of determination, <span class="math notranslate nohighlight">\(R^2\)</span>. Each entry is an estimated
parameter and either a p-value in parentheses or an asterisk to indicate
a p-value less that 0.001.</p>
<p>We conclude that the apparent difference in birth weight is explained,
at least in part, by the difference in mother’s age. When we include
mother’s age in the model, the effect of <code class="docutils literal notranslate"><span class="pre">isfirst</span></code> gets smaller, and the
remaining effect might be due to chance.</p>
<p>In this example, mother’s age acts as a <strong>control variable</strong>; including
<code class="docutils literal notranslate"><span class="pre">agepreg</span></code> in the model “controls for” the difference in age between
first-time mothers and others, making it possible to isolate the effect
(if any) of <code class="docutils literal notranslate"><span class="pre">isfirst</span></code>.</p>
</section>
<section id="data-mining">
<h2>Data mining<a class="headerlink" href="#data-mining" title="Link to this heading">#</a></h2>
<p>So far we have used regression models for explanation; for example, in
the previous section we discovered that an apparent difference in birth
weight is actually due to a difference in mother’s age. But the <span class="math notranslate nohighlight">\(R^2\)</span>
values of those models is very low, which means that they have little
predictive power. In this section we’ll try to do better.</p>
<p>Suppose one of your co-workers is expecting a baby and there is an
office pool to guess the baby’s birth weight (if you are not familiar
with betting pools, see <a class="reference external" href="https://en.wikipedia.org/wiki/Betting_pool">https://en.wikipedia.org/wiki/Betting_pool</a>).</p>
<p>Now suppose that you <em>really</em> want to win the pool. What could you do to
improve your chances? Well, the NSFG dataset includes 244 variables
about each pregnancy and another 3087 variables about each respondent.
Maybe some of those variables have predictive power. To find out which
ones are most useful, why not try them all?</p>
<p>Testing the variables in the pregnancy table is easy, but in order to
use the variables in the respondent table, we have to match up each
pregnancy with a respondent. In theory we could iterate through the rows
of the pregnancy table, use the <code class="docutils literal notranslate"><span class="pre">caseid</span></code> to find the corresponding
respondent, and copy the values from the correspondent table into the
pregnancy table. But that would be slow.</p>
<p>A better option is to recognize this process as a <strong>join</strong> operation as
defined in SQL and other relational database languages (see
<a class="reference external" href="https://en.wikipedia.org/wiki/Join_(SQL)">https://en.wikipedia.org/wiki/Join_(SQL)</a>). Join is implemented as a
DataFrame method, so we can perform the operation like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemResp.dct&quot;</span><span class="p">)</span>
<span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemResp.dat.gz&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nsfg</span>

<span class="n">live</span> <span class="o">=</span> <span class="n">live</span><span class="p">[</span><span class="n">live</span><span class="o">.</span><span class="n">prglngth</span><span class="o">&gt;</span><span class="mi">30</span><span class="p">]</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">nsfg</span><span class="o">.</span><span class="n">ReadFemResp</span><span class="p">()</span>
<span class="n">resp</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">caseid</span>
<span class="n">join</span> <span class="o">=</span> <span class="n">live</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">resp</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;caseid&#39;</span><span class="p">,</span> <span class="n">rsuffix</span><span class="o">=</span><span class="s1">&#39;_r&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The first line selects records for pregnancies longer than 30 weeks,
assuming that the office pool is formed several weeks before the due
date.</p>
<p>The next line reads the respondent file. The result is a DataFrame with
integer indices; in order to look up respondents efficiently, I replace
<code class="docutils literal notranslate"><span class="pre">resp.index</span></code> with <code class="docutils literal notranslate"><span class="pre">resp.caseid</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">join</span></code> method is invoked on <code class="docutils literal notranslate"><span class="pre">live</span></code>, which is considered the “left”
table, and passed <code class="docutils literal notranslate"><span class="pre">resp</span></code>, which is the “right” table. The keyword
argument <code class="docutils literal notranslate"><span class="pre">on</span></code> indicates the variable used to match up rows from the two
tables.</p>
<p>In this example some column names appear in both tables, so we have to
provide <code class="docutils literal notranslate"><span class="pre">rsuffix</span></code>, which is a string that will be appended to the names
of overlapping columns from the right table. For example, both tables
have a column named <code class="docutils literal notranslate"><span class="pre">race</span></code> that encodes the race of the respondent. The
result of the join contains two columns named <code class="docutils literal notranslate"><span class="pre">race</span></code> and <code class="docutils literal notranslate"><span class="pre">race_r</span></code>.</p>
<p>The Pandas implementation is fast. Joining the NSFG tables takes less
than a second on an ordinary desktop computer. Now we can start testing
variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">join</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">join</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">1e-7</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;totalwgt_lb ~ agepreg + &#39;</span> <span class="o">+</span> <span class="n">name</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">join</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">nobs</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">join</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
        <span class="k">continue</span>

    <span class="n">t</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">results</span><span class="o">.</span><span class="n">rsquared</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;$R^2$&#39;</span><span class="p">,</span> <span class="s1">&#39;column&#39;</span><span class="p">]</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;$R^2$&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>$R^2$</th>
      <th>column</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>107</th>
      <td>1.000000</td>
      <td>totalwgt_lb</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.949813</td>
      <td>birthwgt_lb</td>
    </tr>
    <tr>
      <th>49</th>
      <td>0.300824</td>
      <td>lbw1</td>
    </tr>
    <tr>
      <th>39</th>
      <td>0.130125</td>
      <td>prglngth</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.123400</td>
      <td>wksgest</td>
    </tr>
    <tr>
      <th>44</th>
      <td>0.102031</td>
      <td>agecon</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.027144</td>
      <td>mosgest</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.018551</td>
      <td>babysex</td>
    </tr>
    <tr>
      <th>62</th>
      <td>0.016200</td>
      <td>race</td>
    </tr>
    <tr>
      <th>517</th>
      <td>0.016200</td>
      <td>race_r</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>For each variable we construct a model, compute <span class="math notranslate nohighlight">\(R^2\)</span>, and append the
results to a list. The models all include <code class="docutils literal notranslate"><span class="pre">agepreg</span></code>, since we already
know that it has some predictive power.</p>
<p>I check that each explanatory variable has some variability; otherwise
the results of the regression are unreliable. I also check the number of
observations for each model. Variables that contain a large number of
<code class="docutils literal notranslate"><span class="pre">nan</span></code>s are not good candidates for prediction.</p>
<p>For most of these variables, we haven’t done any cleaning. Some of them
are encoded in ways that don’t work very well for linear regression. As
a result, we might overlook some variables that would be useful if they
were cleaned properly. But maybe we will find some good candidates.</p>
</section>
<section id="prediction">
<h2>Prediction<a class="headerlink" href="#prediction" title="Link to this heading">#</a></h2>
<p>The next step is to sort the results and select the variables that yield
the highest values of <span class="math notranslate nohighlight">\(R^2\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>

<span class="k">def</span> <span class="nf">ReadVariables</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Reads Stata dictionary files for NSFG data.</span>

<span class="sd">    returns: DataFrame that maps variables names to descriptions</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">vars1</span> <span class="o">=</span> <span class="n">thinkstats2</span><span class="o">.</span><span class="n">ReadStataDct</span><span class="p">(</span><span class="s1">&#39;2002FemPreg.dct&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">variables</span>
    <span class="n">vars2</span> <span class="o">=</span> <span class="n">thinkstats2</span><span class="o">.</span><span class="n">ReadStataDct</span><span class="p">(</span><span class="s1">&#39;2002FemResp.dct&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">variables</span>

    <span class="n">all_vars</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">vars1</span><span class="p">,</span> <span class="n">vars2</span><span class="p">])</span>
    <span class="n">all_vars</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">all_vars</span><span class="o">.</span><span class="n">name</span>
    <span class="k">return</span> <span class="n">all_vars</span>

<span class="k">def</span> <span class="nf">MiningReport</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Prints variables with the highest R^2.</span>

<span class="sd">    t: list of (R^2, variable name) pairs</span>
<span class="sd">    n: number of pairs to print</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">all_vars</span> <span class="o">=</span> <span class="n">ReadVariables</span><span class="p">()</span>

    <span class="n">variables</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">r2</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">[:</span><span class="n">n</span><span class="p">]:</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;_r$&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">desc</span> <span class="o">=</span> <span class="n">all_vars</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">desc</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">desc</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
                <span class="n">desc</span> <span class="o">=</span> <span class="n">desc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">r2</span><span class="p">,</span> <span class="n">desc</span><span class="p">)</span>
        <span class="k">except</span> <span class="p">(</span><span class="ne">KeyError</span><span class="p">,</span> <span class="ne">IndexError</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">r2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">MiningReport</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>totalwgt_lb 1.0
birthwgt_lb 0.9498127305978009 BD-3 BIRTHWEIGHT IN POUNDS - 1ST BABY FROM THIS PREGNANCY
lbw1 0.3008240784470769 LOW BIRTHWEIGHT - BABY 1
prglngth 0.13012519488625085 DURATION OF COMPLETED PREGNANCY IN WEEKS
wksgest 0.12340041363361076 GESTATIONAL LENGTH OF COMPLETED PREGNANCY (IN WEEKS)
agecon 0.10203149928156052 AGE AT TIME OF CONCEPTION
mosgest 0.02714427463957958 GESTATIONAL LENGTH OF COMPLETED PREGNANCY (IN MONTHS)
babysex 0.018550925293942533 BD-2 SEX OF 1ST LIVEBORN BABY FROM THIS PREGNANCY
race_r 0.016199503586253106 RACE
race 0.016199503586253106 RACE
nbrnaliv 0.016017752709788113 BC-2 NUMBER OF BABIES BORN ALIVE FROM THIS PREGNANCY
paydu 0.014003795578114597 IB-10 CURRENT LIVING QUARTERS OWNED/RENTED, ETC
rmarout03 0.01343006646571343 INFORMAL MARITAL STATUS WHEN PREGNANCY ENDED - 3RD
birthwgt_oz 0.013102457615706498 BD-3 BIRTHWEIGHT IN OUNCES - 1ST BABY FROM THIS PREGNANCY
anynurse 0.012529022541810653 BH-1 WHETHER R BREASTFED THIS CHILD AT ALL - 1ST FROM THIS PREG
bfeedwks 0.012193688404495417 DURATION OF BREASTFEEDING IN WEEKS
totincr 0.011870069031173158 TOTAL INCOME OF R&#39;S FAMILY
marout03 0.011807801994375033 FORMAL MARITAL STATUS WHEN PREGNANCY ENDED - 3RD
marcon03 0.011752599354395321 FORMAL MARITAL STATUS WHEN PREGNANCY BEGAN - 3RD
cebow 0.011437770919637269 NUMBER OF CHILDREN BORN OUT OF WEDLOCK
rmarout01 0.011407737138640073 INFORMAL MARITAL STATUS WHEN PREGNANCY ENDED - 1ST
rmarout6 0.011354138472805753 INFORMAL MARITAL STATUS AT PREGNANCY OUTCOME - 6 CATEGORIES
marout01 0.011269357246806444 FORMAL MARITAL STATUS WHEN PREGNANCY ENDED - 1ST
hisprace_r 0.01123834930203138 RACE AND HISPANIC ORIGIN
hisprace 0.01123834930203138 RACE AND HISPANIC ORIGIN
mar1diss 0.0109615635907514 MONTHS BTW/1ST MARRIAGE &amp; DISSOLUTION (OR INTERVIEW)
fmarcon5 0.0106049646842995 FORMAL MARITAL STATUS AT CONCEPTION - 5 CATEGORIES
rmarout02 0.010546913206564978 INFORMAL MARITAL STATUS WHEN PREGNANCY ENDED - 2ND
marcon02 0.01048140179553414 FORMAL MARITAL STATUS WHEN PREGNANCY BEGAN - 2ND
fmarout5 0.010461691367377068 FORMAL MARITAL STATUS AT PREGNANCY OUTCOME
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_171984/255888651.py:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  desc = desc[0]
</pre></div>
</div>
</div>
</div>
<p>The first variable on the list is <code class="docutils literal notranslate"><span class="pre">totalwgt_lb</span></code>, followed by
<code class="docutils literal notranslate"><span class="pre">birthwgt_lb</span></code>. Obviously, we can’t use birth weight to predict birth
weight.</p>
<p>Similarly <code class="docutils literal notranslate"><span class="pre">prglngth</span></code> has useful predictive power, but for the office
pool we assume pregnancy length (and the related variables) are not
known yet.</p>
<p>The first useful predictive variable is <code class="docutils literal notranslate"><span class="pre">babysex</span></code> which indicates
whether the baby is male or female. In the NSFG dataset, boys are about
0.3 lbs heavier. So, assuming that the sex of the baby is known, we can
use it for prediction.</p>
<p>Next is <code class="docutils literal notranslate"><span class="pre">race</span></code>, which indicates whether the respondent is white, black,
or other. As an explanatory variable, race can be problematic. In
datasets like the NSFG, race is correlated with many other variables,
including income and other socioeconomic factors. In a regression model,
race acts as a <strong>proxy variable</strong>, so apparent correlations with race
are often caused, at least in part, by other factors.</p>
<p>The next variable on the list is <code class="docutils literal notranslate"><span class="pre">nbrnaliv</span></code>, which indicates whether the
pregnancy yielded multiple births. Twins and triplets tend to be smaller
than other babies, so if we know whether our hypothetical co-worker is
expecting twins, that would help.</p>
<p>Next on the list is <code class="docutils literal notranslate"><span class="pre">paydu</span></code>, which indicates whether the respondent owns
her home. It is one of several income-related variables that turn out to
be predictive. In datasets like the NSFG, income and wealth are
correlated with just about everything. In this example, income is
related to diet, health, health care, and other factors likely to affect
birth weight.</p>
<p>Some of the other variables on the list are things that would not be
known until later, like <code class="docutils literal notranslate"><span class="pre">bfeedwks</span></code>, the number of weeks the baby was
breast fed. We can’t use these variables for prediction, but you might
want to speculate on reasons <code class="docutils literal notranslate"><span class="pre">bfeedwks</span></code> might be correlated with birth
weight.</p>
<p>Sometimes you start with a theory and use data to test it. Other times
you start with data and go looking for possible theories. The second
approach, which this section demonstrates, is called <strong>data mining</strong>. An
advantage of data mining is that it can discover unexpected patterns. A
hazard is that many of the patterns it discovers are either random or
spurious.</p>
<p>Having identified potential explanatory variables, I tested a few models
and settled on this one:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;totalwgt_lb ~ agepreg + C(race) + babysex==1 + &#39;</span>
           <span class="s1">&#39;nbrnaliv&gt;1 + paydu==1 + totincr&#39;</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">join</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>This formula uses some syntax we have not seen yet: <code class="docutils literal notranslate"><span class="pre">C(race)</span></code> tells the
formula parser (Patsy) to treat race as a categorical variable, even
though it is encoded numerically.</p>
<p>The encoding for <code class="docutils literal notranslate"><span class="pre">babysex</span></code> is 1 for male, 2 for female; writing
<code class="docutils literal notranslate"><span class="pre">babysex==1</span></code> converts it to boolean, True for male and false for female.</p>
<p>Similarly <code class="docutils literal notranslate"><span class="pre">nbrnaliv&gt;1</span></code> is True for multiple births and <code class="docutils literal notranslate"><span class="pre">paydu==1</span></code> is
True for respondents who own their houses.</p>
<p><code class="docutils literal notranslate"><span class="pre">totincr</span></code> is encoded numerically from 1-14, with each increment
representing about $5000 in annual income.</p>
<p>So we can treat these values as numerical, expressed in units of $5000.</p>
<p>Here are the results of the model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SummarizeResults</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   6.63   (0)
C(race)[T.2]   0.357   (5.43e-29)
C(race)[T.3]   0.266   (2.33e-07)
babysex == 1[T.True]   0.295   (5.39e-29)
nbrnaliv &gt; 1[T.True]   -1.38   (5.1e-37)
paydu == 1[T.True]   0.12   (0.000114)
agepreg   0.00741   (0.0035)
totincr   0.0122   (0.00188)
R^2 0.05999
Std(ys) 1.271
Std(res) 1.232
</pre></div>
</div>
</div>
</div>
<p>The estimated parameters for race are larger than I expected, especially
since we control for income. The encoding is 1 for black, 2 for white,
and 3 for other. Babies of black mothers are lighter than babies of
other races by 0.27–0.36 lbs.</p>
<p>As we’ve already seen, boys are heavier by about 0.3 lbs; twins and
other multiplets are lighter by 1.4 lbs.</p>
<p>People who own their homes have heavier babies by about 0.12 lbs, even
when we control for income. The parameter for mother’s age is smaller
than what we saw in
Section <a class="reference internal" href="#multiple"><span class="xref myst">[multiple]</span></a>{reference-type=“ref”
reference=“multiple”}, which suggests that some of the other variables
are correlated with age, probably including <code class="docutils literal notranslate"><span class="pre">paydu</span></code> and <code class="docutils literal notranslate"><span class="pre">totincr</span></code>.</p>
<p>All of these variables are statistically significant, some with very low
p-values, but <span class="math notranslate nohighlight">\(R^2\)</span> is only 0.06, still quite small. RMSE without using
the model is 1.27 lbs; with the model it drops to 1.23. So your chance
of winning the pool is not substantially improved. Sorry!</p>
</section>
<section id="logistic-regression">
<h2>Logistic regression<a class="headerlink" href="#logistic-regression" title="Link to this heading">#</a></h2>
<p>In the previous examples, some of the explanatory variables were
numerical and some categorical (including boolean). But the dependent
variable was always numerical.</p>
<p>Linear regression can be generalized to handle other kinds of dependent
variables. If the dependent variable is boolean, the generalized model
is called <strong>logistic regression</strong>. If the dependent variable is an
integer count, it’s called <strong>Poisson regression</strong>.</p>
<p>As an example of logistic regression, let’s consider a variation on the
office pool scenario. Suppose a friend of yours is pregnant and you want
to predict whether the baby is a boy or a girl. You could use data from
the NSFG to find factors that affect the “sex ratio”, which is
conventionally defined to be the probability of having a boy.</p>
<p>If you encode the dependent variable numerically, for example 0 for a
girl and 1 for a boy, you could apply ordinary least squares, but there
would be problems. The linear model might be something like this:
$<span class="math notranslate nohighlight">\(y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \eps\)</span><span class="math notranslate nohighlight">\( Where \)</span>y<span class="math notranslate nohighlight">\( is the
dependent variable, and \)</span>x_1<span class="math notranslate nohighlight">\( and \)</span>x_2$ are explanatory variables. Then
we could find the parameters that minimize the residuals.</p>
<p>The problem with this approach is that it produces predictions that are
hard to interpret. Given estimated parameters and values for <span class="math notranslate nohighlight">\(x_1\)</span> and
<span class="math notranslate nohighlight">\(x_2\)</span>, the model might predict <span class="math notranslate nohighlight">\(y=0.5\)</span>, but the only meaningful values
of <span class="math notranslate nohighlight">\(y\)</span> are 0 and 1.</p>
<p>It is tempting to interpret a result like that as a probability; for
example, we might say that a respondent with particular values of <span class="math notranslate nohighlight">\(x_1\)</span>
and <span class="math notranslate nohighlight">\(x_2\)</span> has a 50% chance of having a boy. But it is also possible for
this model to predict <span class="math notranslate nohighlight">\(y=1.1\)</span> or <span class="math notranslate nohighlight">\(y=-0.1\)</span>, and those are not valid
probabilities.</p>
<p>Logistic regression avoids this problem by expressing predictions in
terms of <strong>odds</strong> rather than probabilities. If you are not familiar
with odds, “odds in favor” of an event is the ratio of the probability
it will occur to the probability that it will not.</p>
<p>So if I think my team has a 75% chance of winning, I would say that the
odds in their favor are three to one, because the chance of winning is
three times the chance of losing.</p>
<p>Odds and probabilities are different representations of the same
information. Given a probability, you can compute the odds like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="mf">0.75</span>
<span class="n">o</span> <span class="o">=</span> <span class="n">p</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span>
<span class="n">o</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.0
</pre></div>
</div>
</div>
</div>
<p>Given odds in favor, you can convert to probability like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">o</span> <span class="o">/</span> <span class="p">(</span><span class="n">o</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">p</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.75
</pre></div>
</div>
</div>
</div>
<p>Logistic regression is based on the following model:
$<span class="math notranslate nohighlight">\(\log o = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon\)</span><span class="math notranslate nohighlight">\( Where \)</span>o<span class="math notranslate nohighlight">\( is the
odds in favor of a particular outcome; in the example, \)</span>o$ would be the
odds of having a boy.</p>
<p>Suppose we have estimated the parameters <span class="math notranslate nohighlight">\(\beta_0\)</span>, <span class="math notranslate nohighlight">\(\beta_1\)</span>, and
<span class="math notranslate nohighlight">\(\beta_2\)</span> (I’ll explain how in a minute). And suppose we are given
values for <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span>. We can compute the predicted value of
<span class="math notranslate nohighlight">\(\log o\)</span>, and then convert to a probability:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">log_o</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">o</span><span class="p">)</span>
<span class="n">o</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_o</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">o</span> <span class="o">/</span> <span class="p">(</span><span class="n">o</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">p</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7500000000000001
</pre></div>
</div>
</div>
</div>
<p>So in the office pool scenario we could compute the predictive
probability of having a boy. But how do we estimate the parameters?</p>
</section>
<section id="estimating-parameters">
<h2>Estimating parameters<a class="headerlink" href="#estimating-parameters" title="Link to this heading">#</a></h2>
<p>Unlike linear regression, logistic regression does not have a closed
form solution, so it is solved by guessing an initial solution and
improving it iteratively.</p>
<p>The usual goal is to find the maximum-likelihood estimate (MLE), which
is the set of parameters that maximizes the likelihood of the data. For
example, suppose we have the following data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>And we start with the initial guesses <span class="math notranslate nohighlight">\(\beta_0=-1.5\)</span>, <span class="math notranslate nohighlight">\(\beta_1=2.8\)</span>, and
<span class="math notranslate nohighlight">\(\beta_2=1.1\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">beta</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.8</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Then for each row we can compute <code class="docutils literal notranslate"><span class="pre">log_o</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">log_o</span> <span class="o">=</span> <span class="n">beta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">beta</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">+</span> <span class="n">beta</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">x2</span> 
<span class="n">log_o</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-1.5, -0.4, -0.4,  2.4])
</pre></div>
</div>
</div>
</div>
<p>And convert from log odds to probabilities:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">o</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_o</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">o</span> <span class="o">/</span> <span class="p">(</span><span class="n">o</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Notice that when <code class="docutils literal notranslate"><span class="pre">log_o</span></code> is greater than 0, <code class="docutils literal notranslate"><span class="pre">o</span></code> is greater than 1 and
<code class="docutils literal notranslate"><span class="pre">p</span></code> is greater than 0.5.</p>
<p>The likelihood of an outcome is <code class="docutils literal notranslate"><span class="pre">p</span></code> when <code class="docutils literal notranslate"><span class="pre">y==1</span></code> and <code class="docutils literal notranslate"><span class="pre">1-p</span></code> when <code class="docutils literal notranslate"><span class="pre">y==0</span></code>.
For example, if we think the probability of a boy is 0.8 and the outcome
is a boy, the likelihood is 0.8; if the outcome is a girl, the
likelihood is 0.2. We can compute that like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">likes</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="n">p</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The overall likelihood of the data is the product of <code class="docutils literal notranslate"><span class="pre">likes</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">like</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">likes</span><span class="p">)</span>
<span class="n">like</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.1800933529673034
</pre></div>
</div>
</div>
</div>
<p>For these values of <code class="docutils literal notranslate"><span class="pre">beta</span></code>, the likelihood of the data is 0.18. The goal
of logistic regression is to find parameters that maximize this
likelihood. To do that, most statistics packages use an iterative solver
like Newton’s method (see
<a class="reference external" href="https://en.wikipedia.org/wiki/Logistic_regression#Model_fitting">https://en.wikipedia.org/wiki/Logistic_regression#Model_fitting</a>).</p>
</section>
<section id="implementation">
<h2>Implementation<a class="headerlink" href="#implementation" title="Link to this heading">#</a></h2>
<p>StatsModels provides an implementation of logistic regression called
<code class="docutils literal notranslate"><span class="pre">logit</span></code>, named for the function that converts from probability to log
odds. To demonstrate its use, I’ll look for variables that affect the
sex ratio.</p>
<p>Again, I load the NSFG data and select pregnancies longer than 30 weeks:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">first</span>

<span class="n">live</span><span class="p">,</span> <span class="n">firsts</span><span class="p">,</span> <span class="n">others</span> <span class="o">=</span> <span class="n">first</span><span class="o">.</span><span class="n">MakeFrames</span><span class="p">()</span>
<span class="n">live</span> <span class="o">=</span> <span class="n">live</span><span class="p">[</span><span class="n">live</span><span class="o">.</span><span class="n">prglngth</span><span class="o">&gt;</span><span class="mi">30</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">logit</span></code> requires the dependent variable to be binary (rather than
boolean), so I create a new column named <code class="docutils literal notranslate"><span class="pre">boy</span></code>, using <code class="docutils literal notranslate"><span class="pre">astype(int)</span></code> to
convert to binary integers:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">live</span><span class="p">[</span><span class="s1">&#39;boy&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">live</span><span class="o">.</span><span class="n">babysex</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">live</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(8884, 245)
</pre></div>
</div>
</div>
</div>
<p>Factors that have been found to affect sex ratio include parents’ age,
birth order, race, and social status. We can use logistic regression to
see if these effects appear in the NSFG data. I’ll start with the
mother’s age:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">logit</span><span class="p">(</span><span class="s1">&#39;boy ~ agepreg&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.693015
         Iterations 3
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">logit</span></code> takes the same arguments as <code class="docutils literal notranslate"><span class="pre">ols</span></code>, a formula in Patsy syntax and
a DataFrame. The result is a Logit object that represents the model.</p>
<p>The result of <code class="docutils literal notranslate"><span class="pre">model.fit</span></code> is a BinaryResults object, which is similar to
the RegressionResults object we got from <code class="docutils literal notranslate"><span class="pre">ols</span></code>. Here is a summary of the
results:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SummarizeResults</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   -0.0301   (0.772)
C(race)[T.2]   -0.0224   (0.66)
C(race)[T.3]   -0.000457   (0.996)
agepreg   -0.00267   (0.629)
hpagelb   0.0047   (0.266)
birthord   0.00501   (0.821)
R^2 0.000144
</pre></div>
</div>
</div>
</div>
<p>The parameter of <code class="docutils literal notranslate"><span class="pre">agepreg</span></code> is positive, which suggests that older
mothers are more likely to have boys, but the p-value is 0.783, which
means that the apparent effect could easily be due to chance.</p>
<p>The coefficient of determination, <span class="math notranslate nohighlight">\(R^2\)</span>, does not apply to logistic
regression, but there are several alternatives that are used as “pseudo
<span class="math notranslate nohighlight">\(R^2\)</span> values.” These values can be useful for comparing models. For
example, here’s a model that includes several factors believed to be
associated with sex ratio:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;boy ~ agepreg + hpagelb + birthord + C(race)&#39;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">logit</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.692944
         Iterations 3
</pre></div>
</div>
</div>
</div>
<p>Along with mother’s age, this model includes father’s age at birth
(<code class="docutils literal notranslate"><span class="pre">hpagelb</span></code>), birth order (<code class="docutils literal notranslate"><span class="pre">birthord</span></code>), and race as a categorical
variable. Here are the results:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SummarizeResults</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   -0.0301   (0.772)
C(race)[T.2]   -0.0224   (0.66)
C(race)[T.3]   -0.000457   (0.996)
agepreg   -0.00267   (0.629)
hpagelb   0.0047   (0.266)
birthord   0.00501   (0.821)
R^2 0.000144
</pre></div>
</div>
</div>
</div>
<p>None of the estimated parameters are statistically significant. The
pseudo-<span class="math notranslate nohighlight">\(R^2\)</span> value is a little higher, but that could be due to chance.</p>
</section>
<section id="accuracy">
<h2>Accuracy<a class="headerlink" href="#accuracy" title="Link to this heading">#</a></h2>
<p>In the office pool scenario, we are most interested in the accuracy of
the model: the number of successful predictions, compared with what we
would expect by chance.</p>
<p>In the NSFG data, there are more boys than girls, so the baseline
strategy is to guess “boy” every time.</p>
<p>The model contains attributes called <code class="docutils literal notranslate"><span class="pre">endog</span></code> and <code class="docutils literal notranslate"><span class="pre">exog</span></code> that contain the
<strong>endogenous variable</strong>, another name for the dependent variable, and
the <strong>exogenous variables</strong>, another name for the explanatory variables.
Since they are NumPy arrays, it is sometimes convenient to convert them
to DataFrames:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">endog</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">endog</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">endog_names</span><span class="p">])</span>
<span class="n">exog</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">exog</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">exog_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The accuracy of this strategy is
just the fraction of boys:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">actual</span> <span class="o">=</span> <span class="n">endog</span><span class="p">[</span><span class="s1">&#39;boy&#39;</span><span class="p">]</span>
<span class="n">actual</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(8782,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">baseline</span> <span class="o">=</span> <span class="n">actual</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">baseline</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.507173764518333
</pre></div>
</div>
</div>
</div>
<p>Since <code class="docutils literal notranslate"><span class="pre">actual</span></code> is encoded in binary integers, the mean is the fraction
of boys, which is 0.507.</p>
<p>Here’s how we compute the accuracy of the model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predict</span> <span class="o">=</span> <span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">predict</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">true_pos</span> <span class="o">=</span> <span class="n">predict</span> <span class="o">*</span> <span class="n">actual</span>
<span class="n">true_pos</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3944.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">true_neg</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">predict</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">actual</span><span class="p">)</span>
<span class="n">true_neg</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>548.0
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">results.predict</span></code> returns a NumPy array of probabilities, which we round
off to 0 or 1. Multiplying by <code class="docutils literal notranslate"><span class="pre">actual</span></code> yields 1 if we predict a boy and
get it right, 0 otherwise. So, <code class="docutils literal notranslate"><span class="pre">true_pos</span></code> indicates “true positives”.</p>
<p>Similarly, <code class="docutils literal notranslate"><span class="pre">true_neg</span></code> indicates the cases where we guess “girl” and get
it right. Accuracy is the fraction of correct guesses:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">acc</span> <span class="o">=</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">true_pos</span><span class="p">)</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">true_neg</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span>
<span class="n">acc</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.5115007970849464
</pre></div>
</div>
</div>
</div>
<p>The result is 0.512, slightly better than the baseline, 0.507. But, you
should not take this result too seriously. We used the same data to
build and test the model, so the model may not have predictive power on
new data.</p>
<p>Nevertheless, let’s use the model to make a prediction for the office
pool. Suppose your friend is 35 years old and white, her husband is 39,
and they are expecting their third child:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;agepreg&#39;</span><span class="p">,</span> <span class="s1">&#39;hpagelb&#39;</span><span class="p">,</span> <span class="s1">&#39;birthord&#39;</span><span class="p">,</span> <span class="s1">&#39;race&#39;</span><span class="p">]</span>
<span class="n">new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([[</span><span class="mi">35</span><span class="p">,</span> <span class="mi">39</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To invoke <code class="docutils literal notranslate"><span class="pre">results.predict</span></code> for a new case, you have to construct a
DataFrame with a column for each variable in the model. The result in
this case is 0.52, so you should guess “boy.” But if the model improves
your chances of winning, the difference is very small.</p>
</section>
<section id="glossary">
<h2>Glossary<a class="headerlink" href="#glossary" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>regression</strong>: One of several related processes for estimating
parameters that fit a model to data.</p></li>
<li><p><strong>dependent variables</strong>: The variables in a regression model we
would like to predict. Also known as endogenous variables.</p></li>
<li><p><strong>explanatory variables</strong>: The variables used to predict or explain
the dependent variables. Also known as independent, or exogenous,
variables.</p></li>
<li><p><strong>simple regression</strong>: A regression with only one dependent and one
explanatory variable.</p></li>
<li><p><strong>multiple regression</strong>: A regression with multiple explanatory
variables, but only one dependent variable.</p></li>
<li><p><strong>linear regression</strong>: A regression based on a linear model.</p></li>
<li><p><strong>ordinary least squares</strong>: A linear regression that estimates
parameters by minimizing the squared error of the residuals.</p></li>
<li><p><strong>spurious relationship</strong>: A relationship between two variables that
is caused by a statistical artifact or a factor, not included in the
model, that is related to both variables.</p></li>
<li><p><strong>control variable</strong>: A variable included in a regression to
eliminate or “control for” a spurious relationship.</p></li>
<li><p><strong>proxy variable</strong>: A variable that contributes information to a
regression model indirectly because of a relationship with another
factor, so it acts as a proxy for that factor.</p></li>
<li><p><strong>categorical variable</strong>: A variable that can have one of a discrete
set of unordered values.</p></li>
<li><p><strong>join</strong>: An operation that combines data from two DataFrames using
a key to match up rows in the two frames.</p></li>
<li><p><strong>data mining</strong>: An approach to finding relationships between
variables by testing a large number of models.</p></li>
<li><p><strong>logistic regression</strong>: A form of regression used when the
dependent variable is boolean.</p></li>
<li><p><strong>Poisson regression</strong>: A form of regression used when the dependent
variable is a non-negative integer, usually a count.</p></li>
<li><p><strong>odds</strong>: An alternative way of representing a probability, <span class="math notranslate nohighlight">\(p\)</span>, as
the ratio of the probability and its complement, <span class="math notranslate nohighlight">\(p / (1-p)\)</span>.</p></li>
</ul>
</section>
<section id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<p><strong>Exercise:</strong> Suppose one of your co-workers is expecting a baby and you are participating in an office pool to predict the date of birth. Assuming that bets are placed during the 30th week of pregnancy, what variables could you use to make the best prediction? You should limit yourself to variables that are known before the birth, and likely to be available to the people in the pool.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">first</span>
<span class="n">live</span><span class="p">,</span> <span class="n">firsts</span><span class="p">,</span> <span class="n">others</span> <span class="o">=</span> <span class="n">first</span><span class="o">.</span><span class="n">MakeFrames</span><span class="p">()</span>
<span class="n">live</span> <span class="o">=</span> <span class="n">live</span><span class="p">[</span><span class="n">live</span><span class="o">.</span><span class="n">prglngth</span><span class="o">&gt;</span><span class="mi">30</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise:</strong> The Trivers-Willard hypothesis suggests that for many mammals the sex ratio depends on “maternal condition”; that is, factors like the mother’s age, size, health, and social status. See <a class="reference external" href="https://en.wikipedia.org/wiki/Trivers-Willard_hypothesis">https://en.wikipedia.org/wiki/Trivers-Willard_hypothesis</a></p>
<p>Some studies have shown this effect among humans, but results are mixed. In this chapter we tested some variables related to these factors, but didn’t find any with a statistically significant effect on sex ratio.</p>
<p>As an exercise, use a data mining approach to test the other variables in the pregnancy and respondent files. Can you find any factors with a substantial effect?</p>
<p><strong>Exercise:</strong> If the quantity you want to predict is a count, you can use Poisson regression, which is implemented in StatsModels with a function called <code class="docutils literal notranslate"><span class="pre">poisson</span></code>. It works the same way as <code class="docutils literal notranslate"><span class="pre">ols</span></code> and <code class="docutils literal notranslate"><span class="pre">logit</span></code>. As an exercise, let’s use it to predict how many children a woman has born; in the NSFG dataset, this variable is called <code class="docutils literal notranslate"><span class="pre">numbabes</span></code>.</p>
<p>Suppose you meet a woman who is 35 years old, black, and a college graduate whose annual household income exceeds $75,000. How many children would you predict she has born?</p>
<p>Now we can predict the number of children for a woman who is 35 years old, black, and a college
graduate whose annual household income exceeds $75,000</p>
<p><strong>Exercise:</strong> If the quantity you want to predict is categorical, you can use multinomial logistic regression, which is implemented in StatsModels with a function called <code class="docutils literal notranslate"><span class="pre">mnlogit</span></code>. As an exercise, let’s use it to guess whether a woman is married, cohabitating, widowed, divorced, separated, or never married; in the NSFG dataset, marital status is encoded in a variable called <code class="docutils literal notranslate"><span class="pre">rmarital</span></code>.</p>
<p>Suppose you meet a woman who is 25 years old, white, and a high school graduate whose annual household income is about $45,000. What is the probability that she is married, cohabitating, etc?</p>
<p>Make a prediction for a woman who is 25 years old, white, and a high
school graduate whose annual household income is about $45,000.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="chap10.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Linear least squares</p>
      </div>
    </a>
    <a class="right-next"
       href="chap12.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Time series analysis</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statsmodels">StatsModels</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-regression">Multiple regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nonlinear-relationships">Nonlinear relationships</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-mining">Data mining</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prediction">Prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression">Logistic regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-parameters">Estimating parameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#accuracy">Accuracy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glossary">Glossary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Allen B. Downey
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>