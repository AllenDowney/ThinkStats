{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c1d5d2",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "\n",
    "Exploring the data from the NSFG, we saw several \"apparent effects,\" including differences between first babies and others.\n",
    "So far we have taken these effects at face value; in this chapter, we put them to the test.\n",
    "\n",
    "The fundamental question we want to address is whether the effects we see in a sample are likely to appear in the larger population.\n",
    "For example, in the NSFG sample we see a difference in mean pregnancy length for first babies and others.\n",
    "We would like to know if that effect reflects a real difference for women in the U.S., or if it might appear in the sample by chance.\n",
    "\n",
    "There are several ways we could formulate this question, including Fisher null hypothesis testing, Neyman-Pearson decision theory, and Bayesian inference.\n",
    "What I present here is a subset of all three that makes up most of what people use in practice, which I will call **classical hypothesis testing**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30615f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import basename, exists\n",
    "\n",
    "\n",
    "def download(url):\n",
    "    filename = basename(url)\n",
    "    if not exists(filename):\n",
    "        from urllib.request import urlretrieve\n",
    "\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print(\"Downloaded \" + local)\n",
    "\n",
    "\n",
    "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/nb/thinkstats.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "708e5a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import empiricaldist\n",
    "except ImportError:\n",
    "    !pip install empiricaldist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "684b56bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from thinkstats import decorate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc51b88",
   "metadata": {},
   "source": [
    "## Flipping Coins\n",
    "\n",
    "We'll start with a simple example.\n",
    "When Euro coins were introduced in 2002, a curious coin enthusiast spun a Belgian one-Euro coin on edge 250 times and noted that it landed with the heads side up 140 times and tails side up 110 times.\n",
    "If the coin is perfectly balanced, we expect only 125 heads, so this data suggests the coin is biased.\n",
    "On the other hand, we don't expect to get exactly 125 heads every time, so it's possible that the coin is actually fair, and the apparent excess of heads is due to chance.\n",
    "To see whether that's plausible, we can perform a hypothesis test.\n",
    "\n",
    "We'll use the following function to compute the excess number of heads, which is the difference between the observed number and the expected number if the coin is fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eca557aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 250\n",
    "p = 0.5\n",
    "\n",
    "\n",
    "def excess_heads(heads):\n",
    "    expected = n * p\n",
    "    return heads - expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69024b6",
   "metadata": {},
   "source": [
    "In the observed data, the number of excess heads is 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39a9fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = 140\n",
    "tails = 110\n",
    "\n",
    "observed_stat = excess_heads(heads)\n",
    "observed_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca821d5e",
   "metadata": {},
   "source": [
    "If the coin is actually fair, we can simulate the coin-spinning experiment by generating a sequence of random strings -- either `'H'` or `'T'` with equal probability -- and counting the number of times `'H'` appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3ecbcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_flips():\n",
    "    flips = np.random.choice([\"H\", \"T\"], size=n)\n",
    "    heads = np.sum(flips == \"H\")\n",
    "    return heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2be8aa",
   "metadata": {},
   "source": [
    "Each time we call this function, we get the outcome of a simulated experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63868cdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7da09b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_flips()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e4bee",
   "metadata": {},
   "source": [
    "The following loop simulates the experiment many times and computes the number of excess heads for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e9ddd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_stats = [excess_heads(simulate_flips()) for i in range(10001)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8a0734",
   "metadata": {},
   "source": [
    "The result is a sample from the distribution of excess heads under the assumption that the coin is fair.\n",
    "Here's what the distribution of these values looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23878b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from empiricaldist import Pmf\n",
    "\n",
    "pmf_effects = Pmf.from_seq(simulated_stats)\n",
    "pmf_effects.bar(alpha=0.5)\n",
    "\n",
    "decorate(xlabel=\"Excess Heads\", ylabel=\"PMF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71fbbfd",
   "metadata": {},
   "source": [
    "Values near 0 are the most common.\n",
    "Values greater than 10 and less than -10 are less common.\n",
    "Remembering that in the observed data, there were 15 excess heads, we see that excesses of that magnitude are rare, but not impossible.\n",
    "In this example, the simulated results exceed or equal 15 about 3.5% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f9d5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(simulated_stats) >= 15).mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb096cc7",
   "metadata": {},
   "source": [
    "And about as often the number of excess heads is less than or equal to -15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4c44fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(simulated_stats) <= -15).mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2c7107",
   "metadata": {},
   "source": [
    "If the coin is fair, we expect the excess to be 15 or more 3.5% of the time, just by chance.\n",
    "And we expect the the magnitude of the excess, in either direction, to be 15 or more about 7% of the time.\n",
    "\n",
    "In conclusion, an apparent effect of this size is not common, but it is certainly not impossible, even if the coin is fair.\n",
    "On the basis of this experiment, we can't rule out the possibility that the coin is fair.\n",
    "\n",
    "This example demonstrates the logic of statistical hypothesis testing.\n",
    "\n",
    "* We started with an observation, 140 heads out of 250 spins, and the hypothesis that the coin is biased -- that is, that the probability of heads is greater than 50%.\n",
    "\n",
    "* We chose a **test statistic** that quantifies the size of the apparent effect. In this example, the test statistic is the number of excess heads.\n",
    "\n",
    "* We defined a **null hypothesis**, which is a model based on the assumption that the apparent effect is due to chance. In this example, the null hypothesis is that the coin is fair.\n",
    "\n",
    "* The third step is to compute a **p-value**, which is the probability of seeing the apparent effect if the null hypothesis is true. In this example, the p-value is the probability of 15 or more excess heads.\n",
    "\n",
    "The last step is to interpret the result.\n",
    "If the p-value is low, we can conclude that the effect would be unlikely to happen by chance.\n",
    "In this example, the p-value is either 3.5% or 7%, depending on how we define the effect.\n",
    "So the effect is unlikely to happen by chance, but we can't rule out the possibility.\n",
    "\n",
    "All hypothesis tests are based on these elements -- a test statistic, a null hypothesis, and a p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cd3e27",
   "metadata": {},
   "source": [
    "## Testing a Difference in Means\n",
    "\n",
    "In the NSFG data, we saw that the average pregnancy length for first babies is slightly longer than for other babies.\n",
    "Now let's see if that difference could be due to chance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610b9e16",
   "metadata": {
    "tags": []
   },
   "source": [
    "The following cells download the data and install `statadict`, which we need to read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aca382ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/nb/nsfg.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/2002FemPreg.dct\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/2002FemPreg.dat.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c093aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import statadict\n",
    "except ImportError:\n",
    "    !pip install statadict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0495e1e4",
   "metadata": {},
   "source": [
    "The function `get_nsfg_groups` reads the data, selects live births, and groups live births into first babies and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbb9b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nsfg import get_nsfg_groups\n",
    "\n",
    "live, firsts, others = get_nsfg_groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a99eb55",
   "metadata": {},
   "source": [
    "Now we can select pregnancy lengths, in weeks, for both groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8038bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = firsts[\"prglngth\"].values, others[\"prglngth\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b93fa5",
   "metadata": {},
   "source": [
    "The following function takes the data, as a tuple of two sequences, and computes the difference in means. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29e7d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_means(data):\n",
    "    group1, group2 = data\n",
    "    diff = np.mean(group1) - np.mean(group2)\n",
    "    return np.abs(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979f893e",
   "metadata": {},
   "source": [
    "The average pregnancy length is 0.078 weeks longer for first babies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "389cb8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_diff = diff_means(data)\n",
    "observed_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74756058",
   "metadata": {},
   "source": [
    "So the hypothesis we'll test is whether pregnancy length is generally longer for first babies.\n",
    "The null hypothesis is that pregnancy lengths are actually the same for both groups, and the apparent difference is due to chance.\n",
    "If pregnancy lengths are the same for both groups, we can combine the two groups into a single pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "533453b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = np.hstack(data)\n",
    "len(pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab47f04",
   "metadata": {},
   "source": [
    "Now to simulate the experiment, we can shuffle the pool and divide it into two groups with the same sizes as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "213b5f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_groups(data):\n",
    "    group1, group2 = data\n",
    "    n, m = len(group1), len(group2)\n",
    "\n",
    "    np.random.shuffle(pool)\n",
    "    return pool[:n], pool[-m:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244fdf24",
   "metadata": {},
   "source": [
    "Each time we call this function, it returns a tuple of sequences, which we can pass to `diff_means`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0156bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_means(simulate_groups(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af5f548",
   "metadata": {},
   "source": [
    "The following loop simulated the experiment many times and computes the difference in means for each simulated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9f6f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_diffs = [diff_means(simulate_groups(data)) for i in range(1001)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2714eb6",
   "metadata": {},
   "source": [
    "To visualize the results, we'll use the following function, which takes a sample of simulated results and makes a `Pmf` object that approximates its distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd54b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "from empiricaldist import Pmf\n",
    "\n",
    "\n",
    "def make_pmf(sample, low, high):\n",
    "    kde = gaussian_kde(sample)\n",
    "    qs = np.linspace(low, high, 201)\n",
    "    ps = kde(qs)\n",
    "    return Pmf(ps, qs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c97730e",
   "metadata": {},
   "source": [
    "We'll also use this function, which fills in the tail of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a10aa249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinkstats import underride\n",
    "\n",
    "\n",
    "def fill_tail(pmf, observed, side, **options):\n",
    "    \"\"\"Fill the area under a PMF, right or left of an observed value.\"\"\"\n",
    "    options = underride(options, alpha=0.3)\n",
    "\n",
    "    if side == \"right\":\n",
    "        condition = pmf.qs >= observed\n",
    "    elif side == \"left\":\n",
    "        condition = pmf.qs <= observed\n",
    "\n",
    "    series = pmf[condition]\n",
    "    plt.fill_between(series.index, 0, series, **options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5132a2a4",
   "metadata": {},
   "source": [
    "Here's what the distribution of the simulated results looks like.\n",
    "The shaded region shows the cases where the difference in means under the null hypothesis exceeds the observed difference.\n",
    "The area of this region is the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f631723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf = make_pmf(simulated_diffs, 0, 0.2)\n",
    "pmf.plot()\n",
    "fill_tail(pmf, observed_diff, \"right\")\n",
    "decorate(xlabel=\"Absolute difference in means (weeks)\", ylabel=\"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9332d42d",
   "metadata": {},
   "source": [
    "The following function computes the p-value, which is the fraction of simulated values that are as big or bigger than the observed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74e7cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_p_value(simulated, observed):\n",
    "    \"\"\"Fraction of simulated values as big or bigger than the observed value.\"\"\"\n",
    "    return (np.asarray(simulated) >= observed).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f6d773",
   "metadata": {},
   "source": [
    "In this example, the p-value is about 17%, which means it is plausible that a difference as big as 0.078 weeks could happen by chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "275305f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_p_value(simulated_diffs, observed_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102b66e6",
   "metadata": {},
   "source": [
    "Based on this result, we can't be sure that pregnancy lengths are generally longer for first babies -- it's possible that the difference in this dataset is due to chance.\n",
    "\n",
    "Notice that we've seen the same elements in both examples of hypothesis testing.\n",
    "In this example, the test statistic is the difference in the means.\n",
    "The null hypothesis is that the distribution of pregnancy lengths is actually the same in both groups.\n",
    "We modeled the null hypothesis by combining the data from both groups into a single pool, shuffling the pool, and splitting it into two groups with the same sizes as the originals.\n",
    "This process is called **permutation**, which is another word for shuffling.\n",
    "\n",
    "A strength of this computational approach to hypothesis testing is that we can combine these elements to test different statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd343faf",
   "metadata": {},
   "source": [
    "## Other Test Statistics\n",
    "\n",
    "We might wonder whether pregnancy lengths for first babies are not just longer, but maybe more variable.\n",
    "To test that hypothesis, we can use as a test statistic the difference between the standard deviations of the two groups.\n",
    "The following function computes this test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf26e145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_stds(data):\n",
    "    group1, group2 = data\n",
    "    diff = np.std(group1) - np.std(group2)\n",
    "    return np.abs(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6113fe16",
   "metadata": {},
   "source": [
    "In the NSFG dataset, the difference in standard deviations is about 0.18, pregnancy lengths for first babies are apparently more variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e239d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_diff = diff_stds(data)\n",
    "observed_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536705f5",
   "metadata": {},
   "source": [
    "To see whether this difference might be due to chance, we can use permutation again.\n",
    "The following loop simulates the null hypothesis many times and computes the difference in standard deviation for each simulated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77cb5b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_diffs = [diff_stds(simulate_groups(data)) for i in range(1001)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab987e",
   "metadata": {},
   "source": [
    "Here's what the distribution of the results looks like.\n",
    "Again, the shaded region shows where the test statistic under the null hypothesis exceeds the observed difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ef21386",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf = make_pmf(simulated_diffs, 0, 0.5)\n",
    "pmf.plot()\n",
    "fill_tail(pmf, observed_diff, \"right\")\n",
    "decorate(xlabel=\"Absolute difference in standard deviation (weeks)\", ylabel=\"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ca94ff",
   "metadata": {},
   "source": [
    "We can estimate the area of this region by computing the fraction of results that are as big or bigger than the observed difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef1aa33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_p_value(simulated_diffs, observed_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8112432b",
   "metadata": {},
   "source": [
    "Again, it is plausible that we could see a difference this big even if the two groups are the same.\n",
    "So we can't be sure that pregnancy lengths are generally more variable for first babies -- the difference we see in this dataset could be due to chance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efb6d21",
   "metadata": {
    "tags": []
   },
   "source": [
    "(section_test_correlation)=\n",
    "## Testing a Correlation\n",
    "\n",
    "We can use the same framework to test correlations.\n",
    "For example, in the NSFG data set, there is a correlation between birth weight and mother's age -- older mothers have heavier babies, on average.\n",
    "But could this apparent effect be due to chance?\n",
    "\n",
    "To find out, we'll start by preparing the data.\n",
    "From live births, we'll select cases where the age of the mother and birth weight are known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4c66a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = live.dropna(subset=[\"agepreg\", \"totalwgt_lb\"])\n",
    "valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de677813",
   "metadata": {},
   "source": [
    "Then we'll select the relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5dc70bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = valid[\"agepreg\"]\n",
    "birthweights = valid[\"totalwgt_lb\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b157bccb",
   "metadata": {},
   "source": [
    "The following function takes a tuple of `xs` and `ys` and computes the magnitude of the correlation, positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "686a44fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_correlation(data):\n",
    "    xs, ys = data\n",
    "    corr = np.corrcoef(xs, ys)[0, 1]\n",
    "    return np.abs(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9eaf12",
   "metadata": {},
   "source": [
    "In the NSFG dataset, the correlation is about 0.07."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3be4c743",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ages, birthweights\n",
    "observed_corr = abs_correlation(data)\n",
    "observed_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94504de1",
   "metadata": {},
   "source": [
    "The null hypothesis is that there is no correlation between mother's age and birth weight.\n",
    "By shuffling the observed values, we can simulate a world where the distributions of age and birth weight are the same, but where the variables are unrelated.\n",
    "\n",
    "The following function takes a tuple of `xs` and `ys`, shuffles `xs` and returns a tuple containing the shuffled `xs` and the original `ys`.\n",
    "We could have shuffle the `ys` instead, or shuffled both.\n",
    "Any of those variations would work just as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8fdc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute(data):\n",
    "    xs, ys = data\n",
    "    new_xs = xs.values.copy()\n",
    "    np.random.shuffle(new_xs)\n",
    "    return new_xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e93ab",
   "metadata": {},
   "source": [
    "The correlation of the shuffled values is usually close to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d539d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_correlation(permute(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2630c347",
   "metadata": {},
   "source": [
    "The following loop generates many shuffled datasets and computes the correlation of each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd4066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_corrs = [abs_correlation(permute(data)) for i in range(1001)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2fbbd9",
   "metadata": {},
   "source": [
    "Here's what the distribution of the results looks like.\n",
    "The vertical dotted line shows the observed correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf = make_pmf(simulated_corrs, 0, 0.07)\n",
    "pmf.plot()\n",
    "plt.axvline(observed_corr, ls=\":\")\n",
    "decorate(xlabel=\"Correlation\", ylabel=\"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546bb60a",
   "metadata": {},
   "source": [
    "We can see that the observed correlation is in the tail of the distribution, with no visible area under the curve.\n",
    "If we try to compute a p-value, the result is 0, indicating that the correlation in the shuffled data did not exceed the observed value in any of the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401168b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_p_value(simulated_corrs, observed_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cede1136",
   "metadata": {},
   "source": [
    "The actual p-value is not exactly zero -- it is possible for the correlation of the shuffled data to exceed the observed value -- but it is very unlikely.\n",
    "\n",
    "When the p-value is small, traditionally less than 0.05, we can say that the result is **statistically significant**.\n",
    "But this way of interpreting p-values has always been problematic, and it is slowly becoming less widely used.\n",
    "\n",
    "One problem is that the traditional threshold is arbitrary and not appropriate for all applications.\n",
    "Another problem is that this use of \"significant\" is misleading because it suggests that the effect is important in practice.\n",
    "The correlation between mother's age and birth weight is a good example -- it is statistically significant, but so small that it is not important.\n",
    "\n",
    "An alternative is to interpret p-values qualitatively.\n",
    "\n",
    "* If a p-value is large, it is plausible that the apparent effect could happen by chance.\n",
    "\n",
    "* If the p-value is small, we can often rule out the possibility that the effect is due to chance -- but we should remember that it could still be due to non-representative sampling or measurement errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9934be2",
   "metadata": {},
   "source": [
    "## Testing Proportions\n",
    "\n",
    "As a final example, let's consider a case where the choice of the test statistic takes some thought.\n",
    "Suppose you run a casino and you suspect that a customer is using a crooked die -- that is, one that has been modified to make one of the faces more likely than the others.\n",
    "You apprehend the alleged cheater and confiscate the die, but now you have to prove that it is crooked.\n",
    "You roll the die 60 times and record the frequency of each outcome from 1 to 6.\n",
    "Here are the results in a `Hist` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20912051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from empiricaldist import Hist\n",
    "\n",
    "qs = np.arange(1, 7)\n",
    "freqs = [8, 9, 19, 5, 8, 11]\n",
    "observed = Hist(freqs, qs)\n",
    "observed.index.name = \"outcome\"\n",
    "observed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1b7cdf",
   "metadata": {},
   "source": [
    "On average you expect each value to appear 10 times.\n",
    "In this dataset, the value 3 appears more often than expected, and the value 4 appears less often.\n",
    "But could these differences happen by chance?\n",
    "\n",
    "To test this hypothesis, we'll use the following function to compute the expected frequency for each value, the difference between the expected and observed frequencies, and the total of the absolute differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c56fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_deviation(observed):\n",
    "    n = observed.sum()\n",
    "    outcomes = observed.qs\n",
    "    expected = Hist(n / 6, outcomes)\n",
    "    return sum(abs(observed - expected))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97100b5f",
   "metadata": {},
   "source": [
    "In the observed dataset, the sum of the absolute difference is 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba77210",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_dev = total_deviation(observed)\n",
    "observed_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff22e1",
   "metadata": {},
   "source": [
    "The following function takes the observed data, simulates rolling a fair die the same number of times, and returns a `Hist` object that contains the simulated frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a530baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_dice(observed):\n",
    "    n = np.sum(observed)\n",
    "    rolls = np.random.choice(observed.qs, n, replace=True)\n",
    "    hist = Hist.from_seq(rolls)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb4ced1",
   "metadata": {},
   "source": [
    "The following loop simulates the experiment many times and computes to total absolute deviation for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaef547",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_devs = [total_deviation(simulate_dice(observed)) for i in range(1001)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fa98a9",
   "metadata": {},
   "source": [
    "Here's what the distribution of the total deviations looks like.\n",
    "Notice that the total is always even, because every time an outcome appears more often than expected, another outcome has to appear less often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf_devs = Pmf.from_seq(simulated_devs)\n",
    "pmf_devs.bar(alpha=0.5)\n",
    "\n",
    "decorate(xlabel=\"Total absolute deviation\", ylabel=\"PMF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d86d6d4",
   "metadata": {},
   "source": [
    "We can see that a total deviation of 20 is not unusual.\n",
    "And the p-value is about 13%, which means that we can't be sure the die is crooked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea4115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_p_value(simulated_devs, observed_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f25f12",
   "metadata": {},
   "source": [
    "But the test statistic we chose was not the only option.\n",
    "For a problem like this, it would be more conventional to use the chi-squared statistic, which we can compute like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047569cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_squared_stat(observed):\n",
    "    n = observed.sum()\n",
    "    outcomes = observed.qs\n",
    "    expected = Hist(n / 6, outcomes)\n",
    "    diffs = (observed - expected) ** 2\n",
    "    return sum((observed - expected) ** 2 / expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9cd605",
   "metadata": {},
   "source": [
    "Squaring the deviations (rather than taking absolute values) gives more weight to large deviations.\n",
    "Dividing through by `expected` standardizes the deviations, although in this case it has no effect on the results because the expected frequencies are all equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_chi_squared = chi_squared_stat(observed)\n",
    "observed_chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a1ec55",
   "metadata": {},
   "source": [
    "The chi-squared statistic of the observed data is 11.6.\n",
    "By itself, this number doesn't mean very much, but we can compare it to the results from the simulated rolls.\n",
    "The following loop generates many simulated datasets and computes the chi-squared statistic for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4dff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_chi_squared = [chi_squared_stat(simulate_dice(observed)) for i in range(1001)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27682cd",
   "metadata": {},
   "source": [
    "Here's what the distribution of the chi-squared statistic looks like under the null hypothesis.\n",
    "The shaded region shows the results that exceed the observed test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9776d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf = make_pmf(simulated_chi_squared, 0, 20)\n",
    "pmf.plot()\n",
    "fill_tail(pmf, observed_chi_squared, \"right\")\n",
    "decorate(xlabel=\"Chi-Squared Statistic\", ylabel=\"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df319de1",
   "metadata": {},
   "source": [
    "The area of the shaded region is the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc505143",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_p_value(simulated_chi_squared, observed_chi_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6d27ef",
   "metadata": {},
   "source": [
    "The p-value using the chi-squared statistic is about 0.04, substantially smaller than what we got using total deviation, 0.13. If we take the 5% threshold seriously, we would consider this effect statistically significant.\n",
    "But considering the two tests together, I would say that the results are borderline.\n",
    "I would not rule out the possibility that the die is crooked, but I would not convict the accused cheater.\n",
    "\n",
    "This example demonstrates an important point: the p-value depends on the choice of test statistic and the model of the null hypothesis, and sometimes these choices determine whether an effect is statistically significant or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ff960",
   "metadata": {},
   "source": [
    "## Glossary\n",
    "\n",
    "-   **hypothesis testing**: The process of determining whether an apparent effect is statistically significant.\n",
    "\n",
    "-   **test statistic**: A statistic used to quantify an effect size.\n",
    "\n",
    "-   **null hypothesis**: A model of a system based on the assumption that an apparent effect is due to chance.\n",
    "\n",
    "-   **p-value**: The probability that an effect could occur by chance.\n",
    "\n",
    "-   **statistically significant**: An effect is statistically significant if it is unlikely to occur by chance.\n",
    "\n",
    "-   **permutation test**: A way to compute p-values by generating permutations of an observed dataset.\n",
    "\n",
    "-   **resampling test**: A way to compute p-values by generating samples, with replacement, from an observed dataset.\n",
    "\n",
    "-   **two-sided test**: A test that asks, \"What is the chance of an effect as big as the observed effect, positive or negative?\"\n",
    "\n",
    "-   **one-sided test**: A test that asks, \"What is the chance of an effect as big as the observed effect, and with the same sign?\"\n",
    "\n",
    "-   **chi-squared test**: A test that uses the chi-squared statistic as the test statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940c93d6",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4405a02b",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "NOTE: This exercise and the next use different models of the same scenario, and I will suggest that the second is probably a better choice. I think the first is a good exercise, but the results might be misleading.\n",
    "\n",
    "Returning to the skeet shooting example from Chapter 5.\n",
    "In the 2020 Summer Olympics, 20 competitors participated in the preliminaries, but only the top 6 qualified for the finals.\n",
    "\n",
    "During the preliminaries, each contestant shot 5 rounds of 25 targets each.\n",
    "On average, the 6 qualifiers hit 24.57 out of 25 targets; the competitors who were eliminated hit 23.65 out of 25.\n",
    "Let's see if that difference between the two groups is likely to reflect a real difference in ability, or whether it could have happened by chance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bd7f71",
   "metadata": {},
   "source": [
    "The following cells download the data and read it into a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3834e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = \"Shooting_at_the_2020_Summer_Olympics_Mens_skeet\"\n",
    "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/\" + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18836f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_html(filename)\n",
    "table = tables[6]\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bce66b",
   "metadata": {},
   "source": [
    "We can select the top 6 competitors and the rest like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c65a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualified = table.query(\"Rank <= 6\")\n",
    "eliminated = table.query(\"Rank > 6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d40e7",
   "metadata": {},
   "source": [
    "And here's how we can extract the results for each round, for each competitor, and flatten them into a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c2e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "results_qualified = qualified[columns].values.flatten()\n",
    "np.mean(results_qualified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78264276",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_eliminated = eliminated[columns].values.flatten()\n",
    "np.mean(results_eliminated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99753e7b",
   "metadata": {},
   "source": [
    "Use `diff_means` and `simulate_groups` to generate a large number of simulated datasets under the null hypothesis that the two groups have the same chance of hitting a target, and compute the difference in means for each one.\n",
    "Compare the simulation results to the observed difference and compute a p-value.\n",
    "Is it plausible that the difference between the groups happened by chance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a7f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = results_qualified, results_eliminated\n",
    "observed_diff = diff_means(data)\n",
    "observed_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = np.hstack(data)\n",
    "len(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8978daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_diffs = [diff_means(simulate_groups(data)) for i in range(1001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cab92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf = make_pmf(simulated_diffs, 0, 1.25)\n",
    "pmf.plot()\n",
    "plt.axvline(observed_diff, ls=\":\")\n",
    "decorate(xlabel=\"Difference in means\", ylabel=\"Density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e11636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_p_value(simulated_diffs, observed_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47306dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea768ec8",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "The result of the previous exercise might be misleading because..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bcccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = table[columns].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3ec925",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 25\n",
    "p = np.mean(results / 25)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad98ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "simulated_data = binom.rvs(n, p, size=table[columns].shape)\n",
    "simulated_results = pd.DataFrame(simulated_data, columns=columns)\n",
    "simulated_results[\"Total\"] = simulated_data.sum(axis=1)\n",
    "simulated_results[\"Rank\"] = simulated_results[\"Total\"].rank(\n",
    "    method=\"first\", ascending=False\n",
    ")\n",
    "simulated_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae738cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualified = simulated_results.query(\"Rank <= 6\")\n",
    "eliminated = simulated_results.query(\"Rank > 6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be8e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_qualified = qualified[columns].values.flatten()\n",
    "results_eliminated = eliminated[columns].values.flatten()\n",
    "np.mean(results_qualified), np.mean(results_eliminated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fd5ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
