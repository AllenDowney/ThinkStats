{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79cfee17",
   "metadata": {},
   "source": [
    "# Relationships between variables\n",
    "\n",
    "So far we have only looked at one variable at a time.\n",
    "In this chapter we look at relationships between variables.\n",
    "Two variables are related if knowing one gives you information about the other.\n",
    "For example, height and weight are related; people who are taller tend to be heavier.\n",
    "Of course, it is not a perfect relationship: there are short heavy people and tall light ones.\n",
    "But if you are trying to guess someone's weight, you will be more accurate if you know their height than if you don't."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4cd1fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "[Click here to run this notebook on Colab](https://colab.research.google.com/github/AllenDowney/ThinkStats/blob/v3/nb/chap07.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "542c6943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from os.path import basename, exists\n",
    "\n",
    "\n",
    "def download(url):\n",
    "    filename = basename(url)\n",
    "    if not exists(filename):\n",
    "        from urllib.request import urlretrieve\n",
    "\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print(\"Downloaded \" + local)\n",
    "\n",
    "\n",
    "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/nb/thinkstats.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f41c5c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import empiricaldist\n",
    "except ImportError:\n",
    "    !pip install empiricaldist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c826e189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from thinkstats import decorate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df42f753",
   "metadata": {},
   "source": [
    "## Scatter Plots\n",
    "\n",
    "If you meet someone who is unusually good at math, do you expect their verbal skills to be better or worse than average?\n",
    "On one hand, you might imagine that people specialize in one area or the other, so someone who excels at one might be less good at the other.\n",
    "On the other hand, you might expect someone who is generally smart to be above average in both areas.\n",
    "Let's find out which is true.\n",
    "\n",
    "We'll use data from the National Longitudinal Survey of Youth 1997 (NLSY97), which \"follows the lives of a sample of 8,984 American youth born between 1980-84\". \n",
    "The public data set includes the participants' scores on several standardized tests, including the tests most often used in college admissions, the SAT and ACT.\n",
    "Because test-takers get separate scores for the math and verbal sections, we can use this data to explore the relationship between mathematical and verbal ability.\n",
    "\n",
    "I used the NLS Investigator to create excerpt that contains the variables I'll use for this analysis.\n",
    "With their permission, I can redistribute this except. \n",
    "We can use `read_csv` to read the data and `replace` to replace the special codes for missing data with `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8e375cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/nlsy97-extract.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5395bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_codes = [-1, -2, -3, -4, -5]\n",
    "nlsy = pd.read_csv(\"nlsy97-extract.csv.gz\").replace(missing_codes, np.nan)\n",
    "nlsy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76e92c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvar = \"R1318200\"\n",
    "yvar = \"U4949700\"\n",
    "\n",
    "valid = nlsy.dropna(subset=[xvar, yvar])\n",
    "np.corrcoef(valid[xvar], valid[yvar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80f09e49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlsy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164d0fd5",
   "metadata": {},
   "source": [
    "The `DataFrame` contains one row for each of the 8984 participants in the survey and one column for each of the 34 variables I selected.\n",
    "The column names don't mean much by themselves, but we can replace the ones we use with more interpretable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fc65d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlsy[\"sat_verbal\"] = nlsy[\"R9793800\"]\n",
    "nlsy[\"sat_math\"] = nlsy[\"R9793900\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a6b38",
   "metadata": {},
   "source": [
    "Both columns contain a few values less than 200, which is not possible because 200 is the lowest score, so we'll replace them with `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75f0085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"sat_verbal\", \"sat_math\"]\n",
    "\n",
    "for column in columns:\n",
    "    invalid = nlsy[column] < 200\n",
    "    nlsy.loc[invalid, column] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41efbdaf",
   "metadata": {},
   "source": [
    "Next we'll use `dropna` to select only rows where both scores are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f3d8b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlsy_valid = nlsy.dropna(subset=columns).copy()\n",
    "nlsy_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a23c87",
   "metadata": {},
   "source": [
    "SAT scores are standardized so the mean is 500 and the standard deviation is 100.\n",
    "In the NLSY sample, the means and standard deviations are close to these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d31de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_verbal = nlsy_valid[\"sat_verbal\"]\n",
    "sat_verbal.mean(), sat_verbal.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a984b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_math = nlsy_valid[\"sat_math\"]\n",
    "sat_math.mean(), sat_math.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c079e47",
   "metadata": {},
   "source": [
    "Now, to see whether there is a relationship between these variables, let's look at a **scatter plot**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2e362ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sat_verbal, sat_math)\n",
    "\n",
    "decorate(xlabel=\"SAT Verbal\", ylabel=\"SAT Math\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39524848",
   "metadata": {},
   "source": [
    "Using the default options of the `scatter` function, we can see the general shape of the relationship.\n",
    "People who do well on one section of the test tend to do better on the other, too.\n",
    "\n",
    "However, this version of the figure is **overplotted**, which means there are a lot of overlapping points, which can create a misleading impression of the relationship.\n",
    "The center, where the density of points is highest, is not as dark as it should be; by comparison, the extreme values are darker than they should be.\n",
    "Overplotting tend to give too much visual weight to outliers.\n",
    "\n",
    "We can improve the plot by reducing the marker size so they overlap less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f658d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sat_verbal, sat_math, s=5)\n",
    "\n",
    "decorate(xlabel=\"SAT Verbal\", ylabel=\"SAT Math\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac65084",
   "metadata": {},
   "source": [
    "Now we can see that the markers are aligned in rows and columns, because scores are rounded off to the nearest multiple of 10.\n",
    "Some information is lost in the process.\n",
    "\n",
    "We can't get that information back, but we can minimize the effect on the scatter plot by **jittering** the data, which means adding random noise to reverse the effect of rounding off.\n",
    "The following function takes a sequence and jitters it by adding random values from a normal distribution with mean 0 and the given standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2de395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jitter(seq, std=1):\n",
    "    \"\"\"Jitters the values by adding random Gaussian noise.\n",
    "\n",
    "    seq: sequence of numbers\n",
    "    std: standard deviation of the added noise\n",
    "\n",
    "    returns: new Numpy array\n",
    "    \"\"\"\n",
    "    n = len(seq)\n",
    "    return np.random.normal(0, std, n) + seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a9d53",
   "metadata": {},
   "source": [
    "If we jitter the scores with a standard deviation of 3, the rows and columns are no longer visible in the scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30e7bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_verbal_jittered = jitter(sat_verbal, 3)\n",
    "sat_math_jittered = jitter(sat_math, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feb909a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sat_verbal_jittered, sat_math_jittered, s=5)\n",
    "\n",
    "decorate(xlabel=\"SAT Verbal\", ylabel=\"SAT Math\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ef7d8f",
   "metadata": {},
   "source": [
    "Jittering reduces the visual effect of rounding and makes the shape of the relationship clearer.\n",
    "But in general you should only jitter data for purposes of visualization and avoid using jittered data for analysis.\n",
    "\n",
    "In this example, even after adjusting the marker size and jittering the data, there is still some overplotting.\n",
    "So let's try one more thing: we can use the `alpha` parameter to make the markers partly transparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "267e85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sat_verbal_jittered, sat_math_jittered, s=5, alpha=0.2)\n",
    "\n",
    "decorate(xlabel=\"SAT Verbal\", ylabel=\"SAT Math\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd6085",
   "metadata": {},
   "source": [
    "With transparency, overlapping data points look darker, so darkness is proportional to density.\n",
    "\n",
    "Although scatter plots are a simple and widely-used visualization, they can be hard to get right.\n",
    "In general, it takes some trial and error to adjust marker sizes, transparency, and jittering to find the best visual representation of the relationship between variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e28ec5",
   "metadata": {},
   "source": [
    "## Decile Plots\n",
    "\n",
    "Scatter plots provide a general impression of the relationship between variables, but there are other visualizations that provide more insight into the nature of the relationship.\n",
    "One of them is a **decile plot**.\n",
    "\n",
    "To generate a decile plot, we'll sort the respondents by verbal scores and divide them into 10 groups, called **deciles**.\n",
    "We can use the `qcut` method to compute the deciles and add the results as a column in the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c74cc154",
   "metadata": {},
   "outputs": [],
   "source": [
    "deciles = pd.qcut(nlsy_valid[\"sat_verbal\"], 10, labels=False) + 1\n",
    "deciles.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b217759e",
   "metadata": {},
   "source": [
    "For each respondent, the `decile` column indicates which decile their verbal score falls in.\n",
    "The number of respondents in each decile is roughly equal.\n",
    "\n",
    "Now we can use the `groupby` method to divide the `DataFrame` into groups by `decile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc2d2294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby = nlsy_valid.groupby(deciles)\n",
    "df_groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a1bd59",
   "metadata": {},
   "source": [
    "The result is a `DataFrameGroupBy` object that represents the groups.\n",
    "We can select the `sat_math` column from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "316b9219",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_groupby = df_groupby[\"sat_math\"]\n",
    "series_groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4af738",
   "metadata": {},
   "source": [
    "The result is a `SeriesGroupBy` object that represents the math scores in each decile.\n",
    "We can use the `quantile` function to compute the 10th, 50th, and 90th percentiles in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f2dc655",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = series_groupby.quantile(0.1)\n",
    "median = series_groupby.quantile(0.5)\n",
    "high = series_groupby.quantile(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef92e8e",
   "metadata": {},
   "source": [
    "A decile plot shows these percentiles for each decile group.\n",
    "In the following figure, the line shows the median and the shaded region shows the area between the 10th and 90th percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33bebae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = low.index\n",
    "\n",
    "plt.fill_between(xs, low, high, alpha=0.2)\n",
    "plt.plot(xs, median, color=\"C0\", label=\"median\")\n",
    "\n",
    "decorate(xlabel=\"SAT Verbal Decile\", ylabel=\"SAT Math\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba049565",
   "metadata": {},
   "source": [
    "As an alternative, we can compute the median verbal score in each group and plot those values on the x-axis, rather than the decile numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7079db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = df_groupby[\"sat_verbal\"].median()\n",
    "\n",
    "plt.fill_between(xs, low, high, alpha=0.2)\n",
    "plt.plot(xs, median, color=\"C0\", label=\"median\")\n",
    "\n",
    "decorate(xlabel=\"SAT Verbal\", ylabel=\"SAT Math\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27526e6c",
   "metadata": {},
   "source": [
    "It looks like the relationship between these variables is linear -- that is, each increase the median verbal scores corresponds to a roughly equal increase in median math scores.\n",
    "\n",
    "More generally, we could divide the respondents into any number of groups, not necessarily 10, and we could compute other summary statistics in each group, not just these percentiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503b7c6e",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "\n",
    "When the NLSY participants were in 9th grade, many of them took the mathematics section of the Peabody Individual Achievement Test (PIAT).\n",
    "Let's give the column that contains the results a more interpretable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db6aaf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlsy[\"piat_math\"] = nlsy[\"R1318200\"]\n",
    "nlsy[\"piat_math\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4e4716",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here's what the distribution of scores looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ace951d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from empiricaldist import Cdf\n",
    "\n",
    "cdf_piat_math = Cdf.from_seq(nlsy[\"piat_math\"])\n",
    "cdf_piat_math.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b6f2e",
   "metadata": {},
   "source": [
    "Students who do well on the PIAT in 9th grade are likely to do well on the SAT math second in 12th grade.\n",
    "For the NLSY participants who took both tests, the following scatter plot shows the relationship between their scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1ab698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinkstats import scatter\n",
    "\n",
    "scatter(nlsy, \"piat_math\", \"sat_math\")\n",
    "\n",
    "decorate(xlabel=\"PIAT Math\", ylabel=\"SAT Math\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157c0c7",
   "metadata": {},
   "source": [
    "Students who do well on the PIAT are also likely to do well on the SAT verbal.\n",
    "The following figure shows the relationship between the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1f033da",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(nlsy, \"piat_math\", \"sat_verbal\")\n",
    "\n",
    "decorate(xlabel=\"PIAT Math\", ylabel=\"SAT Verbal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4ce427",
   "metadata": {},
   "source": [
    "Comparing the scatter plots, the points in the first figure might be more compact, and the points in the second figure more dispersed.\n",
    "If so, that means that the PIAT math scores predict SAT math scores more accurately than they predict SAT verbal scores -- and it makes sense if they do.\n",
    "\n",
    "To quantify the strength of these relationships, we can use the **Pearson correlation coefficient**, often just called \"correlation\".\n",
    "To understand correlation, let's start with standardization.\n",
    "\n",
    "To standardize a variable, we subtract off the mean and divide through by the standard deviation, as in this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19abd26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(xs):\n",
    "    \"\"\"Standardizes a sequence of numbers.\n",
    "\n",
    "    xs: sequence of numbers\n",
    "\n",
    "    returns: NumPy array\n",
    "    \"\"\"\n",
    "    return (xs - np.mean(xs)) / np.std(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ffd0a5",
   "metadata": {},
   "source": [
    "To show how it's used, we'll select the rows where `piat_math` and `sat_math` are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e86cfdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = nlsy.dropna(subset=[\"piat_math\", \"sat_math\"])\n",
    "piat_math = valid[\"piat_math\"]\n",
    "sat_math = valid[\"sat_math\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a610382c",
   "metadata": {},
   "source": [
    "And standardize the PIAT math scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "446d2357",
   "metadata": {},
   "outputs": [],
   "source": [
    "piat_math_standard = standardize(piat_math)\n",
    "np.mean(piat_math_standard), np.std(piat_math_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2e36a4",
   "metadata": {},
   "source": [
    "The results are **standard scores**, also called \"z-scores\".\n",
    "By design, the mean of the standard scores is close to 0 and the standard deviation is close to 1.\n",
    "\n",
    "Let's also standardize the SAT math scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf067f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_math_standard = standardize(sat_math)\n",
    "np.mean(sat_math_standard), np.std(sat_math_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8486034c",
   "metadata": {},
   "source": [
    "The following figure shows sequences of these scores for the first 100 participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "391880a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.axhline(0, color=\"gray\", lw=1, alpha=0.5)\n",
    "plt.plot(piat_math_standard.values[:100], label=\"PIAT math\")\n",
    "decorate(ylabel=\"z-score\", xticks=[])\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.axhline(0, color=\"gray\", lw=1, alpha=0.5)\n",
    "plt.plot(sat_math_standard.values[:100], label=\"SAT math\", color=\"C1\")\n",
    "decorate(ylabel=\"z-score\", xticks=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ae4459",
   "metadata": {},
   "source": [
    "These variables are clearly related: when one is above the mean, the other is likely to be above the mean, too.\n",
    "To quantify the strength of this relationship, we'll multiply the standard scores element-wise and compute the mean of the products.\n",
    "\n",
    "When both scores are positive, their product is positive, so it tends to increase the mean.\n",
    "And when both scores are negative, their product is positive, so it also tends to increase the mean.\n",
    "When the scores have opposite signs, the product is negative, so it decreases the mean.\n",
    "As a result, the mean of the product measures the similarity between the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5373a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(piat_math_standard * sat_math_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7351bf",
   "metadata": {},
   "source": [
    "The result, which is about 0.64, is the correlation coefficient.\n",
    "Here's one way to interpret it: if someone's PIAT math score is 1 standard deviation above the mean, we expect their SAT math score to be 0.64 standard deviations above the mean, on average.\n",
    "\n",
    "The result is the same if we multiply the elements in the other order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc6e256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(sat_math_standard * piat_math_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4567ddce",
   "metadata": {},
   "source": [
    "So the correlation coefficient is symmetric: if someone's SAT math score is 1 standard deviation above the mean, we expect their PIAT math score to be 0.64 standard deviations above the mean, on average.\n",
    "\n",
    "Correlation is a commonly-used statistic, so NumPy provides a function that computes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0227198",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(piat_math, sat_math)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3919d9",
   "metadata": {},
   "source": [
    "The result is a **correlation matrix**, with one row and one column for each variable.\n",
    "The value in the upper left is the correlation of `piat_math` with itself.\n",
    "The value in the lower right is the correlation of `sat_math` with itself.\n",
    "The correlation of any variable with itself is 1, which indicates perfect correlation.\n",
    "\n",
    "The values in the upper right and lower left are the correlation of `piat_math` with `sat_math` and the correlation of `sat_math` with `piat_math`, which are necessarily equal. \n",
    "\n",
    "`thinkstats` provides a `corrcoef` function that takes a `DataFrame` and two column names, selects the rows where both columns are valid, and computes their correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "846e2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinkstats import corrcoef\n",
    "\n",
    "corrcoef(nlsy, \"piat_math\", \"sat_math\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8d5a6c",
   "metadata": {},
   "source": [
    "We can use this function to compute the correlation of `piat_math` and `sat_verbal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37e14193",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrcoef(nlsy, \"piat_math\", \"sat_verbal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a98516",
   "metadata": {},
   "source": [
    "The correlation is about 0.51, so if someone's PIAT math score is one standard deviation above the mean, we expect their SAT verbal score to be 0.51 standard deviations above the mean, on average.\n",
    "\n",
    "As we might expect, PIAT math scores predict SAT math scores better than they predict SAT verbal score -- but not by very much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19d94ec",
   "metadata": {},
   "source": [
    "## Strength of Correlation\n",
    "\n",
    "As you look at more scatter plots, you will get a sense of what different correlations look like.\n",
    "To help you develop this sense, the following figure shows scatter plots for randomly-generated data with different correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6eb14d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "xs = np.random.normal(size=300)\n",
    "ys = np.random.normal(size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b70be932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from thinkstats import make_correlated_scatter\n",
    "\n",
    "plt.figure(figsize=(10, 2.5))\n",
    "\n",
    "for i, rho in enumerate([0, 0.3, 0.7, 0.99]):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    make_correlated_scatter(xs, ys, rho)\n",
    "decorate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ec51a8",
   "metadata": {},
   "source": [
    "The Greek letter ρ, which is spelled \"rho\" and pronounced like \"row\", is the conventional symbol for the correlation coefficient.\n",
    "\n",
    "Correlation can also be negative.\n",
    "Here are scatter plots for random data with a range of negative correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fbe1a470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 2.5))\n",
    "\n",
    "for i, rho in enumerate([-0.1, -0.3, -0.7, -0.99]):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    make_correlated_scatter(xs, ys, rho)\n",
    "decorate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf40c0f",
   "metadata": {},
   "source": [
    "The correlation coefficient is always between -1 and 1.\n",
    "If there is no relationship between two variables, their correlation is 0 -- but if the correlation is 0, that doesn't necessarily mean there is no relationship.\n",
    "\n",
    "In particular, if there is a non-linear relationship, the correlation coefficient can be close to 0.\n",
    "In each of the following examples, there is a clear relationship between the variables in the sense that if we are given one of the values, we can make a substantially better prediction of the other.\n",
    "But in each case the correlation coefficient is close to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55bb0f69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from thinkstats import make_nonlinear_scatter\n",
    "\n",
    "plt.figure(figsize=(10, 2.5))\n",
    "\n",
    "for i, kind in enumerate([\"abs\", \"quadratic\", \"sinusoid\"]):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    make_nonlinear_scatter(xs, ys, kind)\n",
    "decorate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813492ce",
   "metadata": {},
   "source": [
    "The important thing to remember is that correlation quantifies the strength of a *linear* relationship between variables.\n",
    "If there is a non-linear relationship, the correlation coefficient can be misleading.\n",
    "And if the correlation is close to 0, that does *not* mean there is no relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d3927",
   "metadata": {},
   "source": [
    "## Rank Correlation\n",
    "\n",
    "\n",
    "The NLSY is longitudinal, which means that it follows the same group of people over time.\n",
    "The group we've been studying includes people born between 1980 and 1984.\n",
    "The ones who took the SAT probably took it in the late 1990s, when they were about 18 years old.\n",
    "So when they were asked about their income in 2021, they were in their late 30s or early 40s.\n",
    "\n",
    "Let's give the column with the income data a more interpretable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e84e6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlsy[\"income\"] = nlsy[\"U4949700\"]\n",
    "nlsy[\"income\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8cbcbb",
   "metadata": {},
   "source": [
    "The values in this column are gross family income, which is total income from all sources of the respondent and the other members of their household, reported in U.S. dollars (USD).\n",
    "Here's what the distribution of income looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02490eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_income = Cdf.from_seq(nlsy[\"income\"])\n",
    "cdf_income.step()\n",
    "\n",
    "decorate(xlabel=\"Income (USD)\", ylabel=\"CDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5fee5a",
   "metadata": {},
   "source": [
    "Notice the step near $600,000 -- values above this threshold were capped to protect the anonymity of the participants.\n",
    "Now here's a scatter plot of the respondents' SAT math scores and their income later in life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "122dfbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(nlsy, \"piat_math\", \"income\")\n",
    "\n",
    "decorate(xlabel=\"PIAT math\", ylabel=\"Gross Family Income (USD)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f8fc85",
   "metadata": {},
   "source": [
    "It looks like there is a relationship between these variables.\n",
    "Here is the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "805329c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrcoef(nlsy, \"piat_math\", \"income\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed93365a",
   "metadata": {},
   "source": [
    "The correlation is about 0.3, which means that if someone gets a PIAT math score one standard deviation above the mean when they are 15 years old, we expect their income to be about 0.3 standard deviations above the mean when they are 40.\n",
    "That's not as strong as the correlation between PIAT scores and SAT scores, but considering the number of factors that affect income, it's pretty strong.\n",
    "\n",
    "In fact, Pearson's correlation coefficient might understate the strength of the relationship.\n",
    "As we can see in the previous scatter plot, both variables have an apparent excess of values at the extremes.\n",
    "Because the correlation coefficient is based on the product of deviations from the mean, it is sensitive to these extreme values.\n",
    "\n",
    "A more robust alternative is the **rank correlation**, which is based on the ranks of the scores rather than standardized scores.\n",
    "We can use the Pandas method `rank` to compute the rank of each score and each income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb84c189",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = nlsy.dropna(subset=[\"piat_math\", \"income\"])\n",
    "\n",
    "piat_math_rank = valid[\"piat_math\"].rank()\n",
    "income_rank = valid[\"income\"].rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a6704d",
   "metadata": {},
   "source": [
    "The results for both variables are ranks from 1 to 6051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4baac236",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_rank.min(), income_rank.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1aacca",
   "metadata": {},
   "source": [
    "Here's a scatter plot of the ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4470cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(piat_math_rank, income_rank, s=5, alpha=0.2)\n",
    "\n",
    "decorate(xlabel=\"PIAT math rank\", ylabel=\"Income rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fde67d",
   "metadata": {},
   "source": [
    "And here's the correlation of the ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9cfd2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(piat_math_rank, income_rank)[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17287efd",
   "metadata": {},
   "source": [
    "The result is about 0.38, somewhat higher than the Pearson correlation, which is 0.30.\n",
    "Because rank correlation is less sensitive to the effect of extreme values, it is probably a better measure of the strength of the relationship between these variables.\n",
    "\n",
    "`thinkplot` provides a `rankcorr` function that encapsulates the code in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9def2d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinkstats import rankcorr\n",
    "\n",
    "rankcorr(nlsy, \"piat_math\", \"income\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375c01a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "And SciPy provides a similar function called `spearmanr`, because rank correlation is also called Spearman's correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53c7ab46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "spearmanr(valid[\"piat_math\"], valid[\"income\"]).statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d26d41",
   "metadata": {},
   "source": [
    "As an exercise, you'll have a chance to compute the correlation between SAT verbal scores and income, using both Pearson's correlation and rank correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a5b4cd",
   "metadata": {},
   "source": [
    "## Correlation and Causation\n",
    "\n",
    "If variables A and B are correlated, there are three possible explanations: A causes B, or B causes A, or some other set of factors causes both A and B. These explanations are called \"causal relationships\".\n",
    "\n",
    "Correlation alone does not distinguish between these explanations, so it does not tell you which ones are true.\n",
    "This rule is often summarized with the phrase \"Correlation does not imply causation,\" which is so pithy it has its own Wikipedia page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06983fb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<http://wikipedia.org/wiki/Correlation_does_not_imply_causation>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4ace1e",
   "metadata": {},
   "source": [
    "So what can you do to provide evidence of causation?\n",
    "\n",
    "1.  Use time. If A comes before B, then A can cause B but not the other way around.\n",
    "The order of events can help us infer the direction of causation, but it does not preclude the possibility that something else causes both A and B.\n",
    "\n",
    "2.  Use randomness.\n",
    "If you divide a large sample into two groups at random and compute the means of almost any variable, you expect the difference to be small.\n",
    "If the groups are nearly identical in all variables but one, you can eliminate spurious relationships.\n",
    "\n",
    "These ideas are the motivation for the **randomized controlled trial**, in which subjects are assigned randomly to two (or more) groups: a **treatment group** that receives some kind of intervention, like a new medicine, and a **control group** that receives no intervention, or another treatment whose effects are known.\n",
    "A randomized controlled trial is the most reliable way to demonstrate a causal relationship, and the foundation of science-based medicine.\n",
    "\n",
    "Unfortunately, controlled trials are only possible in the laboratory sciences, medicine, and a few other disciplines.\n",
    "In the social sciences, controlled experiments are rare, usually because they are impossible or unethical.\n",
    "An alternative is to look for a **natural experiment**, where similar groups are exposed to different conditions due to circumstances beyond the control of the experimenter.\n",
    "\n",
    "Identifying and measuring causal relationships is the topic of a branch of statistics called **causal inference**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4586192",
   "metadata": {},
   "source": [
    "## Glossary\n",
    "\n",
    "-   **scatter plot**: A visualization of the relationship between two variables, showing one point for each row of data.\n",
    "\n",
    "-   **jitter**: Random noise added to data for purposes of visualization.\n",
    "\n",
    "-   **saturation**: Loss of information when multiple points are plotted on top of each other.\n",
    "\n",
    "-   **correlation**: A statistic that measures the strength of the relationship between two variables.\n",
    "\n",
    "-   **standardize**: To transform a set of values so that their mean is 0 and their variance is 1.\n",
    "\n",
    "-   **standard score**: A value that has been standardized so that it is expressed in standard deviations from the mean.\n",
    "\n",
    "-   **covariance**: A measure of the tendency of two variables to vary together.\n",
    "\n",
    "-   **rank**: The index where an element appears in a sorted list.\n",
    "\n",
    "-   **randomized controlled trial**: An experimental design in which subjects are divided into groups at random, and different groups are given different treatments.\n",
    "\n",
    "-   **treatment group**: A group in a controlled trial that receives some kind of intervention.\n",
    "\n",
    "-   **control group**: A group in a controlled trial that receives no treatment, or a treatment whose effect is known.\n",
    "\n",
    "-   **natural experiment**: An experimental design that takes advantage of a natural division of subjects into groups in ways that are at least approximately random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eff46b",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ca158a",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "`thinkstats` provides a function called `decile_plot` that encapsulates the code from Section xxx.\n",
    "We can call it like this to visualize the relationship between SAT verbal and math scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6f6a419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinkstats import decile_plot\n",
    "\n",
    "decile_plot(nlsy, \"sat_verbal\", \"sat_math\")\n",
    "decorate(xlabel=\"SAT Verbal\", ylabel=\"SAT Math\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48e4f9c",
   "metadata": {},
   "source": [
    "Make a decile plot of PIAT math scores and income.\n",
    "Does it appear to be a linear relationship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "253c3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a462b376",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Make a scatter plot of income versus SAT math scores.\n",
    "Compute Pearson's correlation and rank correlation.\n",
    "Are they substantially different?\n",
    "\n",
    "Make a scatter plot of income versus SAT verbal scores, and compute both correlations.\n",
    "Which is a stronger prediction of future income, math or verbal scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c451726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4c09e741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8988e57e",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Let's see how a student's high school grade point average (GPA) is correlated with their SAT scores.\n",
    "Here's the variable in the NLSY dataset that encodes GPA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b4bae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_codes = [-6, -7, -8, -9]\n",
    "nlsy[\"gpa\"] = nlsy[\"R9871900\"].replace(missing_codes, np.nan) / 100\n",
    "nlsy[\"gpa\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df5e3a",
   "metadata": {},
   "source": [
    "And here's what the distribution of GPAs looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b9c42969",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_income = Cdf.from_seq(nlsy[\"gpa\"])\n",
    "cdf_income.step()\n",
    "decorate(xlabel=\"Income (USD)\", ylabel=\"CDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3409ce",
   "metadata": {},
   "source": [
    "Make a scatter plot that shows the relationship between GPA and SAT math scores and compute the correlation coefficient.\n",
    "Do the same for the relationship between GPA and SAT verbal scores.\n",
    "Which SAT score is a better predictor of GPA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ac28b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "79d6b9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa23e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d7b0f8",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Let's investigate the relationship between education and income.\n",
    "The NLSY dataset includes a column that reports the highest degree earned by each respondent.\n",
    "The values are encoded as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1fa8729",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlsy[\"degree\"] = nlsy[\"Z9083900\"]\n",
    "nlsy[\"degree\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6dfbbb",
   "metadata": {},
   "source": [
    "But we can use these lists to decode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cfdc04d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "labels = [\n",
    "    \"None\",\n",
    "    \"GED\",\n",
    "    \"High school diploma\",\n",
    "    \"Associate's degree\",\n",
    "    \"Bachelor's degree\",\n",
    "    \"Master's degree\",\n",
    "    \"PhD\",\n",
    "    \"Professional degree\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edf50ee",
   "metadata": {},
   "source": [
    "And make a `Pmf` that represents the distribution of educational attainment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f496ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from empiricaldist import Pmf\n",
    "\n",
    "Pmf.from_seq(nlsy[\"degree\"]).bar()\n",
    "\n",
    "plt.xticks(positions, labels, rotation=30, ha=\"right\")\n",
    "decorate(ylabel=\"PMF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95686a46",
   "metadata": {},
   "source": [
    "Make a scatter plot of `income` versus `degree`.\n",
    "To avoid overplotting, jitter the values of `degree` and adjust the marker size and transparency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72d38760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b834847",
   "metadata": {},
   "source": [
    "Use the `groupby` method to group respondents by `degree`.\n",
    "From the `DataFrameGroupBy` object, select the `income` column; then use the `quantile` method to compute the median, 10th and 90th percentiles in each group.\n",
    "Use `fill_between` to plot the region between the 10th and 90th percentiles, and use `plot` to plot the medians.\n",
    "\n",
    "What can you say about the income premium associated with each additional degree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "06165707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad16602",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "The Behavioral Risk Factor Surveillance System (BRFSS) dataset includes self-reported heights and weights for more than 400,000 respondents.\n",
    "Instructions for downloading the data are in the notebook for this chapter.\n",
    "\n",
    "Make a scatter plot that shows the relationship between height and weight. You might have to jitter the data to blur the visible rows and columns due to rounding off.\n",
    "And with such a large sample size, you will have to adjust the marker size and transparency to avoid overplotting.\n",
    "Also, because there are outliers in both measurement, you might want to use `xlim` and `ylim` to zoom in on a region that covers most of the respondents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2bf0cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here's how we can load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d079e1cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/CDBRFS08.ASC.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f0c95fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from thinkstats import read_brfss\n",
    "\n",
    "brfss = read_brfss()\n",
    "brfss[\"htm3\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "113a01af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8918c1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b0e975",
   "metadata": {},
   "source": [
    "Make a decile plot of weight versus height. Does the relationship seem to be linear?\n",
    "Compute the correlation coefficient and rank correlation. Are they substantially different? Which one do you think better quantifies the relationship between these variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e8573793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "66c5d783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27da3a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "[Think Stats: Exploratory Data Analysis in Python, 3rd Edition](https://allendowney.github.io/ThinkStats/index.html)\n",
    "\n",
    "Copyright 2024 [Allen B. Downey](https://allendowney.com)\n",
    "\n",
    "Code license: [MIT License](https://mit-license.org/)\n",
    "\n",
    "Text license: [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
