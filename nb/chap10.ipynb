{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ae6fa0",
   "metadata": {},
   "source": [
    "# Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3504ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import basename, exists\n",
    "\n",
    "\n",
    "def download(url):\n",
    "    filename = basename(url)\n",
    "    if not exists(filename):\n",
    "        from urllib.request import urlretrieve\n",
    "\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print(\"Downloaded \" + local)\n",
    "\n",
    "\n",
    "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/nb/thinkstats.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fff28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import empiricaldist\n",
    "except ImportError:\n",
    "    !pip install empiricaldist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "586c1450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from thinkstats import decorate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c71994",
   "metadata": {},
   "source": [
    "## Least Squares Fit\n",
    "\n",
    "As an example, let's return to the scenario from Chapter xxx.\n",
    "Suppose you are a researcher in Antarctica, studying local populations of penguins.\n",
    "Are part of your data collection, you capture a sample of penguins, measure and weigh them -- and then release them unharmed.\n",
    "But it is notoriously difficult to get penguins to stay on the scale long enough to get an accurate measurement.\n",
    "So let's suppose that for some penguins we have measurements like flipper length, but no weights.\n",
    "Maybe we can use the other measurements to fill in the missing data -- this process is called **imputation**.\n",
    "\n",
    "We'll start by exploring the relationship between the weights and measurements, using data collected between 2007 and 2010 by researchers at Palmer Station in Antarctica.\n",
    "The data they collected is freely available -- instructions for downloading it are in the notebook for this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbd7611",
   "metadata": {
    "tags": []
   },
   "source": [
    "The following cell downloads the data from a repository created by Allison Horst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c419a922",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "download(\n",
    "    \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/c19a904462482430170bfe2c718775ddb7dbb885/inst/extdata/penguins_raw.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "620df7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv(\"penguins_raw.csv\").dropna(subset=[\"Body Mass (g)\"])\n",
    "penguins.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1c33a3",
   "metadata": {},
   "source": [
    "The dataset includes measurements of 151 Adélie penguins.\n",
    "We can use `query` to select the rows that contain this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be0840eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adelie = penguins.query('Species.str.startswith(\"Adelie\")')\n",
    "len(adelie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956994da",
   "metadata": {},
   "source": [
    "Now suppose we know the flipper length of an Adélie penguin -- let's see how well we can predict its weight.\n",
    "First we'll select these columns from the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdaaa183",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvar = \"Flipper Length (mm)\"\n",
    "yvar = \"Body Mass (g)\"\n",
    "\n",
    "flipper_length = adelie[xvar]\n",
    "body_mass = adelie[yvar]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a935544",
   "metadata": {},
   "source": [
    "Here's a scatter plot showing the relationship between these quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e00b0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(flipper_length, body_mass, marker=\".\", alpha=0.5)\n",
    "decorate(xlabel=xvar, ylabel=yvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4d6645",
   "metadata": {},
   "source": [
    "It looks like they are related -- we can quantify the strength of the relationship by computing the coefficient of correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39dbc4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(flipper_length, body_mass)[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcf989a",
   "metadata": {},
   "source": [
    "The correlation is about 0.47, so penguins with longer flippers tend to be heavier.\n",
    "That's useful because it means we can guess a penguin's weight more accurately if we know its flipper length, but correlation alone doesn't tell us how to make those guesses.\n",
    "For that, we need to choose a **line of best fit**.\n",
    "\n",
    "There are many ways to define the \"best\" line, but for data like this a common choice is a **linear least squares** fit, which is the straight line that minimizes the mean squared error (MSE).\n",
    "\n",
    "SciPy provides a function called `linregress` that computes a least squares fit.\n",
    "The name is short for **linear regression**, which is another term for a least squares fit.\n",
    "Here's how we use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4058c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "result = linregress(flipper_length, body_mass)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6969e7",
   "metadata": {},
   "source": [
    "The result is a `LinregressResult` object that contains the slope and intercept of the fitted line, along with other information we'll unpack soon.\n",
    "The slope is about 32.8, which means that each additional millimeter of flipper length is associated with an addition 32.8 grams of body weight.\n",
    "\n",
    "The intercept is -2535 grams, which might seem nonsensical, since a measured weight can't be negative.\n",
    "It might make more sense if we use the slope and intercept to evaluate the fitted line at the average flipper length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f44e6281",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = flipper_length.mean()\n",
    "y = result.intercept + result.slope * x\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae01d2f7",
   "metadata": {},
   "source": [
    "For a penguin with flipper length 190 mm, the expected body weight is about 3700 grams.\n",
    "\n",
    "The following function takes the result object and a sequence of `xs` and finds the point on the fitted line for each value of `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06312185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(result, xs):\n",
    "    ys = result.intercept + result.slope * xs\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0478c4e0",
   "metadata": {},
   "source": [
    "The name `predict` might seem odd here -- in natural language, a prediction usually pertains to something happening in the future, but in the context of regression, the points on the fitted line are called predictions.\n",
    "\n",
    "We can use `predict` to compute the points on the line for a range of flipper sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b475289",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_xs = np.linspace(np.min(flipper_length), np.max(flipper_length))\n",
    "fit_ys = predict(result, fit_xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044ffcb5",
   "metadata": {},
   "source": [
    "Here's the fitted line alone with the scatter plot of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c4dcf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(flipper_length, body_mass, marker=\".\", alpha=0.5)\n",
    "plt.plot(fit_xs, fit_ys, color=\"C1\")\n",
    "decorate(xlabel=xvar, ylabel=yvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0559d9",
   "metadata": {},
   "source": [
    "As expected, the fitted line goes through the center of the data and follows the trend.\n",
    "And some of the predictions are accurate -- but many of the data points are far from the line.\n",
    "To get a sense of how good (or bad) the predictions are, we can compute the prediction error, which is the vertical distance of each point from the line.\n",
    "The following function computes these errors, which are also called **residuals**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c854090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_residuals(result, xs, ys):\n",
    "    fit_ys = predict(result, xs)\n",
    "    return ys - fit_ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c117c57d",
   "metadata": {},
   "source": [
    "Here are the residuals for body mass as a function of flipper length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb270150",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = compute_residuals(result, flipper_length, body_mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb325663",
   "metadata": {},
   "source": [
    "As an example, we can look at the results for the first penguin in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "804ae0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = flipper_length[0]\n",
    "y = predict(result, x)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50053fd",
   "metadata": {},
   "source": [
    "The flipper length of the selected penguin is 181 mm and the predicted body mass is 3407 grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80dc7884",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_mass[0], residuals[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac9b5c1",
   "metadata": {},
   "source": [
    "The actual mass of this penguin is 3750 grams, so the residual -- after subtracting away the prediction -- is 343 grams.\n",
    "\n",
    "The average of the squared residuals is the mean squared error (MSE) of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39dc7cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean(residuals**2)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042dca43",
   "metadata": {},
   "source": [
    "By itself, this number doesn't mean very much.\n",
    "We can make more sense of it by computing the coefficient of determination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ffe7e9",
   "metadata": {},
   "source": [
    "## Coefficient of Determination\n",
    "\n",
    "Suppose you want to guess the weight of a penguin.\n",
    "If you know it's flipper length, you can use the least squares fit to inform your guess, and the MSE quantifies the accuracy of your guesses, on average.\n",
    "\n",
    "But what if you don't know the flipper length -- what would you guess?\n",
    "It turns out that the best strategy is to guess the mean.\n",
    "In that case, the prediction errors are the deviations from the mean.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b3afa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "deviations = body_mass - np.mean(body_mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365302a0",
   "metadata": {},
   "source": [
    "And the MSE is the mean squared deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfad7dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(deviations**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00df28",
   "metadata": {},
   "source": [
    "And you might remember that the mean squared deviation is the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cc9ce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(body_mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d3dce4",
   "metadata": {},
   "source": [
    "So we can think of the variance of the masses as the MSE if we always guess the mean, and the variance of the residuals as the MSE if we use the regression line.\n",
    "If we compute the ratio of these variances and subtract it from 1, the result indicates how much the MSE is reduce if we use flipper lengths to inform our guesses.\n",
    "\n",
    "The following function computes this value, which is technically called the **coefficient of determination**, but because it is denoted $R^2$, most people call it \"R squared\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48684cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coefficient_of_determination(ys, residuals):\n",
    "    return 1 - np.var(residuals) / np.var(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8971c156",
   "metadata": {},
   "source": [
    "In the example, $R^2$ is about 0.22, which means that the fitted line reduces MSE by 22%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66e0749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = coefficient_of_determination(body_mass, residuals)\n",
    "R2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224130b5",
   "metadata": {},
   "source": [
    "It turns out that there's a relationship between the coefficient of determination, $R^2$, and the coefficient of correlation, $r$.\n",
    "As you might guess, just based on the notation, $r^2 = R^2$.\n",
    "\n",
    "We can show that's true by computing the square root of $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e36176e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.sqrt(R2)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8062c73d",
   "metadata": {},
   "source": [
    "And comparing it to the correlation we computed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e156d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.corrcoef(flipper_length, body_mass)[0, 1]\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee6aa24",
   "metadata": {},
   "source": [
    "The `linregress` function also computes this value and returns it as an attribute in the `RegressionResult` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f07d4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.rvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b81c96",
   "metadata": {},
   "source": [
    "The coefficients of determination and correlation convey mostly the same information, but they are interpreted differently:\n",
    "\n",
    "* Correlation quantifies the strength of the relationship on a scale from -1 to 1.\n",
    "\n",
    "* $R^2$ quantifies the ability of the fitted line to reduce MSE.\n",
    "\n",
    "Also, $R^2$ is always positive, so it doesn't indicate whether the correlation is positive or negative.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd78c9b5",
   "metadata": {},
   "source": [
    "## Minimizing MSE\n",
    "\n",
    "Earlier I said that the least squares fit is the straight line that minimizes the mean squared error (MSE).\n",
    "We won't prove that, but we can test it by adding small random values to the intercept and slope, and checking whether the MSE gets worse.\n",
    "\n",
    "The `types` module provides a `SimpleNamespace` object we can use to make a an object with `intercept` and `slope` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c98a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "intercept = result.intercept + np.random.normal(0, 1)\n",
    "slope = result.slope + np.random.normal(0, 1)\n",
    "fake_result = SimpleNamespace(intercept=intercept, slope=slope)\n",
    "fake_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02043f15",
   "metadata": {},
   "source": [
    "We can pass this object to `compute_residuals` and use the residuals to compute the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4cb5b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_residuals = compute_residuals(fake_result, flipper_length, body_mass)\n",
    "fake_mse = np.mean(fake_residuals**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef080c",
   "metadata": {},
   "source": [
    "If we compare the result to the MSE of the least squares line, it is always worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93accff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, fake_mse, fake_mse > mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cc8f21",
   "metadata": {},
   "source": [
    "Minimizing MSE is nice, but it's not the only definition of \"best\".\n",
    "One alternative is to minimize the absolute values of the errors (MAE).\n",
    "Another is to minimize the shortest distance from each point to the fitted line, which is called the \"total error\".\n",
    "In some contexts, guessing too high might be better (or worse) than guessing too low.\n",
    "In that case you might want to compute a cost function for each residual, and minimize total cost.\n",
    "\n",
    "But the least squares fit is much more widely used than the alternatives, primarily because it is efficient to compute.\n",
    "The following function shows how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "463fb4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(xs, ys):\n",
    "    xbar = np.mean(xs)\n",
    "    ybar = np.mean(ys)\n",
    "\n",
    "    xdev = xs - xbar\n",
    "    ydev = ys - ybar\n",
    "\n",
    "    slope = np.sum(xdev * ydev) / np.sum(xdev**2)\n",
    "    intercept = ybar - slope * xbar\n",
    "\n",
    "    return intercept, slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c317cad",
   "metadata": {},
   "source": [
    "To test this function, we'll use flipper length and body mass again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b12bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept, slope = least_squares(flipper_length, body_mass)\n",
    "intercept, slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85abab42",
   "metadata": {},
   "source": [
    "And we can confirm that we get the same results we got from `linregress`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "131a2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose([intercept, slope], [result.intercept, result.slope])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80963c2e",
   "metadata": {},
   "source": [
    "Minimizing MSE made sense when computational efficiency was more important than choosing the method most appropriate to the problem at hand.\n",
    "But that's no longer the case, so it is worth considering whether squared residuals are the right thing to minimize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be8b43c",
   "metadata": {},
   "source": [
    "## Estimation\n",
    "\n",
    "The parameters `slope` and `intercept` are estimates based on a sample; like other estimates, they are vulnerable to non-representative sampling, measurement error, and variability due to random sampling.\n",
    "As usual, it's hard to quantify the effect of non-representative sampling and measurement error.\n",
    "It's easier to quantify the effect of random sampling -- by running simulated experiments and computing sampling distributions of the estimates.\n",
    "\n",
    "We can simulate the experiments by resampling the data; that is, by treating the sample as if it were the whole population and drawing new samples, with replacement, from the observed data.\n",
    "The following function takes a `DataFrame` and uses the `sample` method to resample the rows and return a new `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "946cb0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(df):\n",
    "    n = len(df)\n",
    "    return df.sample(n, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ce7da",
   "metadata": {},
   "source": [
    "And the following function takes a `DataFrame`, finds the least squares fit, and returns the slope of the fitted line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bbfe5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_slope(df):\n",
    "    xs, ys = df[\"Flipper Length (mm)\"], df[\"Body Mass (g)\"]\n",
    "    result = linregress(xs, ys)\n",
    "    return result.slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8980ae4",
   "metadata": {},
   "source": [
    "We can use these functions to generate many simulated datasets and compute the slope for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5584d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_slopes = [estimate_slope(resample(adelie)) for i in range(1001)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a0455",
   "metadata": {},
   "source": [
    "The result is a sample from the sampling distribution of the slope.\n",
    "Here's what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8bc7d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinkstats import plot_kde\n",
    "\n",
    "plot_kde(resampled_slopes)\n",
    "\n",
    "decorate(xlabel=\"Slope of the fitted line (g / mm)\", ylabel=\"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e256d1c",
   "metadata": {},
   "source": [
    "We can use `percentile` to compute a 90% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c71f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci90 = np.percentile(resampled_slopes, [5, 95])\n",
    "print(result.slope, ci90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29d0d6a",
   "metadata": {},
   "source": [
    "So we could report that the estimated slope is 33 grams / mm with a 90% CI [26, 41] grams / mm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2df6315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stderr = np.std(resampled_slopes)\n",
    "stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d2bb80",
   "metadata": {},
   "source": [
    "The `RegressionResult` object we got from `linregress` provides an approximation of the standard error, based on some assumptions about the shape of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed506e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431e7625",
   "metadata": {},
   "source": [
    "The standard error we computed by resampling is a little smaller, but the difference probably doesn't matter in practice.\n",
    "\n",
    "Finally, to compute a p-value, we can approximate the sampling distribution with a normal distribution that has the same mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65500d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "m, s = np.mean(resampled_slopes), np.std(resampled_slopes)\n",
    "sampling_dist = norm(m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19193762",
   "metadata": {},
   "source": [
    "Since the estimated slope is positive, the p-value is the probability that the resampled slope is negative, which we can compute with the CDF of the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c12b99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = sampling_dist.cdf(0)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c3c26b",
   "metadata": {},
   "source": [
    "The p-value is very small, so we can conclude that the observed slope would have been very unlikely if there were actually no relationship between flipper length and body weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10af2a8e",
   "metadata": {},
   "source": [
    "## Visualizing Uncertainty\n",
    "\n",
    "Each time we resample the dataset, we get a different fitted line.\n",
    "To see how much variation there is in the lines, one option is to loop through them and plot them all.\n",
    "The following function takes a resampled `DataFrame`, computes a least squares fit, and generates predicted values for a sequence of `xs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1e34e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_line(df, fit_xs):\n",
    "    xs, ys = df[\"Flipper Length (mm)\"], df[\"Body Mass (g)\"]\n",
    "    result = linregress(xs, ys)\n",
    "    fit_ys = predict(result, fit_xs)\n",
    "    return fit_ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c885dbe",
   "metadata": {},
   "source": [
    "Here's the sequence of `xs` we'll use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7533f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = adelie[\"Flipper Length (mm)\"]\n",
    "fit_xs = np.linspace(np.min(xs), np.max(xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3691a5d",
   "metadata": {},
   "source": [
    "And here's what the fitted lines look like, along with a scatter plot of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f02ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(flipper_length, body_mass, marker=\".\", alpha=0.5)\n",
    "\n",
    "for i in range(101):\n",
    "    fit_ys = fit_line(resample(adelie), fit_xs)\n",
    "    plt.plot(fit_xs, fit_ys, color=\"C1\", alpha=0.05)\n",
    "\n",
    "decorate(xlabel=xvar, ylabel=yvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c7fab4",
   "metadata": {},
   "source": [
    "Near the middle, the fitted lines are close together -- at the extremes, they are farther apart.\n",
    "\n",
    "Another way to represent the variability of the fitted lines is to plot a 90% confidence interval for each predicted value.\n",
    "We can do that by collecting the fitted lines as a list of arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "82323ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_ys = [fit_line(resample(adelie), fit_xs) for i in range(1001)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1435df9e",
   "metadata": {},
   "source": [
    "We can think of this list of arrays as a two-dimensional array with one row for each fitted line and one column corresponding to each of the `xs`.\n",
    "\n",
    "Now we can use `percentile` with the `axis=0` argument to find the 5th, 50th, and 95th percentiles of the `ys` corresponding to each of the `xs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6625fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "low, median, high = np.percentile(fitted_ys, [5, 50, 95], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd8b3c8",
   "metadata": {},
   "source": [
    "Now we'll use `fill_between` to plot a region between the 5th and 95 percentiles, which represents the 90% CI, along with the median value in each column and a scatter plot of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f2f2757",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(flipper_length, body_mass, marker=\".\", alpha=0.5)\n",
    "\n",
    "plt.fill_between(fit_xs, low, high, color=\"C1\", lw=0, alpha=0.2)\n",
    "plt.plot(fit_xs, median, color=\"C1\")\n",
    "\n",
    "decorate(xlabel=xvar, ylabel=yvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a2608",
   "metadata": {},
   "source": [
    "This is my favorite way of to represent the variability of a fitted line due to random sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4ad45",
   "metadata": {},
   "source": [
    "## Transformation\n",
    "\n",
    "Before fitting a line to data, it is sometimes useful to transform one or both variables, for example by computing the squares of the values, their square roots, or their logarithms.\n",
    "To demonstrate, we'll use heights and weights from the BRFSS, which we saw in Section xxx.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03624ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "The following cell downloads the BRFSS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e63baf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/CDBRFS08.ASC.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3567c02b",
   "metadata": {},
   "source": [
    "We can load the BRFSS data like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5952b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinkstats import read_brfss\n",
    "\n",
    "brfss = read_brfss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67523bd",
   "metadata": {},
   "source": [
    "Next we'll select the rows with valid data and select the columns containing heights in centimeters and weights in kilograms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69a5306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = brfss.dropna(subset=[\"htm3\", \"wtkg2\"])\n",
    "heights, weights = valid[\"htm3\"], valid[\"wtkg2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dfb595",
   "metadata": {},
   "source": [
    "We can use `linregress` to compute the slope and intercept of the least squares fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "676f5d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_brfss = linregress(heights, weights)\n",
    "result_brfss.intercept, result_brfss.slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc30f57c",
   "metadata": {},
   "source": [
    "The slope is about 0.96, which means that an increase of 1 centimeter corresponds to an increase of almost 1 kilogram, on average.\n",
    "We can use `predict` again to generate predicted values for a range of `xs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "673d3e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_xs = np.linspace(heights.min(), heights.max())\n",
    "fit_ys = predict(result_brfss, fit_xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb43844b",
   "metadata": {},
   "source": [
    "Before we make a scatter plot of the data, it's useful to jitter the heights and weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "096c4dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinkstats import jitter\n",
    "\n",
    "jittered_heights = jitter(heights, 2)\n",
    "jittered_weights = jitter(weights, 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc0610d",
   "metadata": {},
   "source": [
    "And we'll use the mean and standard deviation of the heights to choose the limits of the $x$ axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5dc09724",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, s = heights.mean(), heights.std()\n",
    "xlim = m - 4 * s, m + 4 * s\n",
    "ylim = 0, 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897901c3",
   "metadata": {},
   "source": [
    "Here's a scatter plot of the jittered data along with the fitted line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4dd0b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(jittered_heights, jittered_weights, alpha=0.01, s=0.1)\n",
    "plt.plot(fit_xs, fit_ys, color=\"C1\")\n",
    "decorate(xlabel=\"Height (cm)\", ylabel=\"Weight (kg)\", xlim=xlim, ylim=ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fb9546",
   "metadata": {},
   "source": [
    "It might seem like the fitted line doesn't pass through the densest part of the scatter plot.\n",
    "That's because the weights don't follow a normal distribution.\n",
    "As we saw in Section xxx (Chapter 5), adult weights tend to follow a lognormal distribution, which is skewed toward larger values -- and that pulls the fitted line up.\n",
    "\n",
    "Another cause for concern is the distribution of the residuals, which looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "690052bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = compute_residuals(result_brfss, heights, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a5c068b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinkstats import make_pmf\n",
    "\n",
    "pmf_kde = make_pmf(residuals, -60, 120)\n",
    "pmf_kde.plot()\n",
    "\n",
    "decorate(xlabel=\"Residual (kg)\", ylabel=\"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba56d5a",
   "metadata": {},
   "source": [
    "The distribution of the residuals is skewed to the right.\n",
    "By itself, that's not necessarily a problem, but it suggests that the least squares fit has not described the relationship between these variables precisely.\n",
    "\n",
    "If the weights follow a lognormal distribution, their logarithms follow a normal distribution.\n",
    "So let's see what happens if we fit a line to the logarithms of weight as a function of height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3aee74ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_weights = np.log10(weights)\n",
    "result_brfss2 = linregress(heights, log_weights)\n",
    "result_brfss2.intercept, result_brfss2.slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f943315a",
   "metadata": {},
   "source": [
    "Because we transformed one of the variables, the slope and intercept are harder to interpret.\n",
    "But we can use `predict` to compute the fitted line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d7a70f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_xs = np.linspace(heights.min(), heights.max())\n",
    "fit_ys = predict(result_brfss2, fit_xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14366c7",
   "metadata": {},
   "source": [
    "And then plot it along with a scatter plot of the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "140c444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jittered_log_weights = jitter(log_weights, 1.5)\n",
    "plt.scatter(jittered_heights, log_weights, alpha=0.01, s=0.1)\n",
    "plt.plot(fit_xs, fit_ys, color=\"C1\")\n",
    "decorate(xlabel=\"Height (cm)\", ylabel=\"Weight (log10 kg)\", xlim=xlim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed46ead",
   "metadata": {},
   "source": [
    "The fitted line passes through the densest part of the plot, and the actual values extend about the same distance above and below the line.\n",
    "And the distribution of the residuals is roughly symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "648fcc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = compute_residuals(result, heights, log_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eaf06507",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf_kde = make_pmf(residuals, -0.6, 0.6)\n",
    "pmf_kde.plot()\n",
    "\n",
    "decorate(xlabel=\"Residual (kg)\", ylabel=\"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd26003",
   "metadata": {},
   "source": [
    "The appearance of the scatter plot and the distribution of the residuals suggest that the relationship of height and log-transformed weight is well described by the fitted line.\n",
    "If we compare the $r$ values of the two regressions, we see that the correlation of height with log-transformed weights is slightly higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f06bdbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_brfss.rvalue, result_brfss2.rvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67b10c3",
   "metadata": {},
   "source": [
    "Which means that the $R^2$ value is slightly higher, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e688139",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_brfss.rvalue**2, result_brfss2.rvalue**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50403512",
   "metadata": {},
   "source": [
    "If we use heights to guess weights, the guesses will be a little better if we work with the log-transformed weights.\n",
    "\n",
    "However, transforming the data can make the results harder to interpret -- it can help to invert the transformation before presenting the results.\n",
    "For example, the inverse of a logarithm in base 10 is exponentiation with base 10.\n",
    "Here's what the fitted line looks like after the inverse transformation, along with the untransformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5f0ac955",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(jittered_heights, jittered_weights, alpha=0.01, s=0.1)\n",
    "plt.plot(fit_xs, 10**fit_ys, color=\"C1\")\n",
    "decorate(xlabel=\"Height (cm)\", ylabel=\"Weight (kg)\", xlim=xlim, ylim=ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5b530f",
   "metadata": {},
   "source": [
    "A fitted line that's straight with respect to the transformed data is curved with respect to the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48031c7b",
   "metadata": {},
   "source": [
    "## Glossary\n",
    "\n",
    "-   **linear fit**: a line intended to model the relationship between variables.\n",
    "\n",
    "-   **least squares fit**: A model of a dataset that minimizes the sum of squares of the residuals.\n",
    "\n",
    "-   **residual**: The deviation of an actual value from a model.\n",
    "\n",
    "-   **goodness of fit**: A measure of how well a model fits data.\n",
    "\n",
    "-   **coefficient of determination**: A statistic intended to quantify goodness of fit.\n",
    "\n",
    "-   **sampling weight**: A value associated with an observation in a sample that indicates what part of the population it represents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27d748b",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03729432",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "In this chapter we computed a least squares fit for penguin weights as a function of flipper length.\n",
    "There are two other measurements in the dataset we can also consider: culmen length and culmen depth (the culmen is the top ridge of the bill).\n",
    "\n",
    "Compute the least squares fit for weight as a function of culmen length.\n",
    "Make a scatter plot of these variables and plot the fitted line.\n",
    "\n",
    "Based on the `rvalue` attribute of the `RegressionResult` object, what is the correlation of these variables?\n",
    "What is the coefficient of determination?\n",
    "Which is a better predictor of weight, culmen length or flipper length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6282fc75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xvar = \"Culmen Length (mm)\"\n",
    "yvar = \"Body Mass (g)\"\n",
    "\n",
    "culmen_length = adelie[xvar]\n",
    "body_mass = adelie[yvar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "530f922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "02ed5fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d1d2f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "08ab59b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e8ffe7",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "In this chapter we used resampling to compute the sampling distribution for the slope of a fitted line.\n",
    "We can compute the sampling distribution of the intercept the same way:\n",
    "\n",
    "1. Write a function called `estimate_intercept` that takes a resampled `DataFrame` as an argument, computes the least squares fit of penguin weight as a function of flipper length, and returns the intercept.\n",
    "\n",
    "2. Call the function with many resampled versions of `adelie` and collect the intercepts.\n",
    "\n",
    "3. Use `plot_kde` to plot the sampling distribution of the intercept.\n",
    "\n",
    "4. Compute the standard error and a 90% confidence interval.\n",
    "\n",
    "5. Check that the standard error you get from resampling is consistent with the `intercept_stderr` attribute in the `RegressionResult` object -- it might be a little smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc18c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a7a0230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5e75168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "45981aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2eedfe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41024fcb",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "A person's Body Mass Index (BMI) is their weight in kilograms divided by their height in meters raised to the second power.\n",
    "In the BRFSS dataset, we can compute BMI like this, after converting heights from centimeters to meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0212535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_m = heights / 100\n",
    "bmis = weights / heights_m**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163b0c1",
   "metadata": {},
   "source": [
    "In this definition, heights are squared, rather than raised to some other exponent, because of the observation -- early in the history of statistics -- that average weight increases roughly in proportion to height squared.\n",
    "\n",
    "To see whether that's true, we can use data from the BRFSS, a least squares fit, and a little bit of math.\n",
    "Suppose weight is proportional to height raised to an unknown exponent, $a$.\n",
    "In that case, we can write:\n",
    "\n",
    "$$w = b h^a$$\n",
    "\n",
    "where $w$ is weight, $h$ is height, and $b$ is an unknown constant of proportionality.\n",
    "Taking logarithms of both sides:\n",
    "\n",
    "$$\\log w = \\log b + a \\log h$$\n",
    "\n",
    "So, if we compute a least squares fit for log-transformed weights as a function of log-transformed heights, the slope of the fitted line estimates the unknown exponent $a$.\n",
    "\n",
    "Compute the logarithms of height and weight.\n",
    "You can use any base for the logarithms, as long as it's the same for both transformations.\n",
    "Compute a least squares fit.\n",
    "Is the slope close to 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b4b9a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "71d47297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2de440af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "287d7e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b37273b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0efe8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74046561",
   "metadata": {
    "tags": []
   },
   "source": [
    "[Think Stats: Exploratory Data Analysis in Python, 3rd Edition](https://allendowney.github.io/ThinkStats/index.html)\n",
    "\n",
    "Copyright 2024 [Allen B. Downey](https://allendowney.com)\n",
    "\n",
    "Code license: [MIT License](https://mit-license.org/)\n",
    "\n",
    "Text license: [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n",
    "Copyright 2024 Allen Downey "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
