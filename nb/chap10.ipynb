{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ae6fa0",
   "metadata": {},
   "source": [
    "# Linear least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3504ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import basename, exists\n",
    "\n",
    "\n",
    "def download(url):\n",
    "    filename = basename(url)\n",
    "    if not exists(filename):\n",
    "        from urllib.request import urlretrieve\n",
    "\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print(\"Downloaded \" + local)\n",
    "\n",
    "\n",
    "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/nb/thinkstats.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "586c1450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from thinkstats import decorate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3e49c9",
   "metadata": {},
   "source": [
    "## Least squares fit\n",
    "\n",
    "Correlation coefficients measure the strength and sign of a\n",
    "relationship, but not the slope. There are several ways to estimate the\n",
    "slope; the most common is a **linear least squares fit**. A \"linear fit\"\n",
    "is a line intended to model the relationship between variables. A \"least\n",
    "squares\" fit is one that minimizes the mean squared error (MSE) between\n",
    "the line and the data.\n",
    "\n",
    "Suppose we have a sequence of points, `ys`, that we want to express as a\n",
    "function of another sequence `xs`. If there is a linear relationship\n",
    "between `xs` and `ys` with intercept `inter` and slope `slope`, we\n",
    "expect each `y[i]` to be `inter + slope * x[i]`.\n",
    "\n",
    "But unless the correlation is perfect, this prediction is only\n",
    "approximate. The vertical deviation from the line, or **residual**, is"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2298ef1",
   "metadata": {},
   "source": [
    "# TODO: write this in math notation\n",
    "\n",
    "res = ys - (inter + slope * xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3a7b0c",
   "metadata": {},
   "source": [
    "The residuals might be due to random factors like measurement error, or\n",
    "non-random factors that are unknown. For example, if we are trying to\n",
    "predict weight as a function of height, unknown factors might include\n",
    "diet, exercise, and body type.\n",
    "\n",
    "If we get the parameters `inter` and `slope` wrong, the residuals get\n",
    "bigger, so it makes intuitive sense that the parameters we want are the\n",
    "ones that minimize the residuals.\n",
    "\n",
    "We might try to minimize the absolute value of the residuals, or their\n",
    "squares, or their cubes; but the most common choice is to minimize the\n",
    "sum of squared residuals, `sum(res**2)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b90579",
   "metadata": {},
   "source": [
    "Why? There are three good reasons and one less important one:\n",
    "\n",
    "-   Squaring has the feature of treating positive and negative residuals\n",
    "    the same, which is usually what we want.\n",
    "\n",
    "-   Squaring gives more weight to large residuals, but not so much\n",
    "    weight that the largest residual always dominates.\n",
    "\n",
    "-   If the residuals are uncorrelated and normally distributed with mean\n",
    "    0 and constant (but unknown) variance, then the least squares fit is\n",
    "    also the maximum likelihood estimator of `inter` and `slope`. See\n",
    "    <https://en.wikipedia.org/wiki/Linear_regression>.\n",
    "\n",
    "-   The values of `inter` and `slope` that minimize the squared\n",
    "    residuals can be computed efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd29c0a",
   "metadata": {},
   "source": [
    "The last reason made sense when computational efficiency was more\n",
    "important than choosing the method most appropriate to the problem at\n",
    "hand. That's no longer the case, so it is worth considering whether\n",
    "squared residuals are the right thing to minimize.\n",
    "\n",
    "For example, if you are using `xs` to predict values of `ys`, guessing\n",
    "too high might be better (or worse) than guessing too low. In that case\n",
    "you might want to compute some cost function for each residual, and\n",
    "minimize total cost, `sum(cost(res))`. However, computing a least\n",
    "squares fit is quick, easy and often good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5870b7",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "TODO: Explain how to compute slope and inter\n",
    "\n",
    "The following function takes `xs` and `ys` and returns the intercept and slope of the best fit line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e91598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinkstats import cov\n",
    "\n",
    "\n",
    "def least_squares(xs, ys):\n",
    "    xbar = np.mean(xs)\n",
    "    ybar = np.mean(ys)\n",
    "    slope = cov(xs, ys) / np.var(xs)\n",
    "    inter = ybar - slope * xbar\n",
    "    return inter, slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb7484e",
   "metadata": {},
   "source": [
    "`least_squares` takes sequences `xs` and `ys` and returns the estimated\n",
    "parameters `inter` and `slope`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c8975",
   "metadata": {},
   "source": [
    "We can use these functions to compute the least squares fit for birth\n",
    "weight as a function of mother's age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a407a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/nb/nsfg.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/2002FemPreg.dct\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/2002FemPreg.dat.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "180ec60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nsfg\n",
    "\n",
    "live, firsts, others = nsfg.make_frames()\n",
    "live = live.dropna(subset=[\"agepreg\", \"totalwgt_lb\"])\n",
    "ages = live.agepreg\n",
    "weights = live.totalwgt_lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b160317",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter, slope = least_squares(ages, weights)\n",
    "inter, slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc5e31f",
   "metadata": {},
   "source": [
    "The estimated intercept and slope are 6.8 lbs and 0.017 lbs per year.\n",
    "These values are hard to interpret in this form: the intercept is the\n",
    "expected weight of a baby whose mother is 0 years old, which doesn't\n",
    "make sense in context, and the slope is too small to grasp easily.\n",
    "\n",
    "Instead of presenting the intercept at $x=0$, it is often helpful to\n",
    "present the intercept at the mean of $x$. In this case the mean age is\n",
    "about 25 years and the mean baby weight for a 25 year old mother is 7.3\n",
    "pounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9628bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 25\n",
    "inter + x * slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a47e9",
   "metadata": {},
   "source": [
    "The following function computes the fitted line for a sequence of `xs` and the given intercept and slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cde58c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(xs, inter, slope):\n",
    "    xs = np.asarray(xs)\n",
    "    return inter + slope * xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18803f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_line(xs, inter, slope):\n",
    "    low, high = np.min(xs), np.max(xs)\n",
    "    fit_xs = np.linspace(low, high)\n",
    "    fit_ys = predict(fit_xs, inter, slope)\n",
    "    return fit_xs, fit_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44a7fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_xs, fit_ys = fit_line(ages, inter, slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0e8293",
   "metadata": {},
   "source": [
    "Now we can plot the fitted line on top of a scatter plot of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa0aaf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ages, weights, alpha=0.1, s=5)\n",
    "plt.plot(fit_xs, fit_ys, color=\"C1\", linewidth=2)\n",
    "decorate(\n",
    "    xlabel=\"Mother's age (years)\",\n",
    "    ylabel=\"Birth weight (lbs)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e961aab",
   "metadata": {},
   "source": [
    "It's a good idea to look at a figure like this to assess whether the\n",
    "relationship is linear and whether the fitted line seems like a good\n",
    "model of the relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e815f34b",
   "metadata": {},
   "source": [
    "## Residuals\n",
    "\n",
    "Another useful test is to plot the residuals.\n",
    "\n",
    "TODO: definition\n",
    "\n",
    "The following function computes residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c854090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residuals(xs, ys, inter, slope):\n",
    "    fit_ys = predict(xs, inter, slope)\n",
    "    return ys - fit_ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab39715",
   "metadata": {},
   "source": [
    "`residuals` takes sequences `xs` and `ys` and estimated parameters\n",
    "`inter` and `slope`. It returns the differences between the actual\n",
    "values and the fitted line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc093818",
   "metadata": {},
   "outputs": [],
   "source": [
    "live[\"residual\"] = residuals(ages, weights, inter, slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaf7696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(10, 48, 3)\n",
    "indices = np.digitize(live.agepreg, bins)\n",
    "groups = live.groupby(indices)\n",
    "age_means = [group.agepreg.mean() for _, group in groups][1:-1]\n",
    "age_means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac078f",
   "metadata": {},
   "source": [
    "To visualize the residuals, I group respondents by age and compute\n",
    "percentiles in each group. The following figure\n",
    "shows the 25th, 50th and 75th percentiles of the residuals for each age\n",
    "group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5180d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from empiricaldist import Cdf\n",
    "\n",
    "# TODO: Do this with a simpler version of percentile\n",
    "\n",
    "cdfs = [Cdf.from_seq(group.residual) for _, group in groups][1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac48a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for percent in [0.75, 0.50, 0.25]:\n",
    "    weight_percentiles = [cdf.inverse(percent) for cdf in cdfs]\n",
    "    label = \"%dth\" % percent\n",
    "    plt.plot(age_means, weight_percentiles, label=label)\n",
    "\n",
    "decorate(xlabel=\"Mother's age (years)\", ylabel=\"Residual (lbs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe97a6c",
   "metadata": {},
   "source": [
    "The median is near zero, as expected, and the interquartile range\n",
    "is about 2 pounds. So if we know the mother's age, we can guess the\n",
    "baby's weight within a pound, about 50% of the time.\n",
    "\n",
    "Ideally these lines should be flat, indicating that the residuals are\n",
    "random, and parallel, indicating that the variance of the residuals is\n",
    "the same for all age groups. In fact, the lines are close to parallel,\n",
    "so that's good; but they have some curvature, indicating that the\n",
    "relationship is nonlinear. Nevertheless, the linear fit is a simple\n",
    "model that is probably good enough for some purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be8b43c",
   "metadata": {},
   "source": [
    "## Estimation\n",
    "\n",
    "The parameters `slope` and `inter` are estimates based on a sample; like\n",
    "other estimates, they are vulnerable to sampling bias, measurement\n",
    "error, and sampling error. \n",
    "\n",
    "Sampling bias is caused by non-representative\n",
    "sampling, measurement error is caused by errors in collecting and\n",
    "recording data, and sampling error is the result of measuring a sample\n",
    "rather than the entire population.\n",
    "\n",
    "To assess sampling error, we ask, \"If we run this experiment again, how\n",
    "much variability do we expect in the estimates?\" We can answer this\n",
    "question by running simulated experiments and computing sampling\n",
    "distributions of the estimates.\n",
    "\n",
    "We can simulate the experiments by resampling the data; that is, by treating the\n",
    "observed pregnancies as if they were the entire population and drawing\n",
    "samples, with replacement, from the observed sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "946cb0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_rows(df):\n",
    "    \"\"\"Resamples rows from a DataFrame.\n",
    "\n",
    "    df: DataFrame\n",
    "\n",
    "    returns: DataFrame\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    return df.sample(n, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6382b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_distributions(live, iters=101):\n",
    "    t = []\n",
    "    for _ in range(iters):\n",
    "        sample = resample_rows(live)\n",
    "        ages = sample.agepreg\n",
    "        weights = sample.totalwgt_lb\n",
    "        estimates = least_squares(ages, weights)\n",
    "        t.append(estimates)\n",
    "    inters, slopes = zip(*t)\n",
    "    return inters, slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5584d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inters, slopes = sampling_distributions(live, iters=1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b74a99e",
   "metadata": {},
   "source": [
    "`SamplingDistributions` takes a `DataFrame` with one row per live birth,\n",
    "and `iters`, the number of experiments to simulate. It uses\n",
    "`ResampleRows` to resample the observed pregnancies. We've already seen\n",
    "`SampleRows`, which chooses random rows from a `DataFrame`. `thinkstats2`\n",
    "also provides `ResampleRows`, which returns a sample the same size as\n",
    "the original:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb967d0",
   "metadata": {},
   "source": [
    "After resampling, we use the simulated sample to estimate parameters.\n",
    "The result is two sequences: the estimated intercepts and estimated\n",
    "slopes.\n",
    "\n",
    "I summarize the sampling distributions by printing the standard error\n",
    "and confidence interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c92f2210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(estimates, actual=None):\n",
    "    se = np.std(estimates)\n",
    "    ci = np.percentile(estimates, [5, 95])\n",
    "    print(se, ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be947b14",
   "metadata": {},
   "source": [
    "`summarize` takes a sequence of estimates and the actual value. It\n",
    "prints the mean of the estimates, the standard error and a 90%\n",
    "confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e76726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(inters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7dd9f9",
   "metadata": {},
   "source": [
    "For the intercept, the standard error is 0.071\n",
    "and 90% confidence interval (6.71, 6.94)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da1a80f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(slopes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10af2a8e",
   "metadata": {},
   "source": [
    "For the slope, the standard error is 0.0174, and 90% CI (0.0126, 0.0220).\n",
    "There is almost\n",
    "a factor of two between the low and high ends of this CI, so it should\n",
    "be considered a rough estimate.\n",
    "\n",
    "To visualize the sampling error of the estimate, we can plot all of the fitted lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6075384",
   "metadata": {},
   "outputs": [],
   "source": [
    "for slope, inter in zip(slopes, inters):\n",
    "    fxs, fys = fit_line(age_means, inter, slope)\n",
    "    plt.plot(fxs, fys, color=\"gray\", alpha=0.01)\n",
    "\n",
    "decorate(xlabel=\"Mother's age (years)\", ylabel=\"Residual (lbs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e0bef",
   "metadata": {},
   "source": [
    "Or for a less cluttered representation, we can plot a 90%\n",
    "confidence interval for each age. Here's the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f2f2757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinkstats import percentile_rows\n",
    "\n",
    "\n",
    "def plot_confidence_intervals(xs, inters, slopes, percent=90, **options):\n",
    "    fys_seq = []\n",
    "    for inter, slope in zip(inters, slopes):\n",
    "        fxs, fys = fit_line(xs, inter, slope)\n",
    "        fys_seq.append(fys)\n",
    "    p = (100 - percent) / 2\n",
    "    percents = p, 100 - p\n",
    "    low, high = percentile_rows(fys_seq, percents)\n",
    "    plt.fill_between(fxs, low, high, **options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c3826c",
   "metadata": {},
   "source": [
    "`xs` is the sequence of mother's age. `inters` and `slopes` are the\n",
    "estimated parameters generated by `sampling_distributions`. `percent`\n",
    "indicates which confidence interval to plot.\n",
    "\n",
    "`plot_confidence_intervals` generates a fitted line for each pair of\n",
    "`inter` and `slope` and stores the results in a sequence, `fys_seq`.\n",
    "Then it uses `percentile_rows` to select the upper and lower percentiles\n",
    "of `y` for each value of `x`. For a 90% confidence interval, it selects\n",
    "the 5th and 95th percentiles. `fill_between` draws a polygon that fills\n",
    "the space between two lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bd7bbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confidence_intervals(\n",
    "    age_means, inters, slopes, percent=90, color=\"gray\", alpha=0.3, label=\"90% CI\"\n",
    ")\n",
    "decorate(xlabel=\"Mother's age (years)\", ylabel=\"Residual (lbs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a2608",
   "metadata": {},
   "source": [
    "The vertical width of the region\n",
    "represents the effect of sampling error -- the effect is smaller for\n",
    "values near the mean and larger for the extremes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9372bd28",
   "metadata": {},
   "source": [
    "## Goodness of fit\n",
    "\n",
    "There are several ways to measure the quality of a linear model, or\n",
    "**goodness of fit**. One of the simplest is the standard deviation of\n",
    "the residuals.\n",
    "\n",
    "If you use a linear model to make predictions, `std(res)` is the root\n",
    "mean squared error (RMSE) of your predictions. For example, if you use\n",
    "mother's age to guess birth weight, the RMSE of your guess would be 1.40\n",
    "lbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62d3362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter, slope = least_squares(ages, weights)\n",
    "res = residuals(ages, weights, inter, slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5320cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Std(ys)\", np.std(weights))\n",
    "print(\"Std(res)\", np.std(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893dc012",
   "metadata": {},
   "source": [
    "If you guess birth weight without knowing the mother's age, the RMSE of\n",
    "your guess is `Std(ys)`, which is 1.41 lbs. So in this example, knowing\n",
    "a mother's age does not improve the predictions substantially.\n",
    "\n",
    "Another way to measure goodness of fit is the **coefficient of\n",
    "determination**, usually denoted $R^2$ and called \"R-squared\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5566d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_determination(ys, res):\n",
    "    return 1 - np.var(res) / np.var(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e6315ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = coef_determination(weights, res)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fddcaab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinkstats import corr\n",
    "\n",
    "print(\"rho\", corr(ages, weights))\n",
    "print(\"R\", np.sqrt(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dba7079",
   "metadata": {},
   "source": [
    "`Var(res)` is the MSE of your guesses using the model, `Var(ys)` is the\n",
    "MSE without it. So their ratio is the fraction of MSE that remains if\n",
    "you use the model, and $R^2$ is the fraction of MSE the model\n",
    "eliminates.\n",
    "\n",
    "For birth weight and mother's age, $R^2$ is 0.0047, which means that\n",
    "mother's age predicts about half of 1% of variance in birth weight.\n",
    "\n",
    "There is a simple relationship between the coefficient of determination\n",
    "and Pearson's coefficient of correlation: $R^2 = \\rho^2$. For example,\n",
    "if $\\rho$ is 0.8 or -0.8, $R^2 = 0.64$.\n",
    "\n",
    "Although $\\rho$ and $R^2$ are often used to quantify the strength of a\n",
    "relationship, they are not easy to interpret in terms of predictive\n",
    "power. In my opinion, `Std(res)` is the best representation of the\n",
    "quality of prediction, especially if it is presented in relation to\n",
    "`Std(ys)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a43862",
   "metadata": {},
   "source": [
    "For example, when people talk about the validity of the SAT (a\n",
    "standardized test used for college admission in the U.S.) they often\n",
    "talk about correlations between SAT scores and other measures of\n",
    "intelligence.\n",
    "\n",
    "According to one study, there is a Pearson correlation of $\\rho=0.72$\n",
    "between total SAT scores and IQ scores, which sounds like a strong\n",
    "correlation. But $R^2 = \\rho^2 = 0.52$, so SAT scores account for only\n",
    "52% of variance in IQ.\n",
    "\n",
    "IQ scores are normalized with `Std(ys) = 15`, so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7831695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ys = 15**2\n",
    "rho = 0.72\n",
    "r2 = rho**2\n",
    "var_res = (1 - r2) * var_ys\n",
    "std_res = np.sqrt(var_res)\n",
    "std_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71196000",
   "metadata": {},
   "source": [
    "So using SAT score to predict IQ reduces RMSE from 15 points to 10.4\n",
    "points. A correlation of 0.72 yields a reduction in RMSE of only 31%.\n",
    "\n",
    "If you see a correlation that looks impressive, remember that $R^2$ is a\n",
    "better indicator of reduction in MSE, and reduction in RMSE is a better\n",
    "indicator of predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a544610",
   "metadata": {},
   "source": [
    "## Testing a linear model\n",
    "\n",
    "The effect of mother's age on birth weight is small, and has little\n",
    "predictive power. So is it possible that the apparent relationship is\n",
    "due to chance? There are several ways we might test the results of a\n",
    "linear fit.\n",
    "\n",
    "One option is to test whether the apparent reduction in MSE is due to\n",
    "chance. In that case, the test statistic is $R^2$ and the null\n",
    "hypothesis is that there is no relationship between the variables. We\n",
    "can simulate the null hypothesis by permutation.\n",
    "\n",
    "In fact, because $R^2 = \\rho^2$, a one-sided test\n",
    "of $R^2$ is equivalent to a two-sided test of $\\rho$. We've already done\n",
    "that test, and found $p < 0.001$, so we conclude that the apparent\n",
    "relationship between mother's age and birth weight is statistically\n",
    "significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dafb9f",
   "metadata": {},
   "source": [
    "Another approach is to test whether the apparent slope is due to chance.\n",
    "The null hypothesis is that the slope is actually zero; in that case we\n",
    "can model the birth weights as random variations around their mean.\n",
    "Here's a HypothesisTest for this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e4c6680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinkstats import HypothesisTest\n",
    "\n",
    "\n",
    "class SlopeTest(HypothesisTest):\n",
    "\n",
    "    def test_statistic(self, data):\n",
    "        ages, weights = data\n",
    "        _, slope = least_squares(ages, weights)\n",
    "        return slope\n",
    "\n",
    "    def make_model(self):\n",
    "        _, weights = self.data\n",
    "        self.ybar = weights.mean()\n",
    "        self.res = weights - self.ybar\n",
    "\n",
    "    def run_model(self):\n",
    "        ages, _ = self.data\n",
    "        weights = self.ybar + np.random.permutation(self.res)\n",
    "        return ages, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eb3c6e",
   "metadata": {},
   "source": [
    "The data are represented as sequences of ages and weights. The test\n",
    "statistic is the slope estimated by `LeastSquares`. The model of the\n",
    "null hypothesis is represented by the mean weight of all babies and the\n",
    "deviations from the mean. To generate simulated data, we permute the\n",
    "deviations and add them to the mean.\n",
    "\n",
    "Here's the code that runs the hypothesis test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a0526fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "live = live.dropna(subset=[\"agepreg\", \"totalwgt_lb\"])\n",
    "ht = SlopeTest((live.agepreg, live.totalwgt_lb))\n",
    "p_value = ht.p_value()\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfefce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht.actual, max(ht.test_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc74eae",
   "metadata": {},
   "source": [
    "The p-value is less than $0.001$, so although the estimated slope is\n",
    "small, it is unlikely to be due to chance.\n",
    "\n",
    "Estimating the p-value by simulating the null hypothesis is strictly\n",
    "correct, but there is a simpler alternative. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73488248",
   "metadata": {},
   "source": [
    "## Weighted resampling\n",
    "\n",
    "So far we have treated the NSFG data as if it were a representative\n",
    "sample, but as I mentioned in\n",
    "Section [\\[nsfg\\]](#nsfg){reference-type=\"ref\" reference=\"nsfg\"}, it is\n",
    "not. The survey deliberately oversamples several groups in order to\n",
    "improve the chance of getting statistically significant results; that\n",
    "is, in order to improve the power of tests involving these groups.\n",
    "\n",
    "This survey design is useful for many purposes, but it means that we\n",
    "cannot use the sample to estimate values for the general population\n",
    "without accounting for the sampling process.\n",
    "\n",
    "For each respondent, the NSFG data includes a variable called\n",
    "`finalwgt`, which is the number of people in the general population the\n",
    "respondent represents. This value is called a **sampling weight**, or\n",
    "just \"weight.\"\n",
    "\n",
    "As an example, if you survey 100,000 people in a country of 300 million,\n",
    "each respondent represents 3,000 people. If you oversample one group by\n",
    "a factor of 2, each person in the oversampled group would have a lower\n",
    "weight, about 1500."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cdc9ef",
   "metadata": {},
   "source": [
    "To correct for oversampling, we can use resampling; that is, we can draw\n",
    "samples from the survey using probabilities proportional to sampling\n",
    "weights. Then, for any quantity we want to estimate, we can generate\n",
    "sampling distributions, standard errors, and confidence intervals. As an\n",
    "example, I will estimate mean birth weight with and without sampling\n",
    "weights.\n",
    "\n",
    "In Section [\\[regest\\]](#regest){reference-type=\"ref\"\n",
    "reference=\"regest\"}, we saw `ResampleRows`, which chooses rows from a\n",
    "`DataFrame`, giving each row the same probability. Now we need to do the\n",
    "same thing using probabilities proportional to sampling weights.\n",
    "`ResampleRowsWeighted` takes a `DataFrame`, resamples rows according to\n",
    "the weights in `finalwgt`, and returns a `DataFrame` containing the\n",
    "resampled rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ccf2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_rows_weighted(df, column=\"finalwgt\"):\n",
    "    \"\"\"Resamples a DataFrame using probabilities proportional to given column.\n",
    "\n",
    "    df: DataFrame\n",
    "    column: string column name to use as weights\n",
    "\n",
    "    returns: DataFrame\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    weights = df[column]\n",
    "    return df.sample(n, weights=weights, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6489e",
   "metadata": {},
   "source": [
    "`weights` is a `Series`; converting it to a dictionary makes a map from\n",
    "the indices to the weights. In `cdf` the values are indices and the\n",
    "probabilities are proportional to the weights.\n",
    "\n",
    "`indices` is a sequence of row indices; `sample` is a `DataFrame` that\n",
    "contains the selected rows. Since we sample with replacement, the same\n",
    "row might appear more than once.\n",
    "\n",
    "Now we can compare the effect of resampling with and without weights.\n",
    "Without weights, we generate the sampling distribution like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3f63d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 100\n",
    "estimates = [resample_rows_weighted(live).totalwgt_lb.mean() for _ in range(iters)]\n",
    "summarize(estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da151467",
   "metadata": {},
   "source": [
    "With weights, it looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffdd06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = [resample_rows(live).totalwgt_lb.mean() for _ in range(iters)]\n",
    "summarize(estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7484b502",
   "metadata": {},
   "source": [
    "The following table summarizes the results:\n",
    "\n",
    "TODO: recompute this table, replacing the means of the sampling distributions with the actual estimates\n",
    "\n",
    " ```\n",
    "  ------------ -------------- ---------- --------------\n",
    "                 mean birth    standard      90% CI\n",
    "                weight (lbs)    error    \n",
    "  Unweighted        7.27        0.014     (7.24, 7.29)\n",
    "  Weighted          7.35        0.014     (7.32, 7.37)\n",
    "  ------------ -------------- ---------- --------------\n",
    "```\n",
    "\n",
    "In this example, the effect of weighting is small but non-negligible.\n",
    "The difference in estimated means, with and without weighting, is about\n",
    "0.08 pounds, or 1.3 ounces. This difference is substantially larger than\n",
    "the standard error of the estimate, 0.014 pounds, which implies that the\n",
    "difference is not due to chance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404ac2e8",
   "metadata": {},
   "source": [
    "## Glossary\n",
    "\n",
    "-   **linear fit**: a line intended to model the relationship between\n",
    "    variables.\n",
    "\n",
    "-   **least squares fit**: A model of a dataset that minimizes the sum\n",
    "    of squares of the residuals.\n",
    "\n",
    "-   **residual**: The deviation of an actual value from a model.\n",
    "\n",
    "-   **goodness of fit**: A measure of how well a model fits data.\n",
    "\n",
    "-   **coefficient of determination**: A statistic intended to quantify\n",
    "    goodness of fit.\n",
    "\n",
    "-   **sampling weight**: A value associated with an observation in a\n",
    "    sample that indicates what part of the population it represents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27d748b",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f90970e",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Exercise:** Use `resample_rows` and generate a list of estimates for the mean birth weight.  Use `summarize` to compute the SE and CI for these estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f158404",
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 1001\n",
    "estimates = [resample_rows(live).totalwgt_lb.mean() for _ in range(iters)]\n",
    "summarize(estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a87cef",
   "metadata": {},
   "source": [
    "**Exercise:** Using the data from the BRFSS, compute the linear least squares fit for log(weight) versus height. How would you best present the estimated parameters for a model like this where one of the variables is log-transformed? If you were trying to guess someone’s weight, how much would it help to know their height?\n",
    "\n",
    "Like the NSFG, the BRFSS oversamples some groups and provides a sampling weight for each respondent. In the BRFSS data, the variable name for these weights is totalwt. Use resampling, with and without weights, to estimate the mean height of respondents in the BRFSS, the standard error of the mean, and a 90% confidence interval. How much does correct weighting affect the estimates?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd6ca05",
   "metadata": {},
   "source": [
    "Read the BRFSS data and extract heights and log weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e375d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/nb/brfss.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/CDBRFS08.ASC.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29a2ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import brfss\n",
    "\n",
    "df = brfss.read_brfss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce2bc21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"htm3\", \"wtkg2\"])\n",
    "heights, weights = df.htm3, df.wtkg2\n",
    "log_weights = np.log10(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b4c4d1",
   "metadata": {},
   "source": [
    "Estimate intercept and slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91ee8f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter, slope = least_squares(heights, log_weights)\n",
    "inter, slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f97270",
   "metadata": {},
   "source": [
    "Make a scatter plot of the data and show the fitted line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d7b6daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fxs, fys = fit_line(heights, inter, slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6234c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(heights, log_weights, alpha=0.01, s=5)\n",
    "plt.plot(fxs, fys, color=\"C1\")\n",
    "decorate(xlabel=\"Height (cm)\", ylabel=\"log10 weight (kg)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd25c1",
   "metadata": {},
   "source": [
    "Make the same plot but apply the inverse transform to show weights on a linear (not log) scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8fe4970",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(heights, weights, alpha=0.01, s=5)\n",
    "fxs, fys = fit_line(heights, inter, slope)\n",
    "plt.plot(fxs, 10**fys, color=\"C1\")\n",
    "decorate(xlabel=\"Height (cm)\", ylabel=\"Weight (kg)\", legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5434c525",
   "metadata": {},
   "source": [
    "Plot percentiles of the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e469ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = residuals(heights, log_weights, inter, slope)\n",
    "df[\"residual\"] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "852a4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(130, 210, 5)\n",
    "indices = np.digitize(df.htm3, bins)\n",
    "groups = df.groupby(indices)\n",
    "means = [group.htm3.mean() for i, group in groups][1:-1]\n",
    "cdfs = [Cdf.from_seq(group.residual) for i, group in groups][1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d2b06d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for percent in [0.75, 0.50, 0.25]:\n",
    "    ys = [cdf.inverse(percent) for cdf in cdfs]\n",
    "    label = \"%dth\" % percent\n",
    "    plt.plot(means, ys, label=label)\n",
    "\n",
    "decorate(xlabel=\"height (cm)\", ylabel=\"residual weight (kg)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b974ed8",
   "metadata": {},
   "source": [
    "Compute correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f246543",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = corr(heights, log_weights)\n",
    "rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabe08de",
   "metadata": {},
   "source": [
    "Compute coefficient of determination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db91483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = coef_determination(log_weights, res)\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8adc821",
   "metadata": {},
   "source": [
    "Confirm that $R^2 = \\rho^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36f613c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(rho**2, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e905a590",
   "metadata": {},
   "source": [
    "Compute Std(ys), which is the RMSE of predictions that don't use height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "909dedd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_ys = np.std(log_weights)\n",
    "std_ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fb039f",
   "metadata": {},
   "source": [
    "Compute Std(res), the RMSE of predictions that do use height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9cfa1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_res = np.std(res)\n",
    "std_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4769693",
   "metadata": {},
   "source": [
    "How much does height information reduce RMSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f99d960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - std_res / std_ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faa6745",
   "metadata": {},
   "source": [
    "Use resampling to compute sampling distributions for inter and slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14022587",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "for _ in range(100):\n",
    "    sample = resample_rows(df)\n",
    "    estimates = least_squares(sample.htm3, np.log10(sample.wtkg2))\n",
    "    t.append(estimates)\n",
    "inters, slopes = zip(*t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef667108",
   "metadata": {},
   "source": [
    "Plot the sampling distribution of slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36a23bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = Cdf.from_seq(slopes)\n",
    "cdf.plot()\n",
    "decorate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890c9ae5",
   "metadata": {},
   "source": [
    "Compute the p-value of the slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed1c25f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = cdf(0)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf24a1c",
   "metadata": {},
   "source": [
    "Compute the 90% confidence interval of slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75f25058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab254fe",
   "metadata": {},
   "source": [
    "Compute the standard deviation of the sampling distribution, which is the standard error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2fb86ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab9e81a",
   "metadata": {},
   "source": [
    "Resample rows without weights, compute mean height, and summarize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4380e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb857ce",
   "metadata": {},
   "source": [
    "Resample rows with weights.  Note that the weight column in this dataset is called `finalwt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb52b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc18c928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a0230d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
